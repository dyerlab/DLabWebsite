[
  {
    "objectID": "manuscripts/eckert-dyer-2012/index.html#abstract",
    "href": "manuscripts/eckert-dyer-2012/index.html#abstract",
    "title": "Defining the landscape of adaptive genetic diversity",
    "section": "Abstract",
    "text": "Abstract\nWhether they are used to describe fitness, genome architecture or the spatial distribution of environmental variables, the concept of a landscape has figured prominently in our collective reasoning. The tradition of landscapes in evolutionary biology is one of fitness mapped onto axes defined by phenotypes or molecular sequence states. The characteristics of these landscapes depend on natural selection, which is structured across both genomic and environmental landscapes, and thus, the bridge among differing uses of the landscape concept (i.e. metaphorically or literally) is that of an adaptive phenotype and its distribution across geographical landscapes in relation to selective pressures. One of the ultimate goals of evolutionary biology should thus be to construct fitness landscapes in geographical space. Natural plant populations are ideal systems with which to explore the feasibility of attaining this goal, because much is known about the quantitative genetic architecture of complex traits for many different plant species. What is less known are the molecular components of this architecture. In this issue of Molecular Ecology, Parchman (2012) pioneer one of the first truly genome-wide association studies in a tree that moves us closer to this form of mechanistic understanding for an adaptive phenotype in natural populations of lodgepole pine (Pinus contorta Dougl. ex Loud.)."
  },
  {
    "objectID": "manuscripts/chan-lee-dyer-2018/index.html#abstract",
    "href": "manuscripts/chan-lee-dyer-2018/index.html#abstract",
    "title": "Comparison of Pollination Graphs",
    "section": "Abstract",
    "text": "Abstract\nFrom the agent-based, correlated random walk model presented, we observe theeffects of varying the maximum turning angle, δmax, tree density, ω, and pollen carryover, κmax, on the distribution of pollen within a tree population by examining pollination graphs. Varying maximum turning angle and pollen carryover alters the dispersal of pollen, which affects many measures of connectivity of the pollination graph. Among these measures the clustering coefficient of fathers is largest when δmax is between 60 and 90∘ . The greatest effect of varying ω is not on the clustering coefficient of fathers, but on the other measures of genetic diversity. In particular when comparing simulations with randomly placed trees with that of actual tree placement of C. florida at the VCU Rice Center, it is clear that having specific tree locations is crucial in determining the properties of a pollination graph."
  },
  {
    "objectID": "manuscripts/dyer-sork-2001/index.html#abstract",
    "href": "manuscripts/dyer-sork-2001/index.html#abstract",
    "title": "Pollen pool heterogeneity in shortleaf pine, Pinus echinata Mill.",
    "section": "Abstract",
    "text": "Abstract\nPollen is the dominant vector of gamete exchange for most temperate tree species. Because pollen movement influences the creation, maintenance and erosion of genetic structure in adult populations, it is important to understand what factors influence the process of pollen movement. Isolation by distance in pollen donor populations can create highly structured pollen polls by increased sampling of local fathers. Extrinsic factors, such as the intervening vegetative structure and local pollen donor densities, can also influence the genetic composition of local. pollen pools. Using paternally inherited chloroplast microsatellite markers, we examined the structure and diversity of pollen pools in Pinus echinata Mill. in southern Missouri, USA. Our analysis is based on a multivariate AMOVA analysis of stands (approximate to1 ha; six per region) nested within regions (approximate to 800 ha; four each). Significant multilocus structure of the pollen pool within regions (phi (SR) = 0.095), but not among regions (phi (RT) = 0.010), indicates that pollen movement is relatively restricted. Furthermore, the significant correlation between pairwise genetic and physical distances (Mantel correlation; rho = 0.32) provided support for the isolation by distance hypothesis. Our results indicated that availability of pollen donors did not affect diversity of the pollen pool, measured by the number of unique multilocus genotypes at each stand. However, pollen pool diversity was negatively associated with vegetative structure, measured as total forest tree density. Our findings indicated that on-going pollen movement within continuous forest is relatively restricted as a result of both isolation by distance and vegetative structure."
  },
  {
    "objectID": "manuscripts/kluetsch-dyer-misof-2012/index.html#abstract",
    "href": "manuscripts/kluetsch-dyer-misof-2012/index.html#abstract",
    "title": "Combining multiple analytical approaches for the identification of population structure and genetic delineation of two subspecies of the endemic Arabian burnet moth Reissita simonyi (Zygaenidae; Lepidoptera)",
    "section": "Abstract",
    "text": "Abstract\nHabitat fragmentation and landscape topology may influence the genetic structure and connectivity between natural populations. Six microsatellite loci were used to infer the population structure of 35 populations (N = 788) of the alpine Arabian burnet moth Reissita simonyi (Lepidoptera, Zygaenidae) in Yemen and Oman. Due to the patchy distribution of larval food plants, R. simonyi is not continuously distributed throughout the studied area and the two recognized subspecies of this endemic species (Reissita s. simonyi/R. s. yemenicola) are apparently discretely distributed. All microsatellites showed prevalence of null alleles and therefore a thorough investigation of the impact of null alleles on different population genetic parameters (F-ST, inbreeding coefficients, and Population Graph topologies) is given. In general, null alleles reduced genetic covariance and independence of allele frequencies resulting in a more connected genetic topology in Population Graphs and an overestimation of pairwise F-ST values and inbreeding coefficients. Despite the presence of null alleles, Population Graphs also showed a much higher genetic connectivity within subspecies (and lower genetic differentiation (via F-ST)) than between; supporting existing taxonomic distinction. Partial Mantel tests showed that both geographical distance and altitude were highly correlated with the observed distribution of genetic structure within R. simonyi. In conclusion, we identified geographical and altitudinal distances in R. simonyi as well as an intervening desert area to be the main factors for spatial genetic structure in this species and show that the taxonomic division into two subspecies is confirmed by genetic analysis."
  },
  {
    "objectID": "manuscripts/dyer-2007-tpb/index.html#abstract",
    "href": "manuscripts/dyer-2007-tpb/index.html#abstract",
    "title": "The evolution of genetic topologies",
    "section": "Abstract",
    "text": "Abstract\nThis manuscript explores the simultaneous evolution of population genetic parameters and topological features within a population graph through a series of Monte Carlo simulations. I show that node centrality and graph breadth are significantly correlated to population genetic parameters Phi(ST) and M (p = -0.95; p = -0.98, respectively), which are commonly used in quantifying among population genetic structure and isolation by distance. Next, the topological consequences of migration patterns are examined by contrasting N-island and stepping stone models of gene movement. Finally, I show how variation in migration rate influences the rate of formation of specific topological features with particular emphasis to the phase transition that occurs when populations begin to become fixed due to restricted movement of genes among populations. I close by discussing the utility of this method for the analysis of intraspecific genetic variation. (c) 2006 Elsevier Inc. All rights reserved."
  },
  {
    "objectID": "manuscripts/dyer-et-al-2004/index.html#abstract",
    "href": "manuscripts/dyer-et-al-2004/index.html#abstract",
    "title": "Two-generation analysis of pollen flow across a landscape V: a stepwise approach for extracting factors contributing to pollen structure",
    "section": "Abstract",
    "text": "Abstract\nPatterns of pollen dispersal are central to both the ecology and evolution of plant populations. However, the mechanisms controlling either the dispersal process itself or our estimation of that process may be influenced by site-specific factors such as local forest structure and nonuniform adult genetic structure. Here, we present an extension of the AMOVA model applied to the recently developed 2Gener analysis of pollen pool structure. This model, dubbed the Stepwise AMOVA (StAMOVA), focuses on determining to what extent ecological, demographic, and/or environmental factors influence the observed genetic variation in spatially separated pollen pools. The analysis is verified for efficacy, using an extensive battery of simulations, illustrating: ( 1) how nonuniform adult genetic structure influences the differentiation of spatially separated pollen pools, and ( 2) how effectively the Stepwise analysis performs in carrying out the appropriate corrections. Finally, the model is applied to a Quercus alba data set, from which we have prior evidence that the adult genetic structure is nonuniformly distributed across the sampling landscape. From this data set, we show how the Stepwise model can be applied to remove the effects of spatial adult genetic structure on pollen pool differentiation and contrast these results with those derived from the original 2Gener analysis."
  },
  {
    "objectID": "manuscripts/apsit-et-al-2002/index.html",
    "href": "manuscripts/apsit-et-al-2002/index.html",
    "title": "Patterns of mating in an insect-pollinated tree species in the Missouri Ozark Forest Ecosystem Project",
    "section": "",
    "text": "Contemporary gene flow is a major mechanism for the maintenance of genetic diversity. One component of gene flow is the mating system, which is a composite measure of selfing, mating with relatives, and outcrossing. Although both gene flow and mating patterns contribute to the ecological sustainability of populations, a focus of many forest management plans, these processes are often overlooked in forest management studies. As part of the Missouri Ozark Forest Ecosystem Project (MOFEP) we conducted a study of mating patterns in flowering dogwood (Cornus florida L), an insect-pollinated tree that is abundant and ubiquitous under story tree of upland Missouri Ozark forests. In 1998 and 1999, we collected fruit from over 200 Cornus florida individuals located in six compartments (MOFEP sites 1-6; similar to250-500 ha each), which were subjected to one of three management treatments: even-aged, uneven-aged, and no harvest. To see whether the management treatments influenced tree density surrounding the study trees, we measured and compared tree density across treatments. Because differential germination could reflect either genetic or environmental factors affecting the mating system, we measured germination success on a per maternal tree basis. We then measured the outcrossing rate, the rate of consanguineous mating (mating with relatives), and the effective number of pollen donors for each of the six sites and tested the hypotheses that both treatment and local tree density have no influence on these aspects of mating. Furthermore, the percent germination among mothers was not significantly influenced by the application of forest treatments. Multilocus outcrossing, t(m) (range 0.981-1.000), single locus outcrossing, t(s) (range 0.976-0.996), and the genetic effective number of pollen donors (range 4-11) did not differ among management treatments. For 1998, mating with relatives tended to increase with local density (df=1,28, F=4.07, P=0.053, 1998 only), suggesting local familial structure at the site level. No trend in consanguineous mating was observed in the data collected in 1999. The overall results show that the first cycle of timber harvesting had little effect on insect-mediated pollen movement in C. florida This lack of impact could be due to the fact that the treatments did not alter pollinator behavior. Thus, to evaluate the general impact of forest management on gene flow and mating in woody plants, we recommend ongoing monitoring as management treatments are continued and further studies on additional plant species."
  },
  {
    "objectID": "manuscripts/tassone-et-al-2020/tassone-et-al-2020.html",
    "href": "manuscripts/tassone-et-al-2020/tassone-et-al-2020.html",
    "title": "Evolutionary stability, landscape heterogeneity, and human land-usage shape population genetic connectivity in the Cape Floristic Region biodiversity hotspot.",
    "section": "",
    "text": "Figure 5: Popgraph of genetic connectivity among 51 sampled locales of Leucadendron salignum chloroplast DNA (see Figure 1 for geographic sampling, Table S1 for locale information). Color-coding reflects the five major phylogenetic tree clusters."
  },
  {
    "objectID": "manuscripts/tassone-et-al-2020/tassone-et-al-2020.html#abstract",
    "href": "manuscripts/tassone-et-al-2020/tassone-et-al-2020.html#abstract",
    "title": "Evolutionary stability, landscape heterogeneity, and human land-usage shape population genetic connectivity in the Cape Floristic Region biodiversity hotspot.",
    "section": "Abstract",
    "text": "Abstract\nAs human-induced change eliminates natural habitats, it impacts genetic diversity and population connectivity for local biodiversity. The South African Cape Floristic Region (CFR) is the most diverse extratropical area for plant biodiversity, and much of its habitat is protected as a UNESCO World Heritage site. There has long been great interest in explaining the underlying factors driving this unique diversity, especially as much of the CFR is endangered by urbanization and other anthropogenic activity. Here, we use a population and landscape genetic analysis of SNP data from the CFR endemic plant Leucadendron salignum or “common sunshine conebush” as a model to address the evolutionary and environmental factors shaping the vast CFR diversity. We found that high population structure, along with relatively deeper and older genealogies, is characteristic of the southwestern CFR, whereas low population structure and more recent lineage coalescence depict the eastern CFR. Population network analyses show genetic connectivity is facilitated in areas of lower elevation and higher seasonal precipitation. These population genetic signatures corroborate CFR species-level patterns consistent with high Pleistocene biome stability and landscape heterogeneity in the southwest, but with coincident instability in the east. Finally, we also find evidence of human land-usage as a significant gene flow barrier, especially in severely threatened lowlands where genetic connectivity has been historically the highest. These results help identify areas where conservation plans can prioritize protecting high genetic diversity threatened by contemporary human activities within this unique cultural UNESCO site."
  },
  {
    "objectID": "manuscripts/dyer-2015-AREES/index.html#abstract",
    "href": "manuscripts/dyer-2015-AREES/index.html#abstract",
    "title": "Population Graphs and Landscape Genetics",
    "section": "Abstract",
    "text": "Abstract\nAt the heart of the analyses of landscape genetics are isolation models seeking to explain either interindividual or interpopulation connectivity. These models use spatial, ecological, and topographic predictor variables measured between sites in an attempt to explain observed genetic variation. During the past decade, these models have adopted an increasingly sophisticated set of techniques to quantify intervening physical and ecological spaces, although they are restrained by rather mundane approaches to characterizing the genetic components of connectivity. Population Graphs are one approach to improving the quantification of genetic covariance used in models of landscape genetics. I explain the construction of the Population Graph framework, explain its strengths and weaknesses, and provide examples of how it has been used during the past decade within the contexts of landscape and population genetics."
  },
  {
    "objectID": "manuscripts/dyer-nason-2004/index.html#abstract",
    "href": "manuscripts/dyer-nason-2004/index.html#abstract",
    "title": "Population Graphs: the graph theoretic shape of genetic structure",
    "section": "Abstract",
    "text": "Abstract\nPatterns of intraspecific genetic variation result from interactions among both historical and contemporary evolutionary processes. Traditionally, population geneticists have used methods such as F-statistics, pairwise isolation by distance models, spatial autocorrelation and coalescent models to analyse this variation and to gain insight about causal evolutionary processes. Here we introduce a novel approach (Population Graphs) that focuses on the analysis of marker-based population genetic data within a graph theoretic framework. This method can be used to estimate traditional population genetic summary statistics, but its primary focus is on characterizing the complex topology resulting from historical and contemporary genetic interactions among populations. We introduce the application of Population Graphs by examining the range-wide population genetic structure of a Sonoran Desert cactus (Lophocereus schottii). With this data set, we evaluate hypotheses regarding historical vicariance, isolation by distance, population-level assignment and the importance of specific populations to species-wide genetic connectivity. We close by discussing the applicability of Population Graphs for addressing a wide range of population genetic and phylogeographical problems."
  },
  {
    "objectID": "manuscripts/friedline-et-al-2019/index.html#abstract",
    "href": "manuscripts/friedline-et-al-2019/index.html#abstract",
    "title": "Evolutionary genomics of gypsy moth populations sampled along a latitudinal gradient",
    "section": "Abstract",
    "text": "Abstract\nThe European gypsy moth (Lymantria dispar L.) was first introduced to Massachusetts in 1869 and within 150 years has spread throughout eastern North America. This large‐scale invasion across a heterogeneous landscape allows examination of the genetic signatures of adaptation potentially associated with rapid geographical spread. We tested the hypothesis that spatially divergent natural selection has driven observed changes in three developmental traits that were measured in a common garden for 165 adult moths sampled from six populations across a latitudinal gradient covering the entirety of the range. We generated genotype data for 91,468 single nucleotide polymorphisms based on double digest restriction‐site associated DNA sequencing and used these data to discover genome‐wide associations for each trait, as well as to test for signatures of selection on the discovered architectures. Genetic structure across the introduced range of gypsy moth was low in magnitude (FST = 0.069), with signatures of bottlenecks and spatial expansion apparent in the rare portion of the allele frequency spectrum. Results from applications of Bayesian sparse linear mixed models were consistent with the presumed polygenic architectures of each trait. Further analyses indicated spatially divergent natural selection acting on larval development time and pupal mass, with the linkage disequilibrium component of this test acting as the main driver of observed patterns. The populations most important for these signals were two range‐edge populations established less than 30 generations ago. We discuss the importance of rapid polygenic adaptation to the ability of non‐native species to invade novel environments."
  },
  {
    "objectID": "manuscripts/flores-manzanero-et-al-2019/index.html#abstract",
    "href": "manuscripts/flores-manzanero-et-al-2019/index.html#abstract",
    "title": "Functional connectivity and home range inferred at a microgeographic landscape genetics scale in a desert-dwelling rodent",
    "section": "Abstract",
    "text": "Abstract\nGene flow in animals is limited or facilitated by different features within the landscape matrix they inhabit. The landscape representation in landscape genetics (LG) is traditionally modeled as resistance surfaces (RS), where novel optimization approaches are needed for assigning resistance values that adequately avoid subjectivity. Also, desert ecosystems and mammals are scarcely represented in LG studies. We addressed these issues by evaluating, at a microgeographic scale, the effect of landscape features on functional connectivity of the desert-dwelling Dipodomys merriami. We characterized genetic diversity and structure with microsatellites loci, estimated home ranges and movement of individuals using telemetry-one of the first with rodents, generated a set of individual and composite environmental surfaces based on hypotheses of variables influencing movement, and assessed how these variables relate to individual-based gene flow. Genetic diversity and structure results evidenced a family-induced pattern driven by first-order-related individuals, notably determining landscape genetic inferences. The vegetation cover and soil resistance optimized surface (NDVI) were the best-supported model and a significant predictor of individual genetic distance, followed by humidity and NDVI+humidity. Based on an accurate definition of thematic resolution, we also showed that vegetation is better represented as continuously (vs. categorically) distributed. Hence, with a nonsubjective optimization framework for RS and telemetry, we were able to describe that vegetation cover, soil texture, and climatic variables influence D. merriami’s functional connectivity at a microgeographic scale, patterns we could further explain based on the home range, habitat use, and activity observed between sexes. We describe the relationship between environmental features and some aspects of D. merriami’s behavior and physiology."
  },
  {
    "objectID": "manuscripts/bertrand-et-al-2017/index.html#abstract",
    "href": "manuscripts/bertrand-et-al-2017/index.html#abstract",
    "title": "Sex-specific graphs: Relating group-specific topology to demographic and landscape data",
    "section": "Abstract",
    "text": "Abstract\nSex-specific genetic structure is a commonly observed pattern among vertebrate species. Facing differential selective pressures, individuals may adopt sex-specific life history traits that ultimately shape genetic variation among populations. Although differential dispersal dynamics are commonly detected in the literature, few studies have used genetic structure to investigate sex-specific functional connectivity. The recent use of graph theoretic approaches in landscape genetics has demonstrated network capacities to describe complex system behaviours where network topology represents genetic interaction among subunits. Here, we partition the overall genetic structure into sex-specific graphs, revealing different male and female dispersal dynamics of a fisher (Pekania [Martes] pennanti) metapopulation in southern Ontario. Our analyses based on network topologies supported the hypothesis of male-biased dispersal. Furthermore, we demonstrated that the effect of the landscape, identified at the population level, could be partitioned among sex-specific strata. We found that female connectivity was negatively correlated with snow depth, whereas connectivity among males was not. Our findings underscore the potential of conducting sex-specific analysis by identifying landscape elements or configuration that differentially promotes or impedes functional connectivity between sexes, revealing processes that may otherwise remain cryptic. We propose that the sex-specific graph approach would be applicable to other vagile species where differential sex-specific processes are expected to occur."
  },
  {
    "objectID": "manuscripts/yang-et-al-2015/index.html#abstract",
    "href": "manuscripts/yang-et-al-2015/index.html#abstract",
    "title": "Genetic structure of Pinus henryi and Pinus tabuliformis: Natural landscapes as significant barriers to gene flow among populations",
    "section": "Abstract",
    "text": "Abstract\nMountains as natural barriers often have important effects on intraspecific genetic structure through restraining gene flow and enhancing differentiation among populations. While the Qinling and Daba mountains are considered significant geographic barriers, dividing China into temperate and subtropical regions, little is known about how this barrier influences the genetic patterns of sister species represented in distinct habitats. In this study, we analyzed genetic differentiation and the geographic boundary between Pinus henryi and Pinus tabuliformis using chloroplast microsatellite markers. Our data show high levels of among-population differentiation, consistent with the effects of historical demographic bottlenecks, local adaptation and climate effects. Three main geographic boundaries coinciding with mountain systems indicate natural landscapes, such as large rivers, and habitat loss caused by anthropogenic deforestation, are significant barriers to genetic exchange among populations. The divergence between populations in the eastern and western Qinling Mountains populations may possibly be ascribed to fragmentation driven by climate change. The genetic boundary of P. henryi and P. tabuliformis generally coincides with the previous morphological dividing line based on the unweighted pair group method using arithmetic averages and on spatial analysis of molecular variance. (C) 2015 Elsevier Ltd. All rights reserved."
  },
  {
    "objectID": "manuscripts/garrick-et-al-2008-con-gen/index.html#abstract",
    "href": "manuscripts/garrick-et-al-2008-con-gen/index.html#abstract",
    "title": "A set of polymorphic nuclear intron markers for conservation genetics and phylogeography of Euphorbia species (Pedilanthus clade)",
    "section": "Abstract",
    "text": "Abstract\nWe developed seven nuclear intron markers for Euphorbia lomelii. New exon-primed intron-crossing (EPIC) oligonucleotides were used for initial amplification and sequencing, then locus-specific primers and restriction-fragment-length polymorphism genotyping assays were designed. Loci showed no significant deviation from Hardy-Weinberg and linkage equilibrium, and they cross-amplify in at least three congeneric species."
  },
  {
    "objectID": "manuscripts/sork-et-al-2013/index.html#abstract",
    "href": "manuscripts/sork-et-al-2013/index.html#abstract",
    "title": "Putting the landscape into the genomics of trees: approaches for understanding local adaptation and population responses to changing climate",
    "section": "Abstract",
    "text": "Abstract\nThe Forest ecosystem genomics Research: supporTing Transatlantic Cooperation project (FoResTTraC, http://www.foresttrac.eu/) sponsored a workshop in August 2010 to evaluate the potential for using a landscape genomics approach for studying plant adaptation to the environment and the potential of local populations for coping with changing climate. This paper summarizes our discussions and articulates a vision of how we believe forest trees offer an unparalleled opportunity to address fundamental biological questions, as well as how the application of landscape genomic methods complement to traditional forest genetic approaches that provide critical information needed for natural resource management. In this paper, we will cover four topics. First, we begin by defining landscape genomics and briefly reviewing the unique situation for tree species in the application of this approach toward understanding plant adaptation to the environment. Second, we review traditional approaches in forest genetics for studying local adaptation and identifying loci underlying locally adapted phenotypes. Third, we present existing and emerging methods available for landscape genomic analyses. Finally, we briefly touch on how these approaches can aid in understanding practical topics such as management of tree populations facing climate change."
  },
  {
    "objectID": "manuscripts/baker-dyer-2011/index.html#abstract",
    "href": "manuscripts/baker-dyer-2011/index.html#abstract",
    "title": "Invasion genetics of Microstegium vimineum (Poaceae) within the James River Basin of Virginia, USA",
    "section": "Abstract",
    "text": "Abstract\nPatterns of spatial genetic structure produced following the expansion of an invasive species into novel habitats reflect demographic processes that have shaped the genetic structure we see today. We examined 359 individuals from 23 populations over 370 km within the James River Basin of Virginia, USA as well as four populations outside of the basin. Population diversity levels and genetic structure was quantified using several analyses. Within the James River Basin there was evidence for three separate introductions and a zone of secondary contact between two distinct lineages suggesting a relatively recent expansion within the basin. Microstegium vimineum possesses a mixed-mating system advantageous to invasion and populations with low diversity were found suggesting a recent founder event and self-fertilization. However, surprisingly high levels of diversity were found in some populations suggesting that out-crossing does occur. Understanding how invasive species spread and the genetic consequences following expansion may provide insights into the cause of invasiveness and can ultimately lead to better management strategies for control and eradication."
  },
  {
    "objectID": "manuscripts/watts-dyer-2018/index.html",
    "href": "manuscripts/watts-dyer-2018/index.html",
    "title": "Structure and Resilience of Bald Eagle Roost Networks",
    "section": "",
    "text": "DOI 10.1002/wsb.865"
  },
  {
    "objectID": "manuscripts/watts-dyer-2018/index.html#abstract",
    "href": "manuscripts/watts-dyer-2018/index.html#abstract",
    "title": "Structure and Resilience of Bald Eagle Roost Networks",
    "section": "Abstract",
    "text": "Abstract\nThe recognition that communal roosts are important elements within the life cycle of bald eagles (Haliaeetus leucocephalus) led to their protection under the ``disturb″ clause of the Bald and Golden Eagle Protection Act. The regular roost-switching movements of bald eagles imply that roosts are part of an interactive network where roosts represent nodes linked by birds moving between them. Network analysis holds promise for informing management decisions by assessing the effect of roost removal on the resilience of the broader network. We tracked nonbreeding bald eagles (n = 56) within the upper Chesapeake Bay (2008-2013), USA, to evaluate roost characteristics and network structure. We used midnight locations (n = 14,464) to assess the use of communal roosts (n = 212) and movement of birds among roosts (n = 2,634) on successive roost nights to evaluate the pattern and strength of connections. We performed a sensitivity analysis to assess the response of the roost network to roost loss. Structure of the roost network approximated that of a scale-free network where the distribution of connections follows a power law of the form P(k)=Ak(-gamma) and gamma = 1.1. Unlike random networks, connections within scale-free networks are concentrated within a few highly connected nodes (hubs). These hub roosts serve as bridges between large numbers of other roosts, have the shortest travel times to other roosts and greatest overall influence on network functioning. The effect of roost removal on overall network function was directly proportional to the connectivity of the roost being removed. The targeted removal of the majority (>90%) of roosts had very little effect on the network. Network sensitivity was high in response to the loss of roosts within the highest 10% of connectivity. This small (n = 18) subset of roosts makes a disproportionate contribution to network function and the protection of these roosts should be a stated management objective with high priority. Network analysis represents a powerful tool with the potential to inform management decisions. (C) 2018 The Wildlife Society."
  },
  {
    "objectID": "manuscripts/dyer-2005/index.html#abstract",
    "href": "manuscripts/dyer-2005/index.html#abstract",
    "title": "GENER: a server-based analysis of pollen pool structure",
    "section": "Abstract",
    "text": "Abstract\nThe server-based program GENER performs the two-generation analysis of pollen flow for data consisting of mother/offspring arrays using genetic markers. The GENER program decomposes the genetic variance sampled by maternal individuals within and among pollen pool components of genetic variance and is accessible from http://dyerlab.bio.vcu.edu. These estimates are used to construct the test statistic, Phi(FT), whose significance is tested via permutation. The Phi(FT) statistic can subsequently be used to quantify genetic effective pollen donor population size (N-ep), effective mating area and dispersal distance. Furthermore, the GENER program can calculate Phi(FT) values for all pairs of substrata within the data set."
  },
  {
    "objectID": "manuscripts/foster-chan-dyer-2016/index.html",
    "href": "manuscripts/foster-chan-dyer-2016/index.html",
    "title": "Model Comparison for Abiotic versus Biotic Pollen Dispersal",
    "section": "",
    "text": "PDF Download"
  },
  {
    "objectID": "manuscripts/foster-chan-dyer-2016/index.html#abstract",
    "href": "manuscripts/foster-chan-dyer-2016/index.html#abstract",
    "title": "Model Comparison for Abiotic versus Biotic Pollen Dispersal",
    "section": "Abstract",
    "text": "Abstract\nAn agent-based model with a correlated random walk is used to explore pollination within a forest. For abiotic dispersal, say via the wind, we use a purely random walk where there is no correlation between consecutive steps and for biotic dispersal, say via insect, we use a moderate or highly correlated random walk. In particular, we examine the differences in a number of biological measurement between a purely random walk and a correlated random walk in terms of gene dispersal in low and high plant densities."
  },
  {
    "objectID": "manuscripts/gonzales-et-al-2006/index.html",
    "href": "manuscripts/gonzales-et-al-2006/index.html",
    "title": "Pollen-mediated gene dispersal within continuous and fragmented populations of a forest understorey species, Trillium cuneatum",
    "section": "",
    "text": "DOI 10.1111/j.1365-294X.2006.02913.x"
  },
  {
    "objectID": "manuscripts/gonzales-et-al-2006/index.html#abstract",
    "href": "manuscripts/gonzales-et-al-2006/index.html#abstract",
    "title": "Pollen-mediated gene dispersal within continuous and fragmented populations of a forest understorey species, Trillium cuneatum",
    "section": "Abstract",
    "text": "Abstract\nPollen movement plays a critical role in the distribution of genetic variation within and among plant populations. Direct measures of pollen movement in the large, continuous populations that characterize many herbaceous plant species are often technically difficult and biologically unreliable. Here, we studied contemporary pollen movement in four large populations of Trillium cuneatum. Three populations, located in the Georgia Piedmont, are exposed to strong anthropogenic disturbances, while the fourth population, located in the Southern Appalachian Mountains, is relatively undisturbed. Using the recently developed 2Gener analysis, we extracted estimates of the effective number of pollen donors (N-ep), effective mating neighbourhood size (A(ep)) and the average distance of pollen movement (delta) for each population. We extended the 2Gener method by developing inference on the paternal gametic contribution to the embryo in situations where offspring genotypes are inferred from seeds and elaiosomes of species with bisporic megagametogenesis. Our estimates indicate that maternal plants do not sample pollen randomly from a global pool; rather, pollen movement in all four populations is highly restricted. Although the effective number of pollen donors per maternal plant is low (1.22-1.66) and pollen movement is highly localized in all populations, N-ep in the disturbed Piedmont populations is higher and there is more pollen movement than in the mountains. The distance pollen moves is greater in disturbed sites and fragmented populations, possibly due to edge effects in Trillium habitats."
  },
  {
    "objectID": "manuscripts/dyer-et-al-2010/index.html#abstract",
    "href": "manuscripts/dyer-et-al-2010/index.html#abstract",
    "title": "Landscape modelling of gene flow: improved power using conditional genetic distance derived from the topology of population networks",
    "section": "Abstract",
    "text": "Abstract\nLandscape genetics is a burgeoning field of interest that focuses on how site-specific factors influence the distribution of genetic variation and the genetic connectivity of individuals and populations. In this manuscript, we focus on two methodological extensions for landscape genetic analyses: the use of conditional genetic distance (cGD) derived from population networks and the utility of extracting potentially confounding effects caused by correlations between phylogeographic history and contemporary ecological factors. Individual-based simulations show that when describing the spatial distribution of genetic variation, cGD consistently outperforms the traditional genetic distance measure of linearized F(ST) under both 1- and 2-dimensional stepping stone models and Cavalli-Sforza and Edward’s chord distance D(c) in 1-dimensional landscapes. To show how to identify and extract the effects of phylogeographic history prior to embarking on landscape genetic analyses, we use nuclear genotypic data from the Sonoran desert succulent Euphorbia lomelii (Euphrobiaceae), for which a detailed phylogeographic history has previously been determined. For E. lomelii, removing the effect of phylogeographic history significantly influences our ability to infer both the identity and the relative importance of spatial and bio-climatic variables in subsequent landscape genetic analyses. We close by discussing the utility of cGD in landscape genetic analyses."
  },
  {
    "objectID": "manuscripts/garrick-et-al-2010/index.html#abstract",
    "href": "manuscripts/garrick-et-al-2010/index.html#abstract",
    "title": "Nuclear gene phylogeography using PHASE: dealing with unresolved genotypes, lost alleles, and systematic bias in parameter estimation",
    "section": "Abstract",
    "text": "Abstract\nBackground: A widely-used approach for screening nuclear DNA markers is to obtain sequence data and use bioinformatic algorithms to estimate which two alleles are present in heterozygous individuals. It is common practice to omit unresolved genotypes from downstream analyses, but the implications of this have not been investigated. We evaluated the haplotype reconstruction method implemented by PHASE in the context of phylogeographic applications. Empirical sequence datasets from five non-coding nuclear loci with gametic phase ascribed by molecular approaches were coupled with simulated datasets to investigate three key issues: (1) haplotype reconstruction error rates and the nature of inference errors, (2) dataset features and genotypic configurations that drive haplotype reconstruction uncertainty, and (3) impacts of omitting unresolved genotypes on levels of observed phylogenetic diversity and the accuracy of downstream phylogeographic analyses. Results: We found that PHASE usually had very low false-positives (i.e., a low rate of confidently inferring haplotype pairs that were incorrect). The majority of genotypes that could not be resolved with high confidence included an allele occurring only once in a dataset, and genotypic configurations involving two low-frequency alleles were disproportionately represented in the pool of unresolved genotypes. The standard practice of omitting unresolved genotypes from downstream analyses can lead to considerable reductions in overall phylogenetic diversity that is skewed towards the loss of alleles with larger-than-average pairwise sequence divergences, and in turn, this causes systematic bias in estimates of important population genetic parameters. Conclusions: A combination of experimental and computational approaches for resolving phase of segregating sites in phylogeographic applications is essential. We outline practical approaches to mitigating potential impacts of computational haplotype reconstruction on phylogeographic inferences. With targeted application of laboratory procedures that enable unambiguous phase determination via physical isolation of alleles from diploid PCR products, relatively little investment of time and effort is needed to overcome the observed biases."
  },
  {
    "objectID": "manuscripts/miles-et-al-2019-proc-roy-soc/index.html#abstract",
    "href": "manuscripts/miles-et-al-2019-proc-roy-soc/index.html#abstract",
    "title": "Urban hubs of connectivity: contrasting patterns of gene flow within and among cities in the western black widow spider",
    "section": "Abstract",
    "text": "Abstract\nAs urbanization drastically alters the natural landscape and generates novel habitats within cities, the potential for changes to gene flow for urban-dwelling species increases. The western black widow spider (Latrodectus hesperus) is a medically relevant urban adapter pest species, for which we have previously identified population genetic signatures consistent with urbanization facilitating gene flow, likely due to human-mediated transport. Here, in an analysis of 1.9 million genome-wide SNPs, we contrast broad-scale geographical analyses of 10 urban and 11 non-urban locales with fine-scale within-city analyses including 30 urban locales across the western USA. These hierarchical datasets enable us to test hypotheses of how urbanization impacts multiple urban cities and their genetic connectivity at different spatial scales. Coupled fine-scale and broad-scale analyses reveal contrasting patterns of high and low genetic differentiation among locales within cities as a result of low and high genetic connectivity, respectively, of these cities to the overall population network. We discuss these results as they challenge the use of cities as replicates of urban eco-evolution, and have implications for conservation and human health in a rapidly growing urban habitat."
  },
  {
    "objectID": "manuscripts/garrick-et-al-2010-con-gen/index.html",
    "href": "manuscripts/garrick-et-al-2010-con-gen/index.html",
    "title": "Variable nuclear markers for a Sonoran Desert bark beetle, Araptus attenuatus Wood (Curculionidae: Scolytinae), with applications to related genera",
    "section": "",
    "text": "DOI 10.1007/s10592-008-9738-3"
  },
  {
    "objectID": "manuscripts/garrick-et-al-2010-con-gen/index.html#abstract",
    "href": "manuscripts/garrick-et-al-2010-con-gen/index.html#abstract",
    "title": "Variable nuclear markers for a Sonoran Desert bark beetle, Araptus attenuatus Wood (Curculionidae: Scolytinae), with applications to related genera",
    "section": "Abstract",
    "text": "Abstract\nWe report eight new co-dominant nuclear markers for population genetics of the bark beetle Araptus attenuatus Wood. Several loci include introns from low-copy genes, and four cross-amplify in one or more related genera. The markers show moderate levels of polymorphism (2-19 alleles per locus), and no loci showed significant deviations from Hardy-Weinberg or linkage equilibrium across both of the two populations examined, consistent with Mendelian inheritance patterns."
  },
  {
    "objectID": "manuscripts/lozada-gobilard-et-al-2021/index.html",
    "href": "manuscripts/lozada-gobilard-et-al-2021/index.html",
    "title": "Genetic Diversity and Connectivity in Plant Species Differing in Clonality and Dispersal Mechanisms in Wetland Island Habitats",
    "section": "",
    "text": "Figure 2: Genetic parameters of the analyzed populations of Oenanthe aquatica, Lycopus europaeus, Typha latifolia, and Phragmites australis. Genetic diversity measured as allelic richness.\n\n\nIn plants, long-distance dispersal is both attenuated and directed by specific movement vectors, including animals, wind, and/or water. Hence, movement vectors partly shape metapopulation genetic patterns that are, however, also influenced by other life-history traits such as clonal growth. We studied the relationship between area, isolation, plant-species richness, reproduction, and dispersal mechanisms with genetic diversity and divergence in 4 widespread wetland plant-species in a total of 20 island-like kettle-hole habitats surrounded by an intensive agricultural landscape. Our results showed that genetic parameters reflect the reproduction strategies with the highest genetic diversity being observed in the non-clonal, outcrossing Oenanthe aquatica compared to the clonal Lycopus europaeus, Typha latifolia, and Phragmites australis. Lycopus showed a positive relationship between genetic diversity and kettle-hole area, but a negative relationship with the number of neighboring kettle holes (less isolation). Genetic diversity increased with plant-species richness in the clonal species Phragmites and Lycopus; while it decreased in the non-clonal Oenanthe. Finally, genetic divergence and, therefore, connectivity differed between alternative dispersal strategies, where wind-dispersed Typha and Phragmites had a higher gene flow between the analyzed kettle holes compared with the insect-pollinated, hydrochorous Lycopus and Oenanthe. Our study provides information on genetic patterns related to reproduction and dispersal mechanisms of 4 common wetland species contributing to the understanding of the functioning of plant metacommunities occurring in kettle holes embedded in agricultural landscapes."
  },
  {
    "objectID": "manuscripts/dyer-2015/index.html#abstract",
    "href": "manuscripts/dyer-2015/index.html#abstract",
    "title": "Is there such a thing as landscape genetics?",
    "section": "Abstract",
    "text": "Abstract\nFor a scientific discipline to be interdisciplinary, it must satisfy two conditions; it must consist of contributions from at least two existing disciplines, and it must be able to provide insights, through this interaction, that neither progenitor discipline could address. In this study, I examine the complete body of peer-reviewed literature self-identified as landscape genetics (LG) using the statistical approaches of text mining and natural language processing. The goal here was to quantify the kinds of questions being addressed in LG studies, the ways in which questions are evaluated mechanistically, and how they are differentiated from the progenitor disciplines of landscape ecology and population genetics. I then circumscribe the main factions within published LG studies examining the extent to which emergent questions are being addressed and highlighting a deep bifurcation between existing individual - and population-based approaches. I close by providing some suggestions on where theoretical and analytical work is needed if LGs is to serve as a real bridge connecting evolution and ecology sensu lato."
  },
  {
    "objectID": "manuscripts/ritchie-et-al-2019/index.html#abstract",
    "href": "manuscripts/ritchie-et-al-2019/index.html#abstract",
    "title": "Wide outcrossing provides functional connectivity for new and old Banksia populations within a fragmented landscape",
    "section": "Abstract",
    "text": "Abstract\nHabitat fragmentation affects landscape connectivity, the extent of which is influenced by the movement capacity of the vectors of seed and pollen dispersal for plants. Negative impacts of reduced connectivity can include reduced fecundity, increased inbreeding, genetic erosion and decreased long-term viability. These are issues for not only old (remnant) populations, but also new (restored) populations. We assessed reproductive and connective functionality within and among remnant and restored populations of a common tree, Banksia menziesii R.Br. (Proteaceae), in a fragmented urban landscape, utilising a genetic and graph theoretical approach. Adult trees and seed cohorts from five remnants and two restored populations were genotyped using microsatellite markers. Genetic variation and pollen dispersal were assessed using direct (paternity assignment) and indirect (pollination graphs and mating system characterisation) methods. Restored populations had greater allelic diversity (Ar=8.08; 8.34) than remnant populations (Ar range=6.49-7.41). Genetic differentiation was greater between restored and adjacent remnants (F-ST=0.03 and 0.10) than all other pairwise comparisons of remnant populations (mean FST=0.01 +/- 0.01; N=16 P=0.001). All populations displayed low correlated paternity (rp=0.06-0.16) with wide-ranging realised pollen dispersal distances (<1.7km) and well-connected pollen networks. Here, we demonstrate reproductive and connective functionality of old and new populations of B. menziesii within a fragmented landscape. Due to long-distance pollination events, the physical size of these sites underestimates their effective population size. Thus, they are functionally equivalent to large populations, integrated into a larger landscape matrix."
  },
  {
    "objectID": "manuscripts/desaix-2019/index.html",
    "href": "manuscripts/desaix-2019/index.html",
    "title": "Population assignment reveals low migratory connectivity in a weakly structured songbird",
    "section": "",
    "text": "DOI 10.1111/mec.15083"
  },
  {
    "objectID": "manuscripts/desaix-2019/index.html#abstract",
    "href": "manuscripts/desaix-2019/index.html#abstract",
    "title": "Population assignment reveals low migratory connectivity in a weakly structured songbird",
    "section": "Abstract",
    "text": "Abstract\nUnderstanding migratory connectivity is essential for determining the drivers behind population dynamics and for implementing effective conservation strategies for migratory species. Genetic markers provide a means to describe migratory connectivity; however, they can be uninformative for species with weak population genetic structure, which has limited their application. Here, we demonstrated a genomic approach to describing migratory connectivity in the prothonotary warbler, Protonotaria citrea, a Neotropical songbird of conservation concern. Using 26,189 single nucleotide polymorphisms (SNPs), we revealed regional genetic structure between the Mississippi River Valley and the Atlantic Seaboard with overall weak genetic differentiation among populations (FST = 0.0055; 95% CI: 0.0051–0.0059). Genetic variation had a stronger association with geographic rather than environmental factors, with each explaining 14.5% and 8.2% of genetic variation, respectively. By varying the numbers of genomic markers used in population assignment models with individuals of known provenance, we identified a maximum assignment accuracy (89.7% to site, 94.3% to region) using a subset of 600 highly differentiated SNPs. We then assigned samples from nonbreeding sites to breeding region and found low migratory connectivity. Our results highlight the importance of filtering markers for informative loci in models of population assignment. Quantifying migratory connectivity for weakly structured species will be useful for expanding studies to a wider range of migratory species across taxonomic groups and may contribute to a deeper understanding of the evolution of migratory strategies."
  },
  {
    "objectID": "manuscripts/sork-et-al-2005/index.html",
    "href": "manuscripts/sork-et-al-2005/index.html",
    "title": "A two-generation analysis of pollen pool genetic structure in flowering dogwood, Cornus florida (Cornaceae), in the Missouri Ozarks",
    "section": "",
    "text": "DOI 10.3732/ajb.92.2.262"
  },
  {
    "objectID": "manuscripts/sork-et-al-2005/index.html#abstract",
    "href": "manuscripts/sork-et-al-2005/index.html#abstract",
    "title": "A two-generation analysis of pollen pool genetic structure in flowering dogwood, Cornus florida (Cornaceae), in the Missouri Ozarks",
    "section": "Abstract",
    "text": "Abstract\nAnthropogenic landscape change can disrupt gene flow. As part of the Missouri Ozark Forest Ecosystem Project, this study examined whether silvicultural practices influence pollen-mediated gene movement in the insect-pollinated species, Cornus florida L., by comparing pollen pool structure (Phi(st)) among clear-cutting, selective cutting, and uncut regimes with the expectation that pollen movement should be least in the uncut regime. Using a sample of 1500 seedlings - 10 each from 150 seed parents (43 in clear-cut, 74 in selective, and 33 in control sites) from six sites (each ranging from 266 to 527 ha), eight allozyme loci were analyzed with a pollen pool structure approach known as 2Gener (Smouse et al., 2001; Evolution 55: 260-271). This analysis revealed that pollen pool structure was less in clear-cut ((Phi) over circle (C) = 0.090, P < 0.001) than in uncut areas ((Phi) over cap (U) = 0.174, P < 0.001), with selective-cut intermediate ((Phi) over circles = 0.125, P < 0.001). These estimates translate into more effective pollen donors (N(ep)) in clear-cut (N(ep) = 5.56) and selective-cut (N(ep) = 4.00) areas than in uncut areas (N(ep) = 2.87). We demonstrate that Phi(C) less than or equal to Phi(S) less than or equal to Phi(U), with (Phi) over circle (C), significantly smaller than (Phi) over circle (U) (P < 0.034). The findings imply that, as long as a sufficiently large number of seed parents remain to provide adequate reproduction and to avoid a genetic bottleneck in the effective number of mothers, silvicultural management may not negatively affect the effective number of pollen parents, and hence subsequent genetic diversity in Cornus florida."
  },
  {
    "objectID": "manuscripts/cushman-et-al-2018/index.html#abstract",
    "href": "manuscripts/cushman-et-al-2018/index.html#abstract",
    "title": "Editorial: The Least Cost Path From Landscape Genetics to Landscape Genomics: Challenges and Opportunities to Explore NGS Data in a Spatially Explicit Context",
    "section": "Abstract",
    "text": "Abstract\nEcosystems are the stage on which the play of evolution is acted. Inferring evolutionary processes from the spatial and temporal genetic patterns they produce in populations is challenging because ecosystems are highly complex, spatially structured, and temporally varying. The field of landscape genetics has offered a means of navigating these challenges to make eco-evolutionary insights for many species. The emerging field of landscape genomics offers great promise to expand the potential of landscape genetic analysis even further. The purpose of this Research Topic for Evolutionary and Population Genetics is to explore a number of critical challenges and opportunities for the transition from landscape genetics to landscape genomics."
  },
  {
    "objectID": "manuscripts/sork-et-al-2002/index.html",
    "href": "manuscripts/sork-et-al-2002/index.html",
    "title": "Pollen movement in declining populations of California Valley oak, Quercus lobata: where have all the fathers gone?",
    "section": "",
    "text": "DOI 10.1046/j.1365-294X.2002.01574.x"
  },
  {
    "objectID": "manuscripts/sork-et-al-2002/index.html#abstract",
    "href": "manuscripts/sork-et-al-2002/index.html#abstract",
    "title": "Pollen movement in declining populations of California Valley oak, Quercus lobata: where have all the fathers gone?",
    "section": "Abstract",
    "text": "Abstract\nThe fragmented populations and reduced population densities that result from human disturbance are issues of growing importance in evolutionary and conservation biology. A key issue is whether remnant individuals become reproductively isolated. California Valley oak (Quercus lobata ) is a widely distributed, endemic species in California, increasingly jeopardized by anthropogenic changes in biota and land use. We studied pollen movement in a savannah population of Valley oak at Sedgwick Reserve, Santa Barbara County, to estimate effective number of pollen donors (N (ep) ) and average distance of effective pollen movement (delta). Using twogener, our recently developed hybrid model of paternity and genetic structure treatments that analyses maternal and progeny multilocus genotypes, we found that current N (ep) = 3.68 individuals. Based on an average adult density of d = 1.19 stems/ha, we assumed a bivariate normal distribution to model current average pollen dispersal distance (delta) and estimated delta= 64.8 m. We then deployed our parameter estimates in spatially explicit models of the Sedgwick population to evaluate the extent to which N (ep) may have changed, as a consequence of progressive stand thinning between 1944 and 1999. Assuming that pollen dispersal distance has not changed, we estimate N (ep) was 4.57 individuals in 1944, when stand density was 1.48. Both estimates indicate fewer effective fathers than one might expect for wind-pollinated species and fewer than observed elsewhere. The results presented here provide a basis for further refinements on modelling pollen movement. If the trends continue, then ongoing demographic attrition could further reduce neighbourhood size in Valley oak resulting in increased risk of reproductive failure and genetic isolation."
  },
  {
    "objectID": "manuscripts/tucker-et-al-2016/index.html#abstract",
    "href": "manuscripts/tucker-et-al-2016/index.html#abstract",
    "title": "Opportunistic conspecific brood parasitism in a box-nesting population of Prothonotary Warblers (Protonotaria citrea)",
    "section": "Abstract",
    "text": "Abstract\nConspecific brood parasitism (CBP), although prevalent in some avian taxa, is easily overlooked when it occurs in low frequencies, and therefore the ecology of this behavior has only occasionally been described in passerines. We describe the occurrence of CBP in a population of Prothonotary Warblers (Protonotaria citrea) breeding in nest boxes, demonstrate associated fitness costs, and investigate parasite strategy. We genotyped individuals at 6 microsatellite loci and used Cervus software to determine log-likelihood of maternity (LOD scores) for offspring and social mothers. We set critical cutoff LOD scores at 95% confidence for exclusion of the social mother and assignment of a parasite mother from the breeding population. Of 805 nestlings (233 family groups during 2009-2013), we found that 12.7% had genotypes that were incompatible with their social mother. Females with unrelated nestlings (hosts) fledged fewer biological offspring within the host year than nonhost females despite fledging more total offspring, but being a host was not significantly associated with total reproductive success over 5 yr of breeding. We were able to identify only similar to 30% of parasite females, which suggests that the majority of parasites may be floaters (i.e. non-nesters) in the population or nesting in nearby natural cavities. We found no evidence of host selection based on host age, arrival at the breeding site, or nest-box productivity in the previous year. This opportunistic behavior is likely facilitated by the nesting ecology of this population, in that nest sites are limited, conspicuous, and relatively dense. Future studies investigating CBP in populations using natural cavities can help elucidate the drivers of this behavior."
  },
  {
    "objectID": "manuscripts/kelly-dyer-2002/index.html#abstract",
    "href": "manuscripts/kelly-dyer-2002/index.html#abstract",
    "title": "Demographic consequences of inflorescence-feeding insects for Liatris cylindracea, an iteroparous perennial",
    "section": "Abstract",
    "text": "Abstract\nWhile floral herbivores and predispersal seed predators often reduce plant reproductive output, their role in limiting plant fitness and population growth is less clear, especially for iteroparous perennial plant species. In this study we experimentally excluded floral herbivores and predispersal seed predators (insecticide spray versus water control) over a 2-year period to examine the effect of inflorescence-feeding insects on levels of seed production, seedling emergence, and juvenile establishment for Liatris cylindracea, an iteroparous perennial plant. In addition, we collected detailed demographic data on all life stage transitions for an additional set of individuals in the same population over 4 years. We used the experimental and demographic data to construct stochastic individual-based simulations to evaluate the overall effect of inflorescence-feeding insects on adult recruitment per maternal plant (a fitness component) and population growth rate. The insect exclusion experiments showed that damage due to insects decreased seed production, seedling emergence, and juvenile establishment for both years’ experiments. These results indicate that recruitment was seed-limited through juvenile establishment, and that inflorescence-feeding insects influenced the degree of seed limitation. Results of the individual-based simulation models, which included individual demographic and temporal stochasticity, showed that inflorescence-feeding insects negatively affected the number of adult offspring per maternal plant recruited into the population and population growth rate for both years’ experiments. Taken together, the results of the experimental exclusions and the individual-based models indicate that inflorescence-feeding insects can influence population growth rate, and have the potential to act as a selective force for the evolution of traits in this plant species."
  },
  {
    "objectID": "manuscripts/smouse-et-al-2001/index.html",
    "href": "manuscripts/smouse-et-al-2001/index.html",
    "title": "Two-generation analysis of pollen flow across a landscape. I. Male gamete heterogeneity among females",
    "section": "",
    "text": "PDF Download"
  },
  {
    "objectID": "manuscripts/smouse-et-al-2001/index.html#abstract",
    "href": "manuscripts/smouse-et-al-2001/index.html#abstract",
    "title": "Two-generation analysis of pollen flow across a landscape. I. Male gamete heterogeneity among females",
    "section": "Abstract",
    "text": "Abstract\nGene flow is a key factor in the spatial genetic structure in spatially distributed species. Evolutionary biologists interested in microevolutionary processes and conservation biologists interested in the impact of landscape change require a method that measures the real time process of gene movement. We present a novel two-generation (parent-offspring) approach to the study of genetic structure (TwoGener) that allows us to quantify heterogeneity among the male gamete pools sampled by maternal trees scattered across the landscape and to estimate mean pollination distance and effective neighborhood size. First, we describe the model’s elements: genetic distance matrices to estimate intergametic distances, molecular analysis of variance to determine whether pollen profiles differ among mothers, and optimal sampling considerations. Second, we evaluate the model’s effectiveness by simulating spatially distributed populations. Spatial heterogeneity in male gametes can be estimated by Phi (FT), a male gametic analogue of Wright’s F(ST) and an inverse function of mean pollination distance. We illustrate TwoGener in cases where the male gamete can be categorically or ambiguously determined. This approach does not require the high level of genetic resolution needed by parentage analysis, but the ambiguous case is vulnerable to bias in the absence of adequate genetic resolution. Finally, we apply TwoGener to an empirical study of Quercus alba in Missouri Ozark forests. We find that Phi (FT) = 0.06, translating into about eight effective pollen donors per female and an effective pollination neighborhood as a circle of radius about 17 m. Effective pollen movement in Q. alba is more restricted than previously realized, even though pollen is capable of moving large distances. This case study illustrates that, with a modest investment in field survey and laboratory analysis, the TwoGener approach permits inferences about landscape-level gene movements."
  },
  {
    "objectID": "manuscripts/garrick-et-al-2015/index.html#abstract",
    "href": "manuscripts/garrick-et-al-2015/index.html#abstract",
    "title": "Identification of Eastern United States Reticulitermes Termite Species via PCR-RFLP, Assessed Using Training and Test Data",
    "section": "Abstract",
    "text": "Abstract\nReticulitermes termites play key roles in dead wood decomposition and nutrient cycling in forests. They also damage man-made structures, resulting in considerable economic loss. In the eastern United States, five species (R. flavipes, R. virginicus, R. nelsonae, R. hageni and R. malletei) have overlapping ranges and are difficult to distinguish morphologically. Here we present a molecular tool for species identification. It is based on polymerase chain reaction (PCR) amplification of a section of the mitochondrial cytochrome oxidase subunit II gene, followed by a three-enzyme restriction fragment length polymorphism (RFLP) assay, with banding patterns resolved via agarose gel electrophoresis. The assay was designed using a large set of training data obtained from a public DNA sequence database, then evaluated using an independent test panel of Reticulitermes from the Southern Appalachian Mountains, for which species assignments were determined via phylogenetic comparison to reference sequences. After refining the interpretive framework, the PCR-RFLP assay was shown to provide accurate identification of four co-occurring species (the fifth species, R. hageni, was absent from the test panel, so accuracy cannot yet be extended to training data). The assay is cost- and time-efficient, and will help improve knowledge of Reticulitermes species distributions."
  },
  {
    "objectID": "manuscripts/miles-et-al-2018-mol-ecol/index.html#abstract",
    "href": "manuscripts/miles-et-al-2018-mol-ecol/index.html#abstract",
    "title": "Urbanization as a facilitator of gene flow in a human health pest",
    "section": "Abstract",
    "text": "Abstract\nUrban fragmentation can reduce gene flow that isolates populations, reduces genetic diversity and increases population differentiation, all of which have negative conservation implications. Alternatively, gene flow may actually be increased among urban areas consistent with an urban facilitation model. In fact, urban adapter pests are able to thrive in the urban environment and may be experiencing human-mediated transport. Here, we used social network theory with a population genetic approach to investigate the impact of urbanization on genetic connectivity in the Western black widow spider, as an urban pest model of human health concern. We collected genomewide single nucleotide polymorphism variation from mitochondrial and nuclear double-digest RAD (ddRAD) sequence data sets from 210 individuals sampled from 11 urban and 10 nonurban locales across its distribution of the Western United States. From urban and nonurban contrasts of population, phylogenetic, and network analyses, urban locales have higher within-population genetic diversity, lower between-population genetic differentiation and higher estimates of genetic connectivity. Social network analyses show that urban locales not only have more connections, but can act as hubs that drive connectivity among nonurban locales, which show signatures of historical isolation. These results are consistent with an urban facilitation model of gene flow and demonstrate the importance of sampling multiple cities and markers to identify the role that urbanization has had on larger spatial scales. As the urban landscape continues to grow, this approach will help determine what factors influence the spread and adaptation of pests, like the venomous black widow spider, in building policies for human and biodiversity health."
  },
  {
    "objectID": "manuscripts/dyer-et-al-2012/index.html#abstract",
    "href": "manuscripts/dyer-et-al-2012/index.html#abstract",
    "title": "Pollination graphs: quantifying pollen pool covariance networks and the influence of intervening landscape on genetic connectivity in the North American understory tree, Cornus florida L.",
    "section": "Abstract",
    "text": "Abstract\nThe manner by which pollinators move across a landscape and their resulting preferences and/or avoidances of travel through particular habitat types can have a significant impact on plant population genetic structure and population-level connectivity. We examined the spatial genetic structure of the understory tree Cornus florida (Cornaceae) adults (N-Adults = 452) and offspring (N-Offspring = 736) across two mating events to determine the extent to which pollen pool genetic covariance is influenced by intervening forest architecture. Resident adults showed no spatial partitioning but genotypes were positively autocorrelated up to a distance of 35 m suggesting a pattern of restricted seed dispersal. In the offspring, selfing rates were small (s(m) = 0.035) whereas both biparental inbreeding (s(b;open) (canopy) = 0.16, s(b;closed canopy) = 0.11) and correlated paternity (r(p;open canopy) = 0.21, r(p;closed canopy) = 0.07) were significantly influenced by primary canopy opening above individual mothers. The spatial distribution of genetic covariance in pollen pool composition was quantified for each reproductive event using Pollination Graphs, a network method based upon multivariate conditional genetic covariance. The georeferenced graph topology revealed a significant positive relationship between genetic covariance and pollinator movement through C. florida canopies, a negative relationship with open primary canopy (e. g., roads under open canopies and fields with no primary canopy), and no relationship with either conifer or mixed hardwood canopy species cover. These results suggest that both resident genetic structure within stands and genetic connectivity between sites in C. florida populations are influenced by spatial heterogeneity of mating individuals and quality of intervening canopy cover."
  },
  {
    "objectID": "manuscripts/garrick-et-al-2009-mol-ecol/index.html#abstract",
    "href": "manuscripts/garrick-et-al-2009-mol-ecol/index.html#abstract",
    "title": "Not just vicariance: phylogeography of a Sonoran Desert euphorb indicates a major role of range expansion along the Baja peninsula",
    "section": "Abstract",
    "text": "Abstract\nTo examine the generality of population-level impacts of ancient vicariance identified for numerous arid-adapted animal taxa along the Baja peninsula, we tested phylogeographical hypotheses in a similarly distributed desert plant, Euphorbia lomelii (Euphorbiaceae). In light of fossil data indicating marked changes in the distributions of Baja floristic assemblages throughout the Holocene and earlier, we also examined evidence for range expansion over more recent temporal scales. Two classes of complementary analytical approaches hypothesis-testing and hypothesis-generating were used to exploit phylogeographical signal from chloroplast DNA sequence data and genotypic data from six codominant nuclear intron markers. Sequence data are consistent with a scenario of mid-peninsular vicariance originating c. 1 million years ago (Ma). Alternative vicariance scenarios representing earlier splitting events inferred for some animals (e.g. Isthmus of La Paz inundation, c. 3 Ma; Sea of Cortez formation, c. 5 Ma) were rejected. Nested clade phylo-geographical analysis corroborated coalescent simulation-based inferences. Nuclear markers broadened the temporal spectrum over which phylogeographical scenarios could be addressed, and provided strong evidence for recent range expansions along the north-south axis of the Baja peninsula. In contrast to previous plant studies in this region, however, the expansions do not appear to have been in a strictly northward direction. These findings contribute to a growing appreciation of the complexity of organismal responses to past climatic and geological changes even when taxa have evolved in the same landscape context."
  },
  {
    "objectID": "manuscripts/garrick-et-al-2008-mol-ecol/index.html#abstract",
    "href": "manuscripts/garrick-et-al-2008-mol-ecol/index.html#abstract",
    "title": "Babies and bathwater: a comment on the premature obituary for nested clade phylogeographical analysis",
    "section": "Abstract",
    "text": "Abstract"
  },
  {
    "objectID": "manuscripts/dyer-2009/index.html#abstract",
    "href": "manuscripts/dyer-2009/index.html#abstract",
    "title": "GeneticStudio: a suite of programs for spatial analysis of genetic-marker data",
    "section": "Abstract",
    "text": "Abstract\nThe analysis of genetic marker data is increasingly being conducted in the context of the spatial arrangement of strata (e.g. populations) necessitating a more flexible set of analysis tools. GeneticStudio consists of four interacting programs: (i) Geno a spreadsheet-like interface for the analysis of spatially explicit marker-based genetic variation; (ii) Graph software for the analysis of Population Graph and network topologies, (iii) Manteller, a general purpose for matrix analysis program; and (iv) SNPFinder, a program for identifying single nucleotide polymorphisms. The GeneticStudio suite is available as source code as well as binaries for OSX and Windows and is distributed under the GNU General Public License."
  },
  {
    "objectID": "manuscripts/garrick-et-al-2013/index.html#abstract",
    "href": "manuscripts/garrick-et-al-2013/index.html#abstract",
    "title": "Ecological coassociations influence species’ responses to past climatic change: an example from a Sonoran Desert bark beetle",
    "section": "Abstract",
    "text": "Abstract\nEcologically interacting species may have phylogeographical histories that are shaped both by features of their abiotic landscape and by biotic constraints imposed by their coassociation. The Baja California peninsula provides an excellent opportunity to examine the influence of abiotic vs. biotic factors on patterns of diversity in plant-insect species. This is because past climatic and geological changes impacted the genetic structure of plants quite differently to that of codistributed free-living animals (e.g. herpetofauna and small mammals). Thus, plant-like’ patterns should be discernible in host-specific insect herbivores. Here, we investigate the population history of a monophagous bark beetle, Araptus attenuatus, and consider drivers of phylogeographical patterns in the light of previous work on its host plant, Euphorbia lomelii. Using a combination of phylogenetic, coalescent-simulation-based and exploratory analyses of mitochondrial DNA sequences and nuclear genotypic data, we found that the evolutionary history of A.attenuatus exhibits similarities to its host plant that are attributable to both biotic and abiotic processes. Southward range expansion and recent colonization of continental Sonora from the Baja peninsula appear to be unique to this taxon pair and probably reflect influences of the host plant. On the other hand, abiotic factors with landscape-level influences on a diverse suite of codistributed arid-adapted taxa, such as Plio- and Pleistocene-aged marine incursions in the region, also left genetic signatures in beetle and host plant populations. Superimposed on these similarities, bark beetle-specific patterns and processes were also evident: our data revealed two secondarily sympatric, reproductively isolated genetic lineages, as well as a previously unrecognized mid-peninsular warm desert refuge. Taken together, this work illustrates that the evolutionary history of species-specific insect herbivores may represent a mosaic of influences, includingbut not limited tothose imposed by the host plant."
  },
  {
    "objectID": "manuscripts/dyer-2007/index.html#abstract",
    "href": "manuscripts/dyer-2007/index.html#abstract",
    "title": "Powers of discerning: challenges to understanding dispersal processes in natural populations",
    "section": "Abstract",
    "text": "Abstract\nIn this issue of Molecular Ecology, authors Robledo-Arnuncio & Garcia present a compelling approach for quantifying seed dispersal in plant populations. Building upon methods previously used for quantification of pollen dispersal, the authors not only examine the behaviour of the model with respect to sample sizes, dispersal distance, and the kurtosis of the dispersal function but also provide an empirical example using Prunus mahaleb."
  },
  {
    "objectID": "manuscripts/di-leo-et-al-2014/index.html#abstract",
    "href": "manuscripts/di-leo-et-al-2014/index.html#abstract",
    "title": "The gravity of pollination: integrating at-site features into spatial analysis of contemporary pollen movement",
    "section": "Abstract",
    "text": "Abstract\nPollen-mediated gene flow is a major driver of spatial genetic structure in plant populations. Both individual plant characteristics and site-specific features of the landscape can modify the perceived attractiveness of plants to their pollinators and thus play an important role in shaping spatial genetic variation. Most studies of landscape-level genetic connectivity in plants have focused on the effects of interindividual distance using spatial and increasingly ecological separation, yet have not incorporated individual plant characteristics or other at-site ecological variables. Using spatially explicit simulations, we first tested the extent to which the inclusion of at-site variables influencing local pollination success improved the statistical characterization of genetic connectivity based upon examination of pollen pool genetic structure. The addition of at-site characteristics provided better models than those that only considered interindividual spatial distance (e.g. IBD). Models parameterized using conditional genetic covariance (e.g. population graphs) also outperformed those assuming panmixia. In a natural population of Cornus florida L. (Cornaceae), we showed that the addition of at-site characteristics (clumping of primary canopy opening above each maternal tree and maternal tree floral output) provided significantly better models describing gene flow than models including only between-site spatial (IBD) and ecological (isolation by resistance) variables. Overall, our results show that including interindividual and local ecological variation greatly aids in characterizing landscape-level measures of contemporary gene flow."
  },
  {
    "objectID": "posts/2018-07-19-using-google-drive-as-an-r-data-repository/using-google-drive-as-an-r-data-repository.html",
    "href": "posts/2018-07-19-using-google-drive-as-an-r-data-repository/using-google-drive-as-an-r-data-repository.html",
    "title": "Using Google Drive as an R Data Repository",
    "section": "",
    "text": "This is such a common thing to do these days, it is easier to just post this here rather than search through my class notes each time someone asks me how to do this.\nHere is the issue. Say you have some data associated with your research project and are adding to it and doing analyses. Chances are, you have it shoved into an Excel spreadsheet that is on your laptop, your home computer, the computer in the lab, a backup disk (you are keeping backups, right?), and even perhaps shared on a Cloud Drive with your collaborators/advisors/partner/whatever. Great! Now you have absolutely no way to know which version of the dataset is the real one and which are wrong."
  },
  {
    "objectID": "posts/2018-07-19-using-google-drive-as-an-r-data-repository/using-google-drive-as-an-r-data-repository.html#publishing-spreadsheets-from-google-drive",
    "href": "posts/2018-07-19-using-google-drive-as-an-r-data-repository/using-google-drive-as-an-r-data-repository.html#publishing-spreadsheets-from-google-drive",
    "title": "Using Google Drive as an R Data Repository",
    "section": "Publishing Spreadsheets from Google Drive",
    "text": "Publishing Spreadsheets from Google Drive\nIn R, we can use the ability to serve out spreadsheet-like data as *.csv files using Google Drive. This way, the data are in one (and only one) location and can be accessed by anyone you would like to grant access. Here is how to set it up.\nFirst, on Google Drive, you need to tell it to make a spreadsheet available and how to publish it. This is done from the menu as File -> Publish to the Web… A dialog box will pop up, like the one below, and let you select which sheet is published and what it is published as. The salient part here is that you should select **Comma separated values (*.csv)** as the output type. The URL that is provided in the image below should be copied as we will be using it in R to grab the data.\n\n\n\nNext, you can fire up R (I use RStudio as a sane interface) and make sure you have the RCurl library installed. If not, install it like this:\ninstall.packages(\"RCurl\")\nSo to load the file from Google Drive, we need to format the URL from Google Drive\nrequire(RCurl)\nlink <- \"https://docs.google.com/spreadsheets/d/1QL9fYeKkDKphba12WLVTBJrv_d1WHTc9SrZoBeIFgj8/pub?gid=0&single=true&output=csv\"\nurl <- getURL( link )\nThen open an internet connection asking for a text-based communication between Google Drive and your R session\ncon <- textConnection( url )\nand then pull the data into R as if it was on the local filesystem.\ndata <- read.csv( con )\nAnd your data should be there.\nsummary(data)\n\n#   Population       SampleID      X.Coordinate   Y.Coordinate      Cf.G8      \n# Min.   :2.000   Min.   :203.0   Min.   : 346   Min.   : 254   Min.   :147.0  \n# 1st Qu.:3.000   1st Qu.:315.5   1st Qu.:1482   1st Qu.:2231   1st Qu.:155.0  \n# Median :4.000   Median :428.0   Median :1656   Median :2928   Median :157.0  \n# Mean   :3.809   Mean   :428.0   Mean   :1747   Mean   :2588   Mean   :160.3  \n# 3rd Qu.:5.000   3rd Qu.:540.5   3rd Qu.:1914   3rd Qu.:3082   3rd Qu.:165.0  \n# Max.   :6.000   Max.   :653.0   Max.   :3778   Max.   :6148   Max.   :199.0  \n#                                                               NAs   :9      \n#       X           Cf.H18           X.1            Cf.N5            X.2     \n# Min.   :149   Min.   : 83.0   Min.   : 83.0   Min.   :148.0   Min.   :150  \n# 1st Qu.:161   1st Qu.: 99.0   1st Qu.:107.0   1st Qu.:165.0   1st Qu.:170  \n# Median :167   Median :105.0   Median :115.0   Median :170.0   Median :170  \n# Mean   :172   Mean   :104.5   Mean   :112.8   Mean   :167.7   Mean   :170  \n# 3rd Qu.:181   3rd Qu.:111.0   3rd Qu.:119.0   3rd Qu.:170.0   3rd Qu.:170  \n# Max.   :519   Max.   :123.0   Max.   :123.0   Max.   :172.0   Max.   :172  \n# NAs   :9     NAs   :1       NAs   :1       NAs   :36      NAs   :36   \n#     Cf.N10           X.3            Cf.O5            X.4       \n Min.   :171.0   Min.   :175.0   Min.   :176.0   Min.   :176.0  \n# 1st Qu.:187.0   1st Qu.:193.0   1st Qu.:178.0   1st Qu.:182.0  \n Median :189.0   Median :197.0   Median :182.0   Median :194.0  \n# Mean   :189.4   Mean   :196.3   Mean   :182.5   Mean   :190.3  \n 3rd Qu.:193.0   3rd Qu.:201.0   3rd Qu.:182.0   3rd Qu.:196.0  \n# Max.   :205.0   Max.   :205.0   Max.   :202.0   Max.   :204.0  \n NAs   :13      NAs   :13      NAs   :8       NAs   :8"
  },
  {
    "objectID": "posts/2015-03-26-color-palettes-in-ggpairs/color-palettes-in-ggpairs.html",
    "href": "posts/2015-03-26-color-palettes-in-ggpairs/color-palettes-in-ggpairs.html",
    "title": "Color palettes in ggpairs",
    "section": "",
    "text": "Working on some code and was having a tough time configuring the color palette in GGally since it does not produce a ggplot object. It appears to be a larger problem. So, here is one hack, redefine the ggplot function and change the default palette there. Need to make a dyerlab::palette now…\nggplot <- function(...) ggplot2::ggplot(...) + scale_color_brewer(palette=\"Set1\")\nunlockBinding(\"ggplot\",parent.env(asNamespace(\"GGally\")))\nassign(\"ggplot\",ggplot,parent.env(asNamespace(\"GGally\")))\nrequire(GGally)\nggpairs(df,columns = 3:7,axisLabels=\"none\",color=\"color\")"
  },
  {
    "objectID": "posts/2018-06-20-the-atom-editor/the-atom-editor.html",
    "href": "posts/2018-06-20-the-atom-editor/the-atom-editor.html",
    "title": "The Atom Editor",
    "section": "",
    "text": "Being new to the Windows platform, I’m on the look for a good text editor that can do the myriad of tasks that we do each day. Notepad is not an option, let’s be real. I’m looking for something that can be extended and has been designed from the bottom up for wrangling text and writing code. Ultimately, I would like something that is amenable to teaching both R and Python using a single interface. RStudio is great for R but sucks for Python. Juypter notebooks are clunky and toy-like.\n\n\n\n\n\nAtom is created by the Github folks and is integrated into ‘the mothership’ repository. Here is what I did to get it up and running and having Python running correctly.\n\n\n\n\n\nPackages\n\n\n\n\n\nPackages are extensions to the main editor that accomplish some function to make you life a bit easier. Here are some of the ones I find helpful. You can find packages and install them using Settings -> Install. Then search for the packages and hit the install button.\n\n\n\n\n\nMinimap\n\n\n\n\n\nIf you have scripts and/or code that is longer than a single page (and who doesn’t) minimap provides a graphical depiction of your code on the right-hand side of the window to allow you to easily jump up and down the file. Here is an example on an R script.\n\n\n\n\n\n\n\n\n\n\n\nScript\n\n\n\n\n\nScript is a package that runs code in the editor directly. This means you can run individual lines as you develop and look at the output. Very helpful.\n\n\n\n\n\nThemes\n\n\n\n\n\nThere are a ton of themes, both overall for the editor as well as syntax highlighting, available. To install one, select Install -> Theme and type a name from Settings. Here is the atom-material-syntax being installed.\n\n\n\n\n\n\n\n\n\n\n\nOnce installed, you can change both the UI and the syntax colors.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs I expand more into using Atom, I’ll add additional posts showing how I have configured it for use in my daily coding activities."
  },
  {
    "objectID": "posts/2016-07-08-collab-slack-r/collab-slack-r.html",
    "href": "posts/2016-07-08-collab-slack-r/collab-slack-r.html",
    "title": "Collab Slack R",
    "section": "",
    "text": "I just ran across an R package that allows you to integrate your R workflow into the Slack environment. Really cool. Below I show how to set it up and to post output of your analyses to slack channels for your team as well as to register notifications.\n\n\nFirst things first, I recommend installing the latest version from the github repository.\nlibrary(devtools)\ninstall_github(\"hrbrmstr/slackr\")\n\nNow you have to set up a config file. I think it looks for it in ~/.slackr It is a normal Debian Control File (DCF) format. Here is my example one:\napi_token: xoxp-XXXXXXXXXXX-XXXXXXXXX-XXXXXXXXXX-XXXXXXXXX\nchannel: #r\nusername: rodney\nincoming_webhook_url: https://hooks.slack.com/services/XXXXXXXX/XXXXXXXX/XXXXXXXX\nYou need to get the api_token and the incoming_webhook_url from slack itself. Once you have that file saved, when you want to setup the slackr environment, you load it in and can send messages such as:\nrequire(slackr)\nslackr_setup()\nslackr(\"This is an incoming piece of text from RStudio\")\nWhich results in the following in my #r slack channel:\n\nThere is also a provision for sending output graphics like ggplot objects. Here is an example of heterozygosity in the Arapat data set.\nlibrary(gstudio)\nlibrary(ggplot2)\ndata(arapat)\nhe <- genetic_diversity(arapat,mode=\"He\")\np <- ggplot( he, aes(x=Locus, y=He)) + geom_bar(stat=\"identity\") + theme_bw()\nggslack(p)\n\nWhich directly uploads the image to the channel as:\n\nVery Cool!\n\nThere is a slight problem though. The current version of the slackr library has an error in it associated with (perhaps) a recent change in the Slack API that has not been fixed by the developer.\nFor me to get this to work, I had to compile the package myself after making the following change in one file. To fix it, do the following:\n\nDownload (or checkout) the repository from github at: https://github.com/hrbrmstr/slackr\nOpen the project in RStudio\nOpen the R file names slackr_utils.R\nIn the function named slackr_ims the last line (line 117) is something like dplyr::left_join( %some stuff% )\nReplace this line with suppressWarnings( merge(users, ims, by.x=”id”, by.y=‘user’) )\nThe compile and install the package as:\nrequire(devtools)\nload_all()\nbuild()\ninstall()\n\nIt should work just fine.\n\nHopefully, on the next time that this package is updated by the author, the left_join() problem will have been resolved. This issue had been marked as “resolved” in the github issues a while back but apparently not pushed to the repository."
  },
  {
    "objectID": "posts/2015-07-30-installing-r-packages-from-github/installing-r-packages-from-github.html",
    "href": "posts/2015-07-30-installing-r-packages-from-github/installing-r-packages-from-github.html",
    "title": "Installing R packages from github",
    "section": "",
    "text": "The default CRAN repository is not the only place that R packages are stored. You can also find them on github. When I develop libraries for R, I typically develop them on http://github.com/dyerlab and then upload them to CRAN when I get to major milestones. The latest versions of all my software will always be found on github. So here is how to install packages directly.\nTo install from github directly, you need two things, the devtools library and the repository and project name on github that you’ll be installing from. As always, it is a great idea to update everything (latest version of R and packages via update.packages(ask=FALSE)) before you start.\n\nIn R, type install.packages(\"devtools\") and it will go grab the stuff for you. If you are on a machine that does not have compilers and other developers tools on it, R will tell you to go download the RTools package and install it. They give you a URL to follow and a function to test the installation with. Use it.\nrequire(devtools)\nAssuming you are using my account (dyerlab) and installing the gstudio package, you would then type: install_github(\"dyerlab/gstudio\").\nDone."
  },
  {
    "objectID": "posts/2013-10-10-unix-basics/unix-basics.html",
    "href": "posts/2013-10-10-unix-basics/unix-basics.html",
    "title": "Unix Basics",
    "section": "",
    "text": "This covers some basic unix commands so that you can log into a machine and move around in it with ease. It is by no means comprehensive.\n\nLogging In\nTo log into a machine you must use SSH. This is a secure shell and is encrypted on both ends so that others cannot snoop on your passwords or activities. If you are a windows person (shudder), you will have to use a GUI application to log into the server. Download one and install it. The server we will be using in this exercise is:\n\nchesapeake.envs.vcu.edu\nand can also be referenced by the raw IP address as:\n\n\n128.172.178.27\nBoth of these addresses are the same. You will need both a user name and password on the server before you can log into it.\nIf you are outside VCU network, you will have to log into our VPN (see vcu.edu and search for webvpn if you do not know how to do this). On a mac/unix/linux box, you can use the terminal application to log into the server as:\n\n\nssh chesapeake.envs.vcu.edu\nor with the raw IP address. Note: if you have a user name that is different on your local machine than it is on the server, you need to specify that in the ssh call as:\n\n\nssh server_user_id@chesapeake.envs.vcu.edu\nOnce you log into the remote server you will be greeted with a prompt from which you will be able to interact with the computer directly (e.g., no need for gui-pointy-clicky stuff).\n\n\n\nBash\nWhen you are logged into the server, you are actually working in an interactive programming environment. By default, the dyerlab servers run the Bash Shell. This is a command line interface that has the ability to do quite a few things that reduce the amount of tedium in your computational life. The entire philosophy of unix is to provide an environment where:\n\nThere is a strict partition between the stuff that you do in your own account and the stuff others do. Security at the OS level is priority number one and as such has a fairly strict set of requirements for what you as a user can see and do. This is good.\nThings work well together. Programs are small. There is no monolithic program that tries to do everything (except emacs but that is a flamewar of a different type). Programs do one type of task and do not try to multitask. This is very good because we have evolved an ecosystem of programs that are very efficient.\nIt is assumed that unix programs read and write text files, not binary files. It goes against the philosophy of the OS for a program to sequester its data into formats that are unreachable by other programs. If a program does this then it is no longer a citizen of the unix program community and as such has cut itself off from the breadth of opportunities that such an interaction entails. This is a very very good thing because you as a user can build complicated workflows in the environment that achieve things that would take much longer in the normal clickity-clickity mouse world we typically inhabit.\n\n\n\nBasic Commands\nTo move around a unix box on a server you are not in front of, you must do it from the command line. You will always be logged into your ‘home’ account. This is literally at the location in the file system /home/your_user_name. Everyone has their own home directory and you cannot see what is in other peoples home directories unless they do some rather severe hacks (violating #1 above). However, there are places you can put stuff to share materials between users, it is just not within the home directory. Here is an overview of some basic commands. You can always find out where you are by typing:\n\n\n\n\n\nProgram\n\n\nDescription\n\n\n\n\npwd\n\n\nPrints out the current directory you are in.\n\n\n\n\nls\n\n\nLists the files and folders in that directory (see ls -l for a long listing)\n\n\n\n\ncd\n\n\nChange to your home directory\n\n\n\n\ncd ..\n\n\nChanges to directory that is the immediate parent of the current one\n\n\n\n\ncd folder\n\n\nChanges the directory to ‘folder’\n\n\n\n\nexit\n\n\nLogs you out of the computer\n\n\n\n\nchmod\n\n\nChanges the permission/privileges for files.\n\n\n\n\necho\n\n\nPrints out variables/content to the shell output\n\n\n\n\ncat\n\n\nConcatenates text to the terminal output\n\n\n\n\nhead\n\n\nPrints out the top lines of a file\n\n\n\n\nwc\n\n\nCounts words (default) or lines (-l) in a file\n\n\n\n\ngrep\n\n\nGets a regular expression (e.g., used for text searching)\n\n\n\n\nAlmost all programs (pwd, ls, cd, etc.) have a manual associated with them. This is because there are often many options to modify the behavior of the output. You can get to the manual for any program by:\n\nman prog\nAll manual entries have the same format and go through all the options available.\n\n\n\nEditing Files\nThere is a plethora of editors available to the unix user. Perhaps the easiest one on the servers you’ll be using is nano. This is a simple editor that allows you to open, change, and save text files. Given that this is a command-line environment, the menu-like options are available via keyboard combinations indicated at the bottom of the screen. In most unix environments the symbol ‘^’ denotes the control key (e.g., ^-Q would be holding down the control key and typing Q), and ‘M’ denotes the key labelled ‘alt’ (the modifier key). In nano these combinations act as the menu functionality.\nTo start an editing session type:\n\nnano\nand it will make a new file. If you have an existing file, you can edit it as:\n\n\nnano myfile.fasta\nfor example and it will open it up and start you on an editing session.\n\n\n\nPutting and Getting Files\nTo move documents from your computer to a remote server, we use the SSH Copy command ‘scp’. This is built into the ssh software itself.\n\nscp file remoteserver:~/\nThe last part, ‘:~/’ is required as it tells scp that the remoteserver is a server and you want the file to go into your home directory ‘~/’\n\n\nscp myremoteserver:~/thefile .\nThis will pull a file from the remote server to your current directory. Again notice that the period is there, a period in the options to a program specifically means ‘this place in the directory heirarchy.’\nIf you are using windows, there is a GUI drag and drop interface with your SSH client.\n\n\n\nRunning a Command Line Program\nOn a server all programs are run from the command line. You have already seen that you can run a program by typing its name and hitting return. The only reason this works is because there are executable binary files located in specific directories on the machine. These directories are all called ‘bin’ and they are located in parts of the folder heirarchy dictating who can access them. If you type at the command prompt:\n\necho $PATH\nit will return all the bin files that you are, by default, able to search for programs. The program echo prints out the value of a variable and all Bash Shell variables are indicated by a dollar sign (and by convention are typed in all upcase).\nIf a program is not in a ‘bin’ folder you access it will not run when you simply type its name. What you have to do is to tell the Bash Shell the location of the program specifically, even if it is in the same directory as you are.\nThere is one more requirement to execute a program. The program must be labelled as something that can be executed! In unix, scripts such as Bash Scripts, perl, python, lua, and many other languages can be used to make programs but these programs are just text files containing the instructions necessary to perform a task. To designate a program as a specific one that can be executed (if its contents actually can do something) you need to set the executable bit on the file by changing the mode of the file. This is done using chmod and telling it to add executable privileges.\n\n\nchmod +x program_file\nMany things have executable privileges, try a ls -l and look at the far left column to see the privileges, the last digit is either x or – indicating executable status or not (n.b., folders are executable, if you turn it off you will not be able to change directory into that folder).\n\n\n\nRedirecting Output\nAs mentioned above, programs are small and do specialized things but can work together in ways that are quite dynamic. This is done by redirecting output. Here are some examples. In the directory /usr/share/velvet_1.2.10/data, there are several example fasta files that come with velvet. Copy the test_reference.fa file to your directory as:\n\ncp /usr/share/velvet_1.2.10/data/test_reads.fa .\nYou should be able to see this file in your directory (via ls). Lets count how many lines are in that file. I see the following output (yours will be a bit different because you are not in my home directory (all the stuff to the left of the $ is not typed and is part of the bash prompt).\n\n\nrodney@chesapeake ~ $ wc -l test_reads.fa\n\n\n285716 test_reads.fa\nSo this file has 285,716 lines in it. Lets now look at the first few lines:\n\n\n>SEQUENCE_0_length_35\n\n\nGGATATAGGGCCAACCCAACTCAACGGCCTGTCTT\n\n\n>SEQUENCE_1_length_35\n\n\nCGACGAATGACAGGTCACGAATTTGGCGGGGATTA\n\n\n>SEQUENCE_2_length_35\n\n\nCCAAATAGGTCCTTACATCATGAGACGGGCCAAAT\n\n\n>SEQUENCE_3_length_35\n\n\nCGAGATGTATACCTCTAACACTGTGTTCCAAGTAC\n\n\n>SEQUENCE_4_length_35\n\n\nAAGCTCCCGCAATGGATCTTGTGACGGGCTGCTCG\nThis output is dumped to the terminal. To redirect this output to another place, say a file, we use the redirect operator ‘>’ otherwise known as the greater than sign.\n\n\nrodney@chesapeake ~ $ head test_reads.fa > firstfew.fa\n\n\nrodney@chesapeake ~ $ wc -l firstfew.fa\n\n\n10 firstfew.fa\n\n\n\nPiping Between Programs\nHooking together programs is the next step and it is called piping. It is accomplished by hooking together the output of one program with the input of another using the pipe character ‘|’ (the vertical line on the slash key on US english keyboards). Lets say I wanted to search for a particular sequence in the test_reads.fa file. I’ll use GATACA because it was a good movie. I use the grep command to find it by passing first what I am looking for and then the file I am looking for it in. I will then pipe this through the wc program to see how many lines have that sequence of nucleotides within it.\n\nrodney@chesapeake ~ $ grep GATACA test_reads.fa | wc -l\n\n\n790\nSo there are almost 800 reads with that sequence in it. We can continue to combine commands together beyond just these two. See if you can figure out what these commands do:\n\n\nrodney@chesapeake ~ $ cat test_reads.fa | sort | head -100 > sortedfirstfew.fa\n\n\nrodney@chesapeake ~ $ head sortedfirstfew.fa\n\n\nAAAAAAAACGGGCTTATAGACCATGCAGGCTTCAT\n\n\nAAAAAAACACTATACAGCCAGAGTTCCTTCTTCTT\n\n\nAAAAAAACCCTTCTGTGTTTGATCTACCTACTATA\n\n\nAAAAAAACGGGCTTATAGACCATGCAGGCTTCATG\n\n\nAAAAAAACGTAAGGAGCGTTTATGCCAAACGAAGA\n\n\nAAAAAAAGGCTCGTGACTGTCATCATCGAGACGCC\n\n\nAAAAAAAGTGGGGTTCAAACACTCTATCCATGAAG\n\n\nAAAAAAATTGACTGTTAATGGCAATTTCAAGTTAT\n\n\nAAAAAACAGCGAACCAGATCTTATTTTGCTTCTAC\n\n\nAAAAAACATGACAACGAGAGCAACCCGGGCATTTG\n\n\n\nScreen\nOK, so when working on long-running programs, there is the need to be able to log in and out of a session without the various things you have running stopping each time. When you log into a unix machine, you start a ‘session’ and you can log in many times using the same user ID. When you log out, every process (running program) is purged from the memory and thus lost. So unless you plan on being logged into a terminal until a long running process is done running (some may take months), a better solution is needed. This is where a program called ‘screen’ comes in handy.\nScreen is a program that is run after you log into the server. What this does is to then make a ‘virtual session’ (or many of them) that you can attach and detach your terminal session to. You start screen by typing:\n\nscreen\nand then a read the verbage and continue (via space bar or hitting return). After that it will look like your normal terminal session and you’ll be able to do whatever you want to do just like before. Screen is running in the background\nSo lets say you start a long running process like:\n\n\n./VelvetOptimiser.pl -s 16 -e 31 -f “-short -raw ~/data/pedima/pedimaSNPs.fasta”\nThis can take a while to run. Now that you are already within a screen session, you can run it and then detach your terminal from that screen session. After you detach, the program will continue running just as before and you can re-attach at a later time to check on progress.\nHere are the commands for listing, attaching, and detaching from screen sessions (n.b., they all start with CTRL+a followed by another letter.\n\n\n\n\nKeys\n\n\nDescription\n\n\n\n\nCTRL+a c\n\n\nCreates a new shell window\n\n\n\n\nCTRL+a k\n\n\nKills the current window\n\n\n\n\nCTRL+a w\n\n\nLists all windows (the current session is marked with an ’*’)\n\n\n\n\nCTRL+a d\n\n\nDetach from current session\n\n\n\n\nCTRL+a D\n\n\nDetach from current session and close the shell as well\n\n\n\n\nCTRL+a 0-9\n\n\nGo to session 0, 1, … 9\n\n\n\n\nAfter you detach (CTRL+a d) you can exit the server and when you come back, you can reattach as:\n\n\nscreen -r\nif you only have one screen session going, otherwise you can just start screen, list the open sessions, and then come back at that time.\n\n\n\nVelvet\nLink to UMissouri\nhttp://umbc.rnet.missouri.edu/resources/How2RunVELVETonClark.html\nFrom NCBI: A basic protocol\nhttp://www.ncbi.nlm.nih.gov/pmc/articles/PMC2952100/"
  },
  {
    "objectID": "posts/2018-07-19-poisonous-plants-in-the-commonwealth/poisonous-plants-in-the-commonwealth.html",
    "href": "posts/2018-07-19-poisonous-plants-in-the-commonwealth/poisonous-plants-in-the-commonwealth.html",
    "title": "Poisonous Plants in the Commonwealth",
    "section": "",
    "text": "This past summer has seen some rather spectacular cases of where people have run afoul of dangerous flora, the most recent of which was a college student after a runin with Giant Hogweed–the results were not good."
  },
  {
    "objectID": "posts/2018-07-19-poisonous-plants-in-the-commonwealth/poisonous-plants-in-the-commonwealth.html#information",
    "href": "posts/2018-07-19-poisonous-plants-in-the-commonwealth/poisonous-plants-in-the-commonwealth.html#information",
    "title": "Poisonous Plants in the Commonwealth",
    "section": "Information",
    "text": "Information\nThe Virginia Tech Cooperative Extension group publishes a nice overview of toxic plants in the Commonwealth. It has some useful information in that all of us should be aware of."
  },
  {
    "objectID": "posts/2015-08-25-rva-urban-dogwood/rva-urban-dogwood.html",
    "href": "posts/2015-08-25-rva-urban-dogwood/rva-urban-dogwood.html",
    "title": "RVA Urban Dogwood",
    "section": "",
    "text": "Here is a map of the dogwood we’ve sampled in the Fan region of Richmond Virginia."
  },
  {
    "objectID": "posts/2020-03-12-setting-up-postgresql-on-mac/setting-up-postgresql-on-mac.html",
    "href": "posts/2020-03-12-setting-up-postgresql-on-mac/setting-up-postgresql-on-mac.html",
    "title": "Setting up Postgresql on mac",
    "section": "",
    "text": "This is rather quick and easy to do. On MacOS, make sure you have Homebrew installed and then follow those instructions.\nFor me, it took a few additional steps because I was installing it on a new mac mini (in the home office). I had not made sure everything was up-to-date before starting so I had to walk away for a little bit to let it all happen. No biggie.\nrodney@rodneys-mini ~ % brew install postgis\nError: The following formulae\n  [#<Dependency: \"python\" []>, #<Options: []>] and [#<Dependency: \"gcc\" []>, #<Options: []>]\ncannot be installed as binary packages and must be built from source.\nInstall the Command Line Tools:\n  xcode-select --install\nSo I ran this to install the command line build tools:\nrodney@rodneys-mini ~ % xcode-select --install\nxcode-select: note: install requested for command line developer tools\nThis took several minutes as I had not updated my XCode in a while. No problem though. Then I went back and ran the command again, which installed a ton of dependencies.\nrodney@rodneys-mini ~ % brew install postgis  \n==> Installing dependencies for postgis: cfitsio, popt, epsilon, expat, freexl, gdbm, openssl@1.1, readline, sqlite, xz, python, geos, giflib, gmp, isl, mpfr, libmpc, gcc, szip, hdf5, jpeg, jasper, json-c, libxml2, libdap, libtiff, proj, libgeotiff, libpng, libpq, libspatialite, netcdf, openblas, numpy, pcre, freetype, fontconfig, libffi, glib, lzo, pixman, cairo, little-cms2, nspr, nss, openjpeg, qt, poppler, libtool, unixodbc, webp, xerces-c, zstd, gdal, icu4c, krb5, postgresql, protobuf, protobuf-c, boost, eigen, cgal and sfcgal\nThat took a while."
  },
  {
    "objectID": "posts/2017-03-14-ggproblems/ggproblems.html",
    "href": "posts/2017-03-14-ggproblems/ggproblems.html",
    "title": "ggproblems",
    "section": "",
    "text": "OK, so there is a bit of a circular firing squad going on in some of my R installs with ggplot2. Apparently, you can get various CRAN/Github versions out of sync and a whole host of different. Here is how it started:\n\n\n> df <- data.frame(x=runif(20),y=runif(20),z=runif(20))\n> library(ggtern)\nLoading required package: ggplot2\n--\nConsider donating at: http://ggtern.com\nEven small amounts (say $10-50) are very much appreciated!\nRemember to cite, run citation(package = 'ggtern') for further info.\n--\n\nAttaching package: ‘ggtern’\n\nThe following objects are masked from ‘package:ggplot2’:\n\n    %+%, aes, annotate, calc_element, ggplot, ggplot_build,\n    ggplot_gtable, ggplotGrob, ggsave, layer_data, theme, theme_bw,\n    theme_classic, theme_dark, theme_gray, theme_light, theme_linedraw,\n    theme_minimal, theme_void\n\n> ggtern(df,aes(x,y,z))\nError in f(..., self = self) : unused argument (<environment>)\nhmmm…. Then ggmap also died.\nTo fix this, I did the following:\n\nRemoved ggtern, ggplot2, and ggmap from my library\nInstalled ggplot2 from CRAN\nInstalled ggmap from GitHub\nInstalled ggtern from Bitbucket (why not github, I don’t know).\n\nSeems to work now."
  },
  {
    "objectID": "posts/2018-12-06-jane-remfert-doctoral-candidate/jane-remfert-doctoral-candidate.html",
    "href": "posts/2018-12-06-jane-remfert-doctoral-candidate/jane-remfert-doctoral-candidate.html",
    "title": "Jane Remfert Doctoral Candidate",
    "section": "",
    "text": "Jane Remfert has successfully completed the necessary steps to proceed to Doctoral Candidate by completing her written and oral defense and submitting her research proposal. Thank you to Drs. Eckert, Gough, Johnson, and Keyghobadi for their insightful comments and expertise in helping to shape a dynamic and exciting research project.\nNow, you just have to do it!"
  },
  {
    "objectID": "posts/2016-04-07-presentation-zen/presentation-zen.html",
    "href": "posts/2016-04-07-presentation-zen/presentation-zen.html",
    "title": "Presentation Zen",
    "section": "",
    "text": "Here it is, time for student presentations all around! I thought it would be nice to send this presentation around again to remind everyone what make good (and sucky) presentations. More below the fold."
  },
  {
    "objectID": "posts/2016-06-22-google-drive-038-git/google-drive-038-git.html",
    "href": "posts/2016-06-22-google-drive-038-git/google-drive-038-git.html",
    "title": "Google Drive 038 Git",
    "section": "",
    "text": "I was experiencing a bit of a problem with some conflicting files on google drive and a github repository. I mirror my google drive as my Documents folder and on occassion, I am logged into more than one machine at a time and if you work on the same files without saving, they result in a conflict. I notice this when I got the message.\nOffice-iMac:gstudio rodney$ git pull\nfatal: Reference has invalid format: 'refs/heads/master[Conflict 1]'\n\nAnd then when I looked into my .git folder, I saw\nOffice-iMac:gstudio rodney$ cd .git\nOffice-iMac:.git rodney$ ls\nCOMMIT_EDITMSG index\nCOMMIT_EDITMSG[Conflict 1] index[Conflict 1]\nCOMMIT_EDITMSG[Conflict] index[Conflict 2]\nFETCH_HEAD index[Conflict 3]\nFETCH_HEAD[Conflict 1] index[Conflict 4]\nFETCH_HEAD[Conflict] index[Conflict 5]\nHEAD index[Conflict]\nORIG_HEAD info\nORIG_HEAD[Conflict] logs\nbranches objects\nconfig packed-refs\ndescription refs\nhooks\n\n\nApparently, git does not like square brackets and such in the names. To fix this, you need to do the following.\nfind .git -type f -name \"*Conflict*\" -exec rm -f {} \\;\nAnd then clean up the packed references as:\nawk '!/conflicted/' .git/packed-refs > temp && mv temp .git/packed-refs"
  },
  {
    "objectID": "posts/2022-08-26-Installing-R-Package-From-Source/index.html",
    "href": "posts/2022-08-26-Installing-R-Package-From-Source/index.html",
    "title": "Installing R Packages from Source",
    "section": "",
    "text": "So there are times when you need a package but the normal installation process is not giving you what you want. Either the package is old and hasn’t been updated (and you’ve been keeping up with your working version) or some aspect of the dependency tree is not satisfied.\nHere is the first option. \nBelow is a gist that shows two different ways of getting it. They both require that the package be available as a source file (.tar.gz or .zip) AND that the package is located on CRAN.\n\nProblems:\n\nIf this does not work because it is not on CRAN, then you’ll need to figure out where the source is and install it from there. If it is on GitHub or GitLab, you can use remotes::install_github().\nIf it tries to install but R barfs because of some other package, then you’ll have to go manually install those dependencies yourself."
  },
  {
    "objectID": "posts/2015-08-24-basic-graphics-in-r/basic-graphics-in-r.html",
    "href": "posts/2015-08-24-basic-graphics-in-r/basic-graphics-in-r.html",
    "title": "Basic graphics in R",
    "section": "",
    "text": "Here is a short (39 minute) video of some basic graphics approaches in R I use in a class on population genetics."
  },
  {
    "objectID": "posts/2016-02-05-chapter-2-hardy-weinberg-equilibrium/chapter-2-hardy-weinberg-equilibrium.html",
    "href": "posts/2016-02-05-chapter-2-hardy-weinberg-equilibrium/chapter-2-hardy-weinberg-equilibrium.html",
    "title": "Chapter 2 Hardy Weinberg Equilibrium",
    "section": "",
    "text": "Here are the online presentations for Chapter 2: Hardy Weinberg Equilibrium from the upcoming text, Applied Population Genetics. More information on this text can be found here."
  },
  {
    "objectID": "posts/2015-12-12-life-sciences-graduation/life-sciences-graduation.html",
    "href": "posts/2015-12-12-life-sciences-graduation/life-sciences-graduation.html",
    "title": "Life Sciences Graduation",
    "section": "",
    "text": "Life Sciences Graduation ceremony is here."
  },
  {
    "objectID": "posts/2017-03-02-new-urls/new-urls.html",
    "href": "posts/2017-03-02-new-urls/new-urls.html",
    "title": "New URLs",
    "section": "",
    "text": "This web page is now available as through the following URL’s\nhttp://dyerlab.org\nhttp://dyerlab.com\nbecause the longer URL is too long and confusing.\nhttp://dyerlab.ces.vcu.edu"
  },
  {
    "objectID": "posts/2016-12-10-life-sciences-graduation/life-sciences-graduation.html",
    "href": "posts/2016-12-10-life-sciences-graduation/life-sciences-graduation.html",
    "title": "Life Sciences Graduation",
    "section": "",
    "text": "Pomp and Circumstance\nRecessional"
  },
  {
    "objectID": "posts/2015-12-17-applied-population-genetics-textbook-release/applied-population-genetics-textbook-release.html",
    "href": "posts/2015-12-17-applied-population-genetics-textbook-release/applied-population-genetics-textbook-release.html",
    "title": "Applied Population Genetics Textbook Release",
    "section": "",
    "text": "I will be posting portions of all 10 chapters of my upcoming textbook, Applied Population Genetics, as early draft chapters to this website over the spring semester. \nThis book will be published in both ibook and print-on-demand versions. I prefer the ibook format because I can embed interactive content (movies, JavaScript, etc.) into the text and it will update automatically when I make revisions etc.\nThe drawback is that ibook is limited to OSX and iOS devices at this time—which is why I will also be making it available as a print-on-demand text (though the interactive content will not obviously be included). The complete text is scheduled to be made available by the end of the academic year and I will be using it as the primary source in my Spring courses of Population Genetics BIOL516 and Landscape Genetics ENVS 692\n\n \n\n\n\n\n\n\n\n\nChapter 1: Learning R\n\n\n\nInstallation, Package Management, RStudio, Github\n\n\nData Types\n\n\nData Containers\n\n\nBasic Programming\n\n\nGraphical Output\n\n\n\n\n\n\n\n\n\n\nChapter 2: Hardy-Weinberg Equilibrium\n\n\n\nTheoretical Foundations & Expectations\n\n\nTesting for Hardy-Weinberg Equilibrium\n\n\n\n\n\n\n\n\n\n\nChapter 3: Mutation\n\n\n\nCauses and Consequences\n\n\nEquilibrium Expectations\n\n\nEstimating Mutation Rates\n\n\n\n\n\n\n\n\n\n\nChapter 4: Non-random Mating\n\n\n\nGenetic Linkage\n\n\nInbreeding\n\n\nMixed Mating Systems & Selfing Rates\n\n\nRelatedness\n\n\n\n\n\n\n\n\n\n\nChapter 5: Genetic Drift\n\n\n\nDrift & Structure\n\n\nAllelic & Genotypic Diversity\n\n\nGenetic Effective Population Size\n\n\nRarefaction\n\n\n\n\n\n\n\n\n\n\nChapter 6: Population Subdivision\n\n\n\nGene Frequencies & Gene Flow\n\n\nGenetic Distance\n\n\nGenetic Structure\n\n\n\n\n\n\n\n\n\n\nChapter 7: Selection\n\n\n\nThe Fundamental Theorem of Natural Selection\n\n\nNeutral Theory\n\n\nSelection on Genotypes\n\n\nIdentifying Putative Selection in Outliers & Gradients\n\n\n\n\n\n\n\n\n\n\nChapter 8: Spatial Data\n\n\n\nSpatial Autocorrelation\n\n\nShapefiles in R\n\n\nVector Data\n\n\nRaster Data\n\n\n\n\n\n\n\n\n\n\nChapter 9: Graph Models\n\n\n\nModel Free Networks\n\n\nPopulation Graphs\n\n\nIsolation Models\n\n\n\n\n\n\n\n\n\n\nChapter 10: Parent-Offspring Data\n\n\n\nPedigree Analyses\n\n\nParentage Analysis in Populations\n\n\nPollen Pool Analyses\n\n\n\n\n\n\n\n\n\nAppendices\n\n\n\nData sets in gstudio\n\n\nInstalling GDAL & RGEOS\n\n\nSpatial Projections\n\n\nCustomizing the R Environment\n\n\nAbout the Author"
  },
  {
    "objectID": "posts/2019-03-25-get-map-problems-w-o-google-api/get-map-problems-w-o-google-api.html",
    "href": "posts/2019-03-25-get-map-problems-w-o-google-api/get-map-problems-w-o-google-api.html",
    "title": "get map Problems w o Google API",
    "section": "",
    "text": "There is a persistent problem with the get_map() function now that the google api is required. Even if you ask for source=”stamen” you still get an error asking for the google api. A fix is to do the following:\nlibrary(gstudio)\ndata(arapat)\ncoords <- strata_coordinates(arapat)\nb1 <- c( left = -114.2935,\n         bottom = 23.0757,\n         right = -109.1263,\n         top=  29.32541)\n\nmap <- get_stamenmap( bbox = b1, zoom=7 )\nggmap(map)"
  },
  {
    "objectID": "posts/2016-04-20-rstudio-cheatsheets/rstudio-cheatsheets.html",
    "href": "posts/2016-04-20-rstudio-cheatsheets/rstudio-cheatsheets.html",
    "title": "RStudio Cheatsheets",
    "section": "",
    "text": "Here are some very useful cheat sheets put out by RStudio. A great resource of information!\n\n\nCheatsheets"
  },
  {
    "objectID": "posts/2022-03-18-github-distill-manuscript-automation/github-distill-manuscript-automation.html",
    "href": "posts/2022-03-18-github-distill-manuscript-automation/github-distill-manuscript-automation.html",
    "title": "Github Distill Manuscript Automation",
    "section": "",
    "text": "o, I’ve been having some fun playing around with the Distill for R Markdown package as I work on getting back into research after the “Admin Craptastic” I’ve been doing through. It is a really nice way to create manuscripts and publish content with the help of github and GitHub Pages .\nOne of the things that has been holding me back thought is that I would have to set up a custom script so that the manuscript file itself (when compiled into html) could be moved into a specific folder in the repository that will be served up on GitHub pages. I chose to use the /docs folder and set this up in the settings section of the repository. Once you save it, it looks like this.\nThen, go back to your repository and add the folder and check it into your GitHub repository.\nThe main problems were:"
  },
  {
    "objectID": "posts/2022-03-18-github-distill-manuscript-automation/github-distill-manuscript-automation.html#the-fix",
    "href": "posts/2022-03-18-github-distill-manuscript-automation/github-distill-manuscript-automation.html#the-fix",
    "title": "Github Distill Manuscript Automation",
    "section": "The Fix",
    "text": "The Fix\nSo the fix is to override the knit function directly in the Rmd YAML data. There is an optional argument that you can use to have a custom render function that is called when you hit the “knit” button in RStudio, that has the following syntax.\nknit: (function(inputFile, encoding) { \n  rmarkdown::render(inputFile,\n                    encoding=encoding,\n                    output_file='docs/index.html') })\nNow, if you put that stuff into the YAML, it will auto-magically render it with the correct name and location by itself behind the scenes AND you will still see it in the preview stuff.\nVery cool."
  },
  {
    "objectID": "posts/2015-08-19-welcome-jane-remfert/welcome-jane-remfert.html",
    "href": "posts/2015-08-19-welcome-jane-remfert/welcome-jane-remfert.html",
    "title": "Welcome Jane Remfert",
    "section": "",
    "text": "We have added a new member to our lab, Jane Remfert. She is an incoming ILS PhD Student who is going to work on pollen movement in dogwood. Very exciting!"
  },
  {
    "objectID": "posts/2013-06-03-compiling-r-devel/compiling-r-devel.html",
    "href": "posts/2013-06-03-compiling-r-devel/compiling-r-devel.html",
    "title": "Compiling r-devel",
    "section": "",
    "text": "There are several reasons why, as someone that contributes packages to R, that you should consider using r-devel instead of the latest release. Primary among these reasons are the fact that there may be changes in r-devel that are not in the latest release version and the maintainers will ding you for not using the correct version. For whatever reason, it is a good idea and here are the notes I’ve put together to compile it on OSX (at the time this was written I was using 10.8.3).\n\nRequirements\nFirst among the requirements is the OS X development environment. This includes all the compilers and associated tools you’ll need. You can get these directly from Apple through the App Store.\nYou will also need:\n\nSubversion. This is some very useful software for source code development and collaboration. This can be installed once you install the XCode stuff from Apple. svn is part of the ‘command line tools’ that the package provides. However, it is not automatically installed, you’ll have to do it after installing XCode directly.\ngfortran-4.2X. This is found on the R webpage. Go to the Mac download and then the ‘tools’ directory. Download and install it.\n\n\n\nInstallation\nHere is the general approach I used, that seemed to work.\n\nGrab the latest version of r-devel.It should be noted that there is currently no certificate for this, so you’ll have to believe that there is no malicious code in the bundle.\nsvn checkout https://svn.r-project.org/R/trunk/ r-devel\nGrab the recommended packages that are not part of the r-devel distribution (you’ll need these or things will go pear shaped).\n./tools/rsync-recommended\nIf you are using OSX Mavericks, you may need to install the command line tools first (this only needs to be done once). Type this:\nxcode-select --install\nConfigure the compilation. I just grabbed these options from the default ones the binary OSX version uses.\n./configure 'CFLAGS=-mtune=core2 -g -O2' 'CXXFLAGS=-mtune=core2 -g -O2' 'OBJCFLAGS=-mtune=core2 -g -O2' 'FCFLAGS=-g -O2' 'F77FLAGS=-g -O2' '--with-system-zlib' '--enable-memory-profiling' '--disable-openmp' '--with-tcltk=/usr/local/lib' --with-x=no\nMake the base packages\nmake\nCheck the compilation for any potential errors.\nmake check\nMake the vignettes\nmake vignettes\nMake the manuals (an optional part here but if you are going to go through all this, you might as well do it completely). I compile them as PDF.\nmake pdf\nInstall it\n$ sudo make install\n\n\n\nUpdating\nOne of the benefits of having a svn repository locally is that you can just update it the next time that you need it and rebuild the components that have changed. To update the repository simply issue the following command in the directory with the r-devel folder.\nsvn up\nThen you can rebuild as outlined above."
  },
  {
    "objectID": "posts/2016-02-19-effective-population-size/effective-population-size.html",
    "href": "posts/2016-02-19-effective-population-size/effective-population-size.html",
    "title": "Effective Population Size",
    "section": "",
    "text": "How big is the data set you are analyzing? Apparently it depends on how you count…"
  },
  {
    "objectID": "posts/2013-09-14-diluting-primers/diluting-primers.html",
    "href": "posts/2013-09-14-diluting-primers/diluting-primers.html",
    "title": "Diluting Primers",
    "section": "",
    "text": "To dilute primers for PCR, you need to first make a 100µM stock solution. To accomplish this, you find the number of nMol on the tube and add 10X that much water in µl. This is your stock solution. Then for your working solution, dilute it to 10µM and work with that one."
  },
  {
    "objectID": "posts/2022-10-28-SwiftPackageManagerResources/index.html",
    "href": "posts/2022-10-28-SwiftPackageManagerResources/index.html",
    "title": "Resources in Swift Package Manager",
    "section": "",
    "text": "The Swift Package Manager is a great tool to wrap up code and help compartmentalize some of your data. It is still evolving but is really powerful. I ran into a few issues when trying to figure out how to add image resources to a package.\nHere are the ways that I used to figure this out."
  },
  {
    "objectID": "posts/2022-10-28-SwiftPackageManagerResources/index.html#still-not-working",
    "href": "posts/2022-10-28-SwiftPackageManagerResources/index.html#still-not-working",
    "title": "Resources in Swift Package Manager",
    "section": "Still Not Working",
    "text": "Still Not Working\nOK, so this is still not working. I didn’t get the error when compiling and testing on MacOS target, but I do when compiling for iOS. Apparetly, the best way to do it is to specify the items in the Resources directly explicitly.\nThe following does actually work!\n        .target(\n            name: \"DLab\",\n            dependencies: [],\n            resources: [\n                .copy(\"Resources/tree.png\")\n            ]\n        ),\nNow it does work. And if you need to have additional items, they need to go into their own .copy() framework."
  },
  {
    "objectID": "posts/2020-02-27-remferts-dogwood-presentation-at-the-research-showcase/remferts-dogwood-presentation-at-the-research-showcase.html",
    "href": "posts/2020-02-27-remferts-dogwood-presentation-at-the-research-showcase/remferts-dogwood-presentation-at-the-research-showcase.html",
    "title": "Remferts Dogwood Presentation at the Research Showcase",
    "section": "",
    "text": "Jane Remfert opened the Integrative Life Sciences Research Symposium this year with her presentation on Cultivar Gene Escape."
  },
  {
    "objectID": "posts/2022-09-01-markdown/index.html",
    "href": "posts/2022-09-01-markdown/index.html",
    "title": "Markdown in the Classroom",
    "section": "",
    "text": "Today I will be working on explaining how to use basic markdown to the Data Literacy class. This is a critical component of understanding basic data literacy as it is a foundation for reproducible research.\nThis year I am using GitHub Classroom as a main teaching tool and each of the componetns of the class are being represented as their own individual repository. For this topic, I have two different repositories.\n\nQuarto the document processing system\nMarkdown syntax\n\nThe basic format of these repositories contains basic learning objectives, content in the form of slide sets and a larger narrative document, external resources, etc.\n\nWe shall see how this goes."
  },
  {
    "objectID": "posts/2016-04-12-point-and-click-theme-editing-for-ggplot/point-and-click-theme-editing-for-ggplot.html",
    "href": "posts/2016-04-12-point-and-click-theme-editing-for-ggplot/point-and-click-theme-editing-for-ggplot.html",
    "title": "Point And Click Theme Editing for ggplot",
    "section": "",
    "text": "This may help you understand customizing themes in ggplot much better.\n\nCheck out https://github.com/calligross/ggthemeassist"
  },
  {
    "objectID": "posts/2022-09-06-Basic-Data-Types/index.html",
    "href": "posts/2022-09-06-Basic-Data-Types/index.html",
    "title": "Basic R Data Types",
    "section": "",
    "text": "So today, we started the work on Basic Data Types in R. I am looking at simplifying things a bit and just starting with a working knowledge of some of the most common data types we use, including:\n\nMissing data NA\nNumeric data\nCharacter data\nLogical data\nDates & Time\n\nThe homework for this activity will focus on use of variable creation, data assignment, coercion, introspection, and some simple operations on the each of the data types."
  },
  {
    "objectID": "posts/2016-03-18-cropping-rasters/cropping-rasters.html",
    "href": "posts/2016-03-18-cropping-rasters/cropping-rasters.html",
    "title": "Cropping Rasters",
    "section": "",
    "text": "It is often the case that the raster we are working with is not the exact size of the area from which our data are collected. It is a much easier situation if the raster is larger than the area than if you need to stitch together two raster Tiles to get all your data onto one extent. In my doctoral thesis work, the area of the southern Ozark mountains that my sites were in was not only straddling a boundary between existing rasters, it was also at the boundary of two UTM zones! What a pain.\n\nSpatial data often consists of very large datasets. One way to minimize the amount of computational resources you are going to use in R is to select only the spatial regions (extents) that you are working in and get rid of the remaining data. This is particularly important if you are going to be doing isolation modeling for genetic connectivity as the cost surface raster needs to be translated into a connectivity network. Data outside your area of interest are unnecessarily taking both resources and time away from your work.\nTo crop a raster, we need to identify the region we wish to keep as an extent object. An extent is a vector of length 4 defined as c(xmin, xmax, ymin, ymax) describing the boundaries of are of interest.\nHere is an extent for the arapat data set.\n\n\n<pre class=\"lang:r decode:true\">require(gstudio)\ndata(arapat) lon.min <- min(arapat\\(Longitude) lon.max <- max(arapat\\)Longitude) lat.min <- min(arapat\\(Latitude) lat.max <- max(arapat\\)Latitude) e <- extent( lon.min, lon.max, lat.min, lat.max ) e ## class: Extent ## xmin: -114.2935 ## xmax: -109.1263 ## ymin: 23.0757 ## ymax: 29.32541\n\n<p>\n  This is the exact boundaries of the data set. However, it is probably a good idea to not have your map cropped exactly to your boundaries but have your most extreme locations plotted within the map boundaries. So I’ll take an approximation (rounding up and down as necessary) to use.\n</p>\n\n<pre class=\"lang:r decode:true\">e <- extent( -115, -108, 23, 30 )\ne ## class: Extent ## xmin: -115 ## xmax: -108 ## ymin: 23 ## ymax: 30\n\n<p>\n  This can now be used as the area from within the alt raster that we want to keep.\n</p>\n\n<pre class=\"lang:r decode:true\">bc <- crop( alt, e )\nbc ## class : RasterLayer ## dimensions : 840, 840, 705600 (nrow, ncol, ncell) ## resolution : 0.008333333, 0.008333333 (x, y) ## extent : -115, -108, 23, 30 (xmin, xmax, ymin, ymax) ## coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 ## data source : in memory ## names : alt_22 ## values : -202, 2774 (min, max)\n\n<p>\n  And if we plot it, we see that it is more properly scaled for the region we are interested in working on.\n</p>\n\n<pre class=\"lang:r decode:true \">plot(bc)</pre>\n\n<p>\n  <img class=\"aligncenter wp-image-865 size-large\" src=\"wp-content/uploads/2016/03/Screen-Shot-2016-03-18-at-1.33.39-PM-1-1024x604.png\" alt=\"Screen Shot 2016-03-18 at 1.33.39 PM\" width=\"768\" height=\"453\" srcset=\"wp-content/uploads/2016/03/Screen-Shot-2016-03-18-at-1.33.39-PM-1-1024x604.png 1024w, wp-content/uploads/2016/03/Screen-Shot-2016-03-18-at-1.33.39-PM-1-300x177.png 300w, wp-content/uploads/2016/03/Screen-Shot-2016-03-18-at-1.33.39-PM-1-768x453.png 768w, wp-content/uploads/2016/03/Screen-Shot-2016-03-18-at-1.33.39-PM-1.png 1552w\" sizes=\"(max-width: 768px) 100vw, 768px\" />\n</p>"
  },
  {
    "objectID": "posts/2016-02-20-envs-orientation/envs-orientation.html",
    "href": "posts/2016-02-20-envs-orientation/envs-orientation.html",
    "title": "ENVS Orientation",
    "section": "",
    "text": "Welcome potential Environmental Studies students"
  },
  {
    "objectID": "posts/2023-02-16-Runing-freebayes/index.html",
    "href": "posts/2023-02-16-Runing-freebayes/index.html",
    "title": "Running freebayes",
    "section": "",
    "text": "As a first pass through the data, I split individual sequences into different groups to run bwa. This works on an individual-by-individual basis and with 5% of each individuals genome takes roughly 30 minutes per individual (*1419 individuals …). Doing it in smaller groups allows me to run multiple instances at the same time. See the table here for the groups and current status. At the time of this writing, this process is still waiting on the final 6 groups of samples to be processed.\nFor a subset of the data, I did call SNPs at the same time that"
  },
  {
    "objectID": "posts/2023-02-16-Runing-freebayes/index.html#batching-freebayes",
    "href": "posts/2023-02-16-Runing-freebayes/index.html#batching-freebayes",
    "title": "Running freebayes",
    "section": "Batching freebayes",
    "text": "Batching freebayes\nTo batch these I made a new directory called snpcalling and linked the bam files from a set of indiviudals in several different populations to this folder.\n\nfor bam in ../samples/O/*.bam; do  \n  ln -s $bam; \ndone\n\nI then made a small runFreeBayes.sh run file that would\n\n#!/bin/bash\nref=\"../samples/all005/reference.fasta\"\nls *.bam > bam.fofn\nfreebayes --fasta-reference ${ref} --bam-list bam.fofn --vcf Output.vcf\n\nI then made it executable\n\nchmod +x runFreeBayes.sh\n\nAnd made a slurm batch file freebayes.sub which contains\n\n#!/bin/bash\n#SBATCH -N 1\n#SBATCH -n 36\n#SBATCH -t 96:00:00\n#SBATCH -J freebayesbaby\n#SBATCH -o freebayes.o%j\n#SBATCH -e freebayes.e%j\n#SBATCH --mail-user=rjdyer@vcu.edu\n#SBATCH --mail-type=ALL\nulimit -s unlimited\n./runFreeBayes.sh\nscontrol show job $SLURM_JOB_ID\n\nand then dumped it off for batch processing\n\nsbatch freebayes.sub\n\nAfter this, you can see that the batch job has been queued up (#34827) and waiting to go.\n[rjdyer@huff snpcalling]$ squeue\n  JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n  34827     basic freebaye   rjdyer PD       0:00      1 (Priority)\nSo, now lets see if it actually works."
  },
  {
    "objectID": "posts/2016-04-05-structure-on-osx/structure-on-osx.html",
    "href": "posts/2016-04-05-structure-on-osx/structure-on-osx.html",
    "title": "STRUCTURE on OSX",
    "section": "",
    "text": "The program STRUCTURE is an ubiquitous feature of many population genetic studies these days—if it is appropriate is another question. Today, while covering model based clustering in population genetics, we ran into a problem where STRUCTURE was unable to run and the OS said it was Corrupted and should be thrown away. Jump below for our fix, it really is an easy one.\n\nThe most recent version of the GUI STRUCTURE java package dates from 2012. This is getting a bit long in the tooth, but when teaching it is not that far fetched to have aged laptops…\nThe error we were running into is the prompted with the following dialog box when attempting to start the program.\n\n\n\nLies about damaged\n\n\nAs it turns out, sometime between 2012 and now, OSX has moved towards digitally signing applications and in this case, it is not that it is “damaged” it just won’t allow the Java Runtime to run it unless we make a small change in the preferences panel and select the Security & Privacy option.\n\n\n\nSecurity Settings\n\n\nThen authenticate on the bottom by clicking on the lock and entering your password.\n\n\n\nClick to Authenticate\n\n\nNow, change the setting on the Allow apps downloaded from to the Anywhere option.\n\n\n\nChange to Allow from Anyone Temporarily\n\n\nThis should allow you to start STRUCTURE and run it. Do that and then close it. Go back to the System Preferences and turn it back to what you had it before.\n\n\n\nChange back\n\n\nOnce you run it once, you will be able to run it again without lowering your security. Happy clustering!"
  },
  {
    "objectID": "posts/2016-03-18-raster-plotting/raster-plotting.html",
    "href": "posts/2016-03-18-raster-plotting/raster-plotting.html",
    "title": "Raster Plotting",
    "section": "",
    "text": "A raster is essentially an image, whose pixel size correspond to a particular spatial extent and the data contained within each pixel represents a particular feature on the landscape. Common rasters are DEM’s (measuring elevation), rainfall, temperature, buildings, etc. In R, it is common to think of rasters as matrices whose values measure some feature on the landscape. In this section, we will examine how to acquire, load, manipulate, and extract data from raster objects.\n\nAs mentioned above, a raster is essentially a matrix with some additional data added onto it related to the spatial extent of the values it contains. As such, we can easily start with a general matrix, perform various matrix manipulations, and then transform it into a raster object when we need it to have spatial properties and attributes. Here is an example of a basic matrix, whose values have been set to random normal variables (mean=0, sd=1) and then plot using the normal R plotting functions.\nx <- matrix(rnorm(100),ncol=10)\nimage(x)\n\n\nYou can see that despite the origin of a matrix when we write it (and when you work with the row and column indices in R on it) is different than when we plot it. Two things should be noted:\n\nThe axes from image() are not very helpful as they are scaled to the fractional width of the matrix rather than the number of rows and columns. This is apparently the preferred behavior from the people who wrote the original R graphics package.\nThe aspect ratio of the cells (e.g., each cell width and height) are not the same. This is problematic if we are intending these data to represent spatial content.\n\nThis matrix can be ‘decorated’ with additional attributes and turned into a raster object by casting it as one using the raster() function.\nrequire(raster)\nr <- raster( x )\nr\n## class : RasterLayer\n## dimensions : 10, 10, 100 (nrow, ncol, ncell)\n## resolution : 0.1, 0.1 (x, y)\n## extent : 0, 1, 0, 1 (xmin, xmax, ymin, ymax) ## coord. ref. : NA\n## data source : in memory\n## names : layer\n## values : -2.612584, 2.403894 (min, max)\nIf we plot the raster object, we get a different view.\nplot(r)"
  },
  {
    "objectID": "posts/2016-03-11-welcome-to-the-lab-bonnie/welcome-to-the-lab-bonnie.html",
    "href": "posts/2016-03-11-welcome-to-the-lab-bonnie/welcome-to-the-lab-bonnie.html",
    "title": "Welcome to the Lab Bonnie",
    "section": "",
    "text": "As part of a collaboration with VDOT, I am pleased to announce that Ms. Bonnie Roderique has just joined the Dyer laboratory to work on a project around the endangered James River Spinymussel (Pleurobema collina). Not a plant, but at least not a vertebrate!"
  },
  {
    "objectID": "posts/2023-02-14-Variant-Filtering/index.html#merging-vcf-files",
    "href": "posts/2023-02-14-Variant-Filtering/index.html#merging-vcf-files",
    "title": "Variant Filtering",
    "section": "Merging VCF Files",
    "text": "Merging VCF Files\nThe first thing we need to to is zip and then index the individual vcf files. As a reminder, these files have been created by individual freebayes SNP calling of chunks of individuals partitioned into groups based upon the first letter of the popualtion from which they were collected. So, in the following examples, the file R.vcf contains all the individuals in populations starting with the letter R. When there are not that many individuals in a group, they are clustered—below we have JK.vcf which has all the individuals from populations starting with the letters J and K.\nSo, lets compress these raw files first.\n\n% bgzip JK.vcf\n% bgzip P.vcf \n% bgzip R.vcf \n% bgzip S.vcf \n% bgzip W.vcf\n% ls -alh\ntotal 70032\ndrwxr-xr-x   7 rodney  staff   224B Feb 16 14:22 .\ndrwxr-xr-x  21 rodney  staff   672B Feb 16 14:10 ..\n-rw-r--r--   1 rodney  staff   3.1M Feb 16 14:20 JK.vcf.gz\n-rw-r--r--   1 rodney  staff   5.8M Feb 16 14:22 P.vcf.gz\n-rw-r--r--   1 rodney  staff   4.6M Feb 16 14:22 R.vcf.gz\n-rw-r--r--   1 rodney  staff    14M Feb 16 14:22 S.vcf.gz\n-rw-r--r--   1 rodney  staff   5.8M Feb 16 14:22 W.vcf.gz\n\nNow we need to index these files.\n\n% tabix -p vcf JK.vcf.gz \n% tabix -p vcf P.vcf.gz \n% tabix -p vcf R.vcf.gz\n% tabix -p vcf S.vcf.gz\n% tabix -p vcf W.vcf.gz\n\nThen we can merge the files together into a single file. Here, the output file indicates the populations that contribute to it.\n\n % vcf-merge JK.vcf.gz P.vcf.gz R.vcf.gz S.vcf.gz W.vcf.gz > JKPRSW.vcf\n\nSo here are a few things that I’ve found that provide some insights into the data we are getting. Here is the sequencing depth per individual for only the SNP sites who have a minimum quality score of 20.\n\n% vcftools --vcf JKPRSW.vcf --remove-indels --minQ 20 --depth -c > depth.txt\n\nThis produced a distribution of sequencing depths for these individuals.\n\n\n\n\n\nFigure 1 Average sequencing depth across loci within each of the 302 individuals.\n\n\n\n\nAlternatively—and perhaps more important for us—we can look at the per-site depths. The goal here is to retain sites that have enough sequencing depth such that we are confident that it is a good site but not too much such that it is a reapeaty region in the geniome. For simplicity, I’ll drop the lower and upper standard deviation.\n\n\n\n\n\nFigure 2 Average sequencing depth per site across 302 individuals.\n\n\n\n\nFor simplicity, I’m just going to take the inner-50% of the data, dropping off the lower and upper quantiles.\n\nquantile( site_depth$SUM_DEPTH,\n          prob = c(0.25,0.75))\n\n25% 75% \n110 964 \n\n\nThis leaves us with 5047 sites.\nNow, we can go back to vcftools and use these values to select only sites with a quality score exceeding 20, and are in the middle 50 percentile of the depth coverage and have a minor allele frequency of at least 5%.\n\n% vcftools --vcf JKPRSW.vcf --remove-indels --min-meanDP 110 --max-meanDP 964 --minQ 20 --maf 0.05  --min-alleles 2 --max-alleles 2 --freq\nAfter filtering, kept 302 out of 302 Individuals\nOutputting Frequency Statistics...\nAfter filtering, kept 120 out of a possible 22604 Sites\nRun Time = 1.00 seconds\n\nSo, we have 120 loci to work with from this subset."
  },
  {
    "objectID": "posts/2019-03-29-the-enigmatic-seedlings-data-file/the-enigmatic-seedlings-data-file.html",
    "href": "posts/2019-03-29-the-enigmatic-seedlings-data-file/the-enigmatic-seedlings-data-file.html",
    "title": "The Enigmatic Seedlings Data File",
    "section": "",
    "text": "Here is the seedlings file."
  },
  {
    "objectID": "posts/2022-10-05-ddRADSeq-I/index.html",
    "href": "posts/2022-10-05-ddRADSeq-I/index.html",
    "title": "ddRADSeq Demultiplexing",
    "section": "",
    "text": "Your sequencing facility will let you provide to you a ftp link to download compressed fasta files (ending in .fa.gz in my case). We are getting these data in raw form and will do own own demultiplexing and creating a de novo assembly from which to call SNPs.\n\n\nOne pain point in doing this is that you’ll have to do all the work on a remote server and logging in each time can lead to a pain point (because you are using unique, long, and complicated passwords for each of your accounts, right?).\nTo overcome this, set up your public/private SSH key pair. First, check if you have one setup.\nrodney@Rodneys-Mac-Studio ~ % ls .ssh/id*.pub\n.ssh/id_rsa.pub\nIf there is nothing there, then you need to generate a new public key.\n\nrodney@Rodneys-Mac-Studio ~ % ssh-keygen -t rsa -b 4096 -C \"your_email@domain.com\"\n\nand follow the online instructions. If you do use a passphrase MAKE SURE you have it written down somewhere (like in your password manager).\nAfter this, you should see both the public and private versions in your local repository.\nrodney@Rodneys-Mac-Studio ~ % ls .ssh/id*    \n.ssh/id_rsa     .ssh/id_rsa.pub\nNow, what you need to do is to copy your identity over to the new server.\nssh-copy-id remoteUserID@remote.server.com\nYou should get some message like:\nremoteUserID@remote.server.com's password: \n\nNumber of key(s) added:        1\n\nNow try logging into the machine, with:   \n\"ssh 'remoteUserID@remote.server.com'\"\nand check to make sure that only the key(s) you \nwanted were added.\nNow you should be able to log into the remote server without needing to copy over a password all the time.\nOne last thing that I find to help out. If your remote server has some long name to it, you can make a shortcut by adding an entry to the /etc/hosts file.\nsudo vim /etc/hosts\nTo this file, add a line that has the full name of the server, a tab, and then a nickname you give it.\nrodney@Rodneys-Mac-Studio ~ % cat /etc/hosts\n##\n# Host Database\n#\n# localhost is used to configure the loopback interface\n# when the system is booting.  Do not change this entry.\n##\n127.0.0.1   localhost\n255.255.255.255 broadcasthost\n::1             localhost\nmy.server.with.long.name    nickname\nNow, you should be able to log into your remote server as:\nssh user@nickname\nmuch easier.\n\n\n\nStacks is a set of programs that are used to assemble sequence data. I use it commonly for demultiplexing. Go grab the link to the latest version here.\nWhen I did it for this document it was version 2.62. Grab it from your server. I typically put all the source code into a src folder.\n$ mkdir src\n$ cd src\n$ wget http://catchenlab.life.illinois.edu/stacks/source/stacks-2.62.tar.gz\n$ tar zxvf stacks-2.62.tar.gz\n$ cd stacks-2.62\nThen you need to install it.\nOn my current server, they use a Module system for loading various development environments. You can find the documentation here. To load up the most recent version of the gcc compiler set, you enter.\n$ module load gcc\n$ module list\nCurrently Loaded Modules:\n  1) gcc/10.2.1\nThen you can configure the compiliation and environment.\n$ ./configure --prefix=/home/user/\nAnd if all the stuff is there, you should get a long list of stuff ending with:\nchecking that generated files are newer than configure... done\nconfigure: creating ./config.status\nconfig.status: creating Makefile\nconfig.status: creating htslib/Makefile\nconfig.status: creating config.h\nconfig.status: executing depfiles commands\nNow, compile the components (and go grab a cup of coffee)\n$ make \nIf it died for some reason, you’ll have to do some spelunking and figure out why it died (probably due to a missing dependency) and then grab the components that you were missing.\nAfter that, you can install it (to your local directories).\n$ make install\nAnd everything should be good.\n\n\n\nDoing anything with this large amount of data will take time. It is good to remember that the vast majority of what you’ll be working with is actually stuff you are going to throw away in the end anyways. That being said, our first main tool will be screen. This is a program that allows you to create a “sub shell” for a process, do something that is going to take a long time, log out of the shell and continue on your daily routine. Then, at various times in the near (or distant) future, you can log back in and see how things are going.\nYou can run screen on your machine or on the remote server where things are happening. I’m going to run it on the other end.\n$ screen --help \nTo start a new screen session, invoke it as:\n$ screen\nAnd you will be entered into a new session. To exit, hit CTRL-A D and you will be pooped out of the screen session.\nTo reattach to an existing session, you can list the current active ones\n$ screen -list \nThere are screens on:\n    12892.pts-10.server (Detached)\n    12775.pts-10.server (Detached)\n    12658.pts-10.server (Detached)\n3 Sockets in /var/run/screen/S-user.\nThen reattach to one, you need to specify it by the id.\n$ screen -r 12892\nTo exit a session you are in (and no longer retain it), type\n$ exit\n\n\n\nLast time I tried this, I ran it with this configuration on a single linux box.\nprocess_radtags -p ./raw/ -o ./samples/run_13_2/ -b ./barcodes/all/barcodes_all.csv --inline-null --disable-rad-check -i gzfastq -r -e ecoRI\nNow I am on a cluster and we need to submit our jobs through SLURM. Here is a config file to run a batch run.\n#!/bin/bash\n#SBATCH --time=72:00:00\n#SBATCH --chdir=./\n#SBATCH --mem=16G\n#SBATCH --mail-user=rjdyer@vcu.edu\n#SBATCH --mail-type=BEGIN\n#SBATCH --mail-type=END\n#SBATCH --mail-type=FAIL\n#SBATCH --mail-type=REQUEUE\n#SBATCH --mail-type=ALL\n#SBATCH -J \"radtags\"\n#SBATCH --ntasks=1\n\n\nSTART=$(date +%s.%N)\necho \"Starting process radtags\" \n\n# for the run, you need to change the lane\nprocess_radtags -p ./raw/lane3/ -o ./samples/land3/ -b ./barcodes/all/barcodes_all.csv --inline-null --disable-rad-check -i gzfastq -r -D -e ecoRI \n\n\nEND=$(date +%s.%N)\nDIFF=$(echo \"($END - $START)/60\" | bc)\necho \"Processing radtags took ${DIFF} minutes to complete.\"\nTo run it, I saved the script as 01-process_radtags_slurm.sh, made it executable as\n$ chmod +x 01-process_radtags_slurm.sh\nand ran it as:\n$ sbatch ./01-process_radtags_slurm.sh\nActually I was not able to get sbatch to run, so I just did a quick bash srun job.\n$ srun -A rjdyer --nodes=1 --time=48:00:00 --mem=16G --pty /bin/bash\n$ process_radtags -p ./raw/lane3/ -o ./samples/land3/ -b ./barcodes/all/barcodes_all.csv --inline-null --disable-rad-check -i gzfastq -r -e ecoRI \nSome pages of interest\n\nhttps://slurm.schedmd.com/quickstart.html\nhttps://gist.github.com/andersgs/4aa1c19f7cd8a2db49a26f06efe7492d\n\n\nCover Photo by Sangharsh Lohakare on Unsplash"
  },
  {
    "objectID": "posts/2022-08-25-GitHub-Classroom/index.html",
    "href": "posts/2022-08-25-GitHub-Classroom/index.html",
    "title": "GitHub Classroom",
    "section": "",
    "text": "GitHub is a tremendously helpful tool for our daily activities as data mungers, programmers, and code monkeys. It allows us to keep a historically accurate account of our projects and to collaborate seamlessly with people from across the world. And for teaching, if you get away from using proprietary software from that Redmond company, it is spectacular.\nA few years ago, I began taking all of my teaching components and breaking them down into the smallest self-contained unit. I did this because:\n\nEach topic (say Factors in R) can be understood in isolation.\nEach topic may be of interest for several different courses.\nReusing topics makes my life so much less sucky (see also Dyer’s Philosophy of Life)"
  },
  {
    "objectID": "posts/2015-09-22-research-talk-chaire-ecoconception/research-talk-chaire-ecoconception.html",
    "href": "posts/2015-09-22-research-talk-chaire-ecoconception/research-talk-chaire-ecoconception.html",
    "title": "Research Talk Chaire EcoConception",
    "section": "",
    "text": "I’ve been asked to provide a talk for a meeting in Paris at the Institut des Sciences et Technologies, about how we use network theory to uncover connectivity networks in urban pollination systems. What an awesome opportunity. Here are my slides:\n\n\n\n\nClick on the image of my slide to present."
  },
  {
    "objectID": "posts/2017-10-23-envs-601-lecture/envs-601-lecture.html",
    "href": "posts/2017-10-23-envs-601-lecture/envs-601-lecture.html",
    "title": "ENVS 601 Lecture",
    "section": "",
    "text": "Here are my slides from a guest lecture I gave in ENVS 601. Interesting class, only place I’ve been called totally ignorant by another instructor… I’m thinking it was a compliment aimed at bias-free research approaches.\n\n\n\n\nDyer’s lecture"
  },
  {
    "objectID": "posts/2016-02-03-environmental-studies-orientation/environmental-studies-orientation.html",
    "href": "posts/2016-02-03-environmental-studies-orientation/environmental-studies-orientation.html",
    "title": "Environmental Studies Orientation",
    "section": "",
    "text": "Introduction to Environmental Studies."
  },
  {
    "objectID": "posts/2022-11-17-VSCode-Remote/index.html",
    "href": "posts/2022-11-17-VSCode-Remote/index.html",
    "title": "Using R on VSCode Remotely",
    "section": "",
    "text": "First of all, we’ll need to install some stuff on the R side. The language serve is necessary for VSCode and the httpgd is helpful for viewing graphical output. The following code will check to see if you have them installed and if not, install them for you.\n\nif( !require(languageserver) ) { \n  install.packages(\"languageserver\")\n}\n\nLoading required package: languageserver\n\nif( !require(httpgd)) { \n  remotes::install_github(\"nx10/httpgd\")\n}\n\nLoading required package: httpgd\n\n\nNow, download VSCode from the main server. You will also need to install the R Extension for Visual Studio Code, which can be installed from inside VSCode."
  },
  {
    "objectID": "posts/2022-11-17-VSCode-Remote/index.html#making-secure-connections",
    "href": "posts/2022-11-17-VSCode-Remote/index.html#making-secure-connections",
    "title": "Using R on VSCode Remotely",
    "section": "Making Secure Connections",
    "text": "Making Secure Connections"
  },
  {
    "objectID": "posts/2022-11-17-VSCode-Remote/index.html#remote-work",
    "href": "posts/2022-11-17-VSCode-Remote/index.html#remote-work",
    "title": "Using R on VSCode Remotely",
    "section": "Remote Work",
    "text": "Remote Work"
  },
  {
    "objectID": "posts/2023-01-30-2pt5pct-dDocent-Run/index.html",
    "href": "posts/2023-01-30-2pt5pct-dDocent-Run/index.html",
    "title": "A 2.5% dDocent Run",
    "section": "",
    "text": "So, started again with a smaller amount of starting data. This time, I set the random sample to 2.5% of the sequences from each individual. Instructions for how I did that are here.\nIt took about 3 hours to do this plus another 2 hours to gzip all the data files.\n\ndDocent Run\n[rjdyer@huff10 all0025]$ dDocent\n\ndDocent 2.9.4\nContact jpuritz@uri.edu with any problems\n\nChecking for required software\nAll required software is installed!\ndDocent version 2.9.4 started Mon Jan 30 13:32:43 EST 2023\n\n1416 individuals are detected. Is this correct? Enter yes or no and press [ENTER]\nyes\nProceeding with 1416 individuals\n\ndDocent detects 256 processors available on this system.\nPlease enter the maximum number of processors to use for this analysis.\n256\n  \n\nDo you want to quality trim your reads?\nType yes or no and press [ENTER]?\nyes\n\nDo you want to perform an assembly?\nType yes or no and press [ENTER].\nyes\n\nWhat type of assembly would you like to perform?  Enter SE for single end, PE for paired-end, RPE for paired-end sequencing for RAD protocols with random shearing, or OL for paired-end sequencing that has substantial overlap.\nThen press [ENTER]\nSE\n\nReads will be assembled with Rainbow\n\nCD-HIT will cluster reference sequences by similarity. The -c parameter (% similarity to cluster) may need to be changed for your taxa.\nWould you like to enter a new c parameter now? Type yes or no and press [ENTER]\nyes\n\nPlease enter new value for c. Enter in decimal form (For 90%, enter 0.9)\n0.85\n\nDo you want to map reads?  Type yes or no and press [ENTER]\nno\n\nMapping will not be performed\n\nDo you want to use FreeBayes to call SNPs?  Please type yes or no and press [ENTER]\nno\n\nPlease enter your email address.  dDocent will email you when it is finished running.\n\nDont worry; dDocent has no financial need to sell your email address to spammers.\nrjdyer@vcu.edu\n\n\ndDocent will require input during the assembly stage.  Please wait until prompt says it is safe to move program to the background.\n  \n\nTrimming reads and simultaneously assembling reference sequences\nRan into error\nparallel: Warning: Starting 32 processes took > 2 sec.\nparallel: Warning: Consider adjusting -j. Press CTRL-C to stop.\nResults were posted at 1725\n\nfor the first question and 1528 for the next one\n\nI then put it into the background and let it run.\nNow sit back, relax, and wait for your analysis to finish\n\ndDocent assembled 13966 sequences (after cutoffs) into 6676 contigs\n\ndDocent has finished with an analysis in /lustre/home/rjdyer/clemgu/samples/all0025\n\ndDocent started Mon Jan 30 13:32:43 EST 2023\ndDocent finished Mon Jan 30 17:30:02 EST 2023"
  },
  {
    "objectID": "posts/2016-06-05-intalling-shiny-server-on-ubuntu-14-lts/intalling-shiny-server-on-ubuntu-14-lts.html",
    "href": "posts/2016-06-05-intalling-shiny-server-on-ubuntu-14-lts/intalling-shiny-server-on-ubuntu-14-lts.html",
    "title": "Intalling Shiny Server on Ubuntu 14 LTS",
    "section": "",
    "text": "OK, so I just ‘found‘ shiny and it has a lot of cool stuff to it. OK, I’ve known about it for a long time but have just had the opportunity to sit down and work it out and see how it can fit into the presentation and learning I’m trying to develop in my Applied Population Genetics online textbook. Here is a brief overview of how I set up the shiny server on my Ubuntu box that is hosting the book (so I can embed more interactivity in the display).\nOK, below are the steps that I’m taking to upgrade everything on the box and install the shiny server app and start hosting individual shiny apps."
  },
  {
    "objectID": "posts/2016-06-05-intalling-shiny-server-on-ubuntu-14-lts/intalling-shiny-server-on-ubuntu-14-lts.html#updating-background-installing-necessary-components",
    "href": "posts/2016-06-05-intalling-shiny-server-on-ubuntu-14-lts/intalling-shiny-server-on-ubuntu-14-lts.html#updating-background-installing-necessary-components",
    "title": "Intalling Shiny Server on Ubuntu 14 LTS",
    "section": "Updating Background & Installing Necessary Components",
    "text": "Updating Background & Installing Necessary Components\nFirst, you should update to the latest releases. I’m running a LTS version (long-term support) so it is pretty stark.\nsudo apt-get update\nsudo apt-get upgrade\nNext, I needed to install the following development libraries so that things will go easily.\nsudo apt-get install libssl-dev\nsudo apt-get install gdebi-core\nsudo su - -c \"R -e \\\"install.packages('devtools', repos='http://cran.rstudio.com/')\\\"\"\nAnd then we can use the gdebi framework to install the the server\nwget https://download3.rstudio.org/ubuntu-12.04/x86_64/shiny-server-1.4.2.786-amd64.deb\nsudo gdebi shiny-server-1.4.2.786-amd64.deb\nThis puts the conf file in /etc/init/shiny-server.conf , sets up the user shiny (and has a home directory), and starts the shiny-server process."
  },
  {
    "objectID": "posts/2016-06-05-intalling-shiny-server-on-ubuntu-14-lts/intalling-shiny-server-on-ubuntu-14-lts.html#redirecting-url-requests",
    "href": "posts/2016-06-05-intalling-shiny-server-on-ubuntu-14-lts/intalling-shiny-server-on-ubuntu-14-lts.html#redirecting-url-requests",
    "title": "Intalling Shiny Server on Ubuntu 14 LTS",
    "section": "Redirecting URL Requests",
    "text": "Redirecting URL Requests\nAt this point the shiny-server is running and is servubg pages on port 3838. However, I block all ports other than 22 and 80 for security, so what I want to do is to redirect requests to my server asking for anything in the subdirectory http://popgen.bio.vcu.edu/shiny to redirect to http://127.0.0.1:3838 locally. I need to do this by fiddling with the Apache configuration scripts.\nApache on Ubuntu puts configuration scripts in /etc/apache2/sites-available and symliks them to /etc/apache2/sites-enabled. In this file, I set up a proxy pass so that any url that is asking for stuff in the /shiny/ subdirectory be redirected to the 3838 port on this machine. At the end of the section for this server, enclosed in <VirtualHost *:80> , I put the following in:\nRewriteCond %{HTTP:Upgrade} =websocket\nRewriteRule /shiny/(.*) ws://localhost:3838/$1 [P,L]\nRewriteCond %{HTTP:Upgrade} !=websocket\nRewriteRule /shiny/(.*) http://localhost:3838/$1 [P,L]\nProxyPass /shiny/ http://localhost:3838/        \nProxyPassReverse /shiny/ http://localhost:3838/\nYou need to make sure that the following mod are turned on for apache:\n\nmod_proxy\nmod_proxy_html\nmod_proxy_wstunnel\n\nEnable them the way that is appropriate for your server. On Ubuntu it is:\na2enmod mod_proxy\na2enmod mod_proxy_html\na2enmod mod_proxy_wstunnel"
  },
  {
    "objectID": "posts/2016-06-05-intalling-shiny-server-on-ubuntu-14-lts/intalling-shiny-server-on-ubuntu-14-lts.html#restart-apache",
    "href": "posts/2016-06-05-intalling-shiny-server-on-ubuntu-14-lts/intalling-shiny-server-on-ubuntu-14-lts.html#restart-apache",
    "title": "Intalling Shiny Server on Ubuntu 14 LTS",
    "section": "Restart Apache",
    "text": "Restart Apache\nAll that is left to do now is restart apache and check to see the startup screen for all shiny apps on the http://popgen.bio.vcu.edu/shiny/ page.\nsudo service apache2 restart\nThe first shiny app to be integrated into the Applied Population Genetics textbook is located in the Hardy-Weinberg chapter. It is embedded as:\n\nAnd creates the following widget in the book (go ahead and play with it, it is interactive):\nThis opens a whole slew of interactive graphics for the textbook!"
  },
  {
    "objectID": "posts/2015-09-16-methylation-structure/methylation-structure.html",
    "href": "posts/2015-09-16-methylation-structure/methylation-structure.html",
    "title": "Methylation Structure",
    "section": "",
    "text": "Here is some interesting data coming out of the Baja Araptus attenuatus project. We looked at methylation variation, localized within the genome and compared the amount of among-population variation present. The underlying idea here is that in insects, methylation is more often encountered in coding regions, and has been shown in many cases to be influencing phenotype.\n\nSo, the questions we are looking at are:\n\nIs there spatial genetic variation in the methylation ‘loci’? If not, methylation may not be useful in the search for adaptive variance.\nIf there is variation, does it mimic the spatial structure found in nucleotide-based markers?\n\nIf some fraction of methylation loci, say p, do contain spatial structure then it means that these methylation patterns are inherited and can be used to help reconstruct neutral history.\nThe rest of the methylation structure, say 1-p, can be considered as being due to processes that operate at a time scale that does not capture recent demographic processes. These would be the ones we are most interested in looking at for evidence of local adaptation, right?\n\n\nSo in the first step, how is the variation distributed amongst populations in the nucleotide markers and their paired methylation markers can be seen below.\n\n\n\nPaired population structure for nucleotide, MSP, and methylation, HPA, loci.\n\n\nIf we look at genetic distances between population for both sets of markers, we see a discongruence in the topological structure. Here is a tangle plot of the data, on the left are the nucleotide markers and on the right are the methylation ones. The red branches in the interior of each are those that are different between the two topologies.\n\n\n\nPaired neighbor joining trees for methylation and nucleotide population structure"
  },
  {
    "objectID": "posts/2016-01-29-prothonotary-warblers/prothonotary-warblers.html",
    "href": "posts/2016-01-29-prothonotary-warblers/prothonotary-warblers.html",
    "title": "Prothonotary Warblers",
    "section": "",
    "text": "Way to go Dr. Bulluck! A cool overview of some research that we’ve been associated with over the years."
  },
  {
    "objectID": "posts/2015-10-29-the-taxonomy-of-academic-sustainability/the-taxonomy-of-academic-sustainability.html",
    "href": "posts/2015-10-29-the-taxonomy-of-academic-sustainability/the-taxonomy-of-academic-sustainability.html",
    "title": "The Taxonomy of Academic Sustainability",
    "section": "",
    "text": "Been working on a lexicographic analysis of ‘Sustainability’ as published by the journals PNAS and Sustainability. Here are the stemmed word forms for 366 published articles represented as a hierarchical clustering. The wordclouds represent the top 10 word stems per group."
  },
  {
    "objectID": "posts/2022-09-07-Rendering-R-Helpfiles/index.html",
    "href": "posts/2022-09-07-Rendering-R-Helpfiles/index.html",
    "title": "Rendering R Help Files",
    "section": "",
    "text": "In teaching, there are many situations where you may want to show a generic help file and have it rendered in markdown. However, it has been a constant pain to do this for some reason. I finally found a way to do it easily in quarto so that you can quickly grab a help file, render it as HTML and then put it into a slide that is .scrollable using Quarto in a ReactJS presentation.\nHere is how to set it up.\n\nCreate a slide that has the atrributed {.scrollable} so that the content on the slide can be much taller than the slide itself (it will be).\nCreate a chunk that is not echoed (e.g., add the #| echo: false at the first line.)\nThe main code grabs the help file, renders it into html, saves it as a temporary file, and then uses knitr to paste it into the slide as raw ouptput.\n\nHere is an example I used for embedding ?strptime into the presentation.\n\nhlp <- help(strptime)\nhelpfile <- utils:::.getHelpFile( hlp )\noutfile <- tempfile(fileext = \".html\")\ntools::Rd2HTML(helpfile, out=outfile)\nrawHTML <- paste( readLines(outfile), collapse = \"\\n\")\nknitr::asis_output( htmltools::htmlPreserve(rawHTML))\n\n\nR: Date-time Conversion Functions to and from Character\n\n\n\n\n\n\n\n\nstrptimeR Documentation\n\nDate-time Conversion Functions to and from Character\n\nDescription\n\nFunctions to convert between character representations and objects of\nclasses \"POSIXlt\" and \"POSIXct\" representing calendar\ndates and times.\n\n\n\nUsage\n\n## S3 method for class 'POSIXct'\nformat(x, format = \"\", tz = \"\", usetz = FALSE, ...)\n## S3 method for class 'POSIXlt'\nformat(x, format = \"\", usetz = FALSE,\n       digits = getOption(\"digits.secs\"), ...)\n\n## S3 method for class 'POSIXt'\nas.character(x, ...)\n\nstrftime(x, format = \"\", tz = \"\", usetz = FALSE, ...)\nstrptime(x, format, tz = \"\")\n\n\n\nArguments\n\n\nx\n\nAn object to be converted: a character vector for\nstrptime, an object which can be converted to\n\"POSIXlt\" for strftime.\n\ntz\n\nA character string specifying the time zone to be used for\nthe conversion.  System-specific (see as.POSIXlt), but\n\"\" is the current time zone, and \"GMT\" is UTC.\nInvalid values are most commonly treated as UTC, on some platforms with\na warning.\n\nformat\n\nA character string.  The default for the format\nmethods is\n\"%Y-%m-%d %H:%M:%S\" if any element has a time\ncomponent which is not midnight, and \"%Y-%m-%d\"\notherwise.  If options(\"digits.secs\") is set, up to\nthe specified number of digits will be printed for seconds.\n\n...\n\nFurther arguments to be passed from or to other methods.\n\nusetz\n\nlogical.  Should the time zone abbreviation be appended\nto the output?  This is used in printing times, and more reliable\nthan using \"%Z\".\n\ndigits\n\ninteger determining the format()ing of seconds when needed.\n\n\n\n\nDetails\n\nThe format and as.character methods and strftime\nconvert objects from the classes \"POSIXlt\" and\n\"POSIXct\" to character vectors.\n\nstrptime converts character vectors to class \"POSIXlt\":\nits input x is first converted by as.character.\nEach input string is processed as far as necessary for the format\nspecified: any trailing characters are ignored.\n\nstrftime is a wrapper for format.POSIXlt, and it and\nformat.POSIXct first convert to class \"POSIXlt\" by\ncalling as.POSIXlt (so they also work for class\n\"Date\").  Note that only that conversion depends on the\ntime zone.\nSince R version 4.2.0, that as.POSIXlt() conversion now treats\nthe non-finite numeric -Inf, Inf, NA and NaN\ndifferently (where previously all were treated as NA) and also\nthe format() method for POSIXlt now treats these different\nnon-finite times and dates analogously to type double.\n\nThe usual vector re-cycling rules are applied to x and\nformat so the answer will be of length of the longer of these\nvectors.\n\nLocale-specific conversions to and from character strings are used\nwhere appropriate and available.  This affects the names of the days\nand months, the AM/PM indicator (if used) and the separators in output\nformats such as %x and %X, via the setting of\nthe LC_TIME locale category.  The ‘current\nlocale’ of the descriptions might mean the locale in use at the start\nof the R session or when these functions are first used.  (For input,\nthe locale-specific conversions can be changed by calling\nSys.setlocale with category LC_TIME (or\nLC_ALL).  For output, what happens depends on the OS but\nusually works.)\n\n\nThe details of the formats are platform-specific, but the following are\nlikely to be widely available: most are defined by the POSIX standard.\nA conversion specification is introduced by %, usually\nfollowed by a single letter or O or E and then a single\nletter.  Any character in the format string not part of a conversion\nspecification is interpreted literally (and %% gives\n%).  Widely implemented conversion specifications include\n\n\n\n%aAbbreviated weekday name in the current\nlocale on this platform.  (Also matches full name on input:\nin some locales there are no abbreviations of names.)\n\n%AFull weekday name in the current locale.  (Also\nmatches abbreviated name on input.)\n\n%bAbbreviated month name in the current locale on\nthis platform.  (Also matches full name on input: in\nsome locales there are no abbreviations of names.)\n\n%BFull month name in the current locale.  (Also\nmatches abbreviated name on input.)\n\n%cDate and time.   Locale-specific on output,\n\"%a %b %e %H:%M:%S %Y\" on input.\n\n%CCentury (00–99): the integer part of the year\ndivided by 100.\n\n%dDay of the month as decimal number (01–31).\n\n%DDate format such as %m/%d/%y: the C99\nstandard says it should be that exact format (but not all OSes\ncomply).\n\n%eDay of the month as decimal number (1–31), with\na leading space for a single-digit number.\n\n%FEquivalent to %Y-%m-%d (the ISO 8601 date\nformat).\n\n%gThe last two digits of the week-based year\n(see %V).  (Accepted but ignored on input.)\n\n%GThe week-based year (see %V) as a decimal\nnumber.  (Accepted but ignored on input.)\n\n%hEquivalent to %b.\n\n%HHours as decimal number (00–23).  As a special\nexception strings such as ‘⁠24:00:00⁠’ are accepted for input,\nsince ISO 8601 allows these.\n\n%IHours as decimal number (01–12).\n\n%jDay of year as decimal number (001–366):  For\ninput, 366 is only valid in a leap year.\n\n%mMonth as decimal number (01–12).\n\n%MMinute as decimal number (00–59).\n\n%nNewline on output, arbitrary whitespace on input.\n\n%pAM/PM indicator in the locale.  Used in\nconjunction with %I and not with %H.  An\nempty string in some locales (for example on some OSes,\nnon-English European locales including Russia). The behaviour is\nundefined if used for input in such a locale.\n\nSome platforms accept %P for output, which uses a lower-case\nversion (%p may also use lower case): others will output\nP.\n \n%rFor output, the 12-hour clock time (using the\nlocale's AM or PM): only defined in some locales, and on some OSes\nmisleading in locales which do not define an AM/PM indicator.\nFor input, equivalent to %I:%M:%S %p.\n \n%REquivalent to %H:%M.\n\n%SSecond as integer (00–61), allowing for\nup to two leap-seconds (but POSIX-compliant implementations\nwill ignore leap seconds).\n\n%tTab on output, arbitrary whitespace on input.\n\n%TEquivalent to %H:%M:%S.\n\n%uWeekday as a decimal number (1–7, Monday is 1).\n\n\n\n\n%UWeek of the year as decimal number (00–53) using\nSunday as the first day 1 of the week (and typically with the\nfirst Sunday of the year as day 1 of week 1).  The US convention.\n\n%VWeek of the year as decimal number (01–53) as\ndefined in ISO 8601.\nIf the week (starting on Monday) containing 1 January has four or\nmore days in the new year, then it is considered week 1.  Otherwise, it\nis the last week of the previous year, and the next week is week\n1.  (Accepted but ignored on input.)\n\n%wWeekday as decimal number (0–6, Sunday is 0).\n\n%WWeek of the year as decimal number (00–53) using\nMonday as the first day of week (and typically with the\nfirst Monday of the year as day 1 of week 1).  The UK convention.\n\n%xDate.  Locale-specific on output,\n\"%y/%m/%d\" on input.\n\n%XTime.  Locale-specific on output,\n\"%H:%M:%S\" on input.\n\n%yYear without century (00–99).  On input, values\n00 to 68 are prefixed by 20 and 69 to 99 by 19 – that is the\nbehaviour specified by the 2018 POSIX standard, but it does\nalso say ‘it is expected that in a future version the\ndefault century inferred from a 2-digit year will change’.\n\n%YYear with century.  Note that whereas there was no\nzero in the original Gregorian calendar, ISO 8601:2004 defines it\nto be valid (interpreted as 1BC): see\nhttps://en.wikipedia.org/wiki/0_(year).  However, the standards\nalso say that years before 1582 in its calendar should only be used\nwith agreement of the parties involved.\n\nFor input, only years 0:9999 are accepted.\n\n%zSigned offset in hours and minutes\nfrom UTC, so -0800 is 8 hours behind UTC. Values up to\n+1400 are accepted.  (Standard only for output.  For input\nR currently supports it on all platforms.)\n \n%Z(Output only.)  Time zone abbreviation as a\ncharacter string (empty if not available).  This may not be reliable\nwhen a time zone has changed abbreviations over the years.\n\n\n\nWhere leading zeros are shown they will be used on output but are\noptional on input.  Names are matched case-insensitively on input:\nwhether they are capitalized on output depends on the platform and the\nlocale.  Note that abbreviated names are platform-specific (although\nthe standards specify that in the ‘⁠C⁠’ locale they must be the\nfirst three letters of the capitalized English name: this convention\nis widely used in English-language locales but for example the French\nmonth abbreviations are not the same on any two of Linux, macOS, Solaris\nand Windows). Knowing what the abbreviations are is essential\nif you wish to use %a, %b or %h as part of an\ninput format: see the examples for how to check.\n\n\nWhen %z or %Z is used for output with an\nobject with an assigned time zone an attempt is made to use the values\nfor that time zone — but it is not guaranteed to succeed.\n\nNot in the standards and less widely implemented are\n\n\n\n%kThe 24-hour clock time with single digits preceded\nby a blank.\n\n%lThe 12-hour clock time with single digits preceded\nby a blank.\n\n%s(Output only.) The number of seconds since the\nepoch.\n\n%+(Output only.) Similar to %c, often\n\"%a %b %e %H:%M:%S %Z %Y\". May depend on the locale.\n\n\n\nFor output there are also %O[dHImMUVwWy] which may emit\nnumbers in an alternative locale-dependent format (e.g., roman\nnumerals), and %E[cCyYxX] which can use an alternative\n‘era’ (e.g., a different religious calendar).  Which of these\nare supported is OS-dependent.  These are accepted for input, but with\nthe standard interpretation.\n\nSpecific to R is %OSn, which for output gives the seconds\ntruncated to 0 <= n <= 6 decimal places (and if %OS is\nnot followed by a digit, it uses the setting of\ngetOption(\"digits.secs\"), or if that is unset, n =\n  0).  Further, for strptime %OS will input seconds\nincluding fractional seconds.  Note that %S does not read\nfractional parts on output. \n\nThe behaviour of other conversion specifications (and even if other\ncharacter sequences commencing with % are conversion\nspecifications) is system-specific.  Some systems document that the\nuse of multi-byte characters in format is unsupported: UTF-8\nlocales are unlikely to cause a problem.\n\n\n\nValue\n\nThe format methods and strftime return character vectors\nrepresenting the time.  NA times are returned as\nNA_character_.  The elements are restricted to 256 bytes, plus\na time zone abbreviation if usetz is true.  (On known platforms\nlonger strings are truncated at 255 or 256 bytes, but this is not\nguaranteed by the C99 standard.)\n\nstrptime turns character representations into an object of\nclass \"POSIXlt\".  The time zone is used to set the\nisdst component and to set the \"tzone\" attribute if\ntz != \"\".  If the specified time is invalid (for example\n‘⁠\"2010-02-30 08:00\"⁠’) all the components of the result are\nNA.  (NB: this does means exactly what it says – if it is an\ninvalid time, not just a time that does not exist in some time zone.)\n\n\n\nPrinting years\n\nEveryone agrees that years from 1000 to 9999 should be printed with 4\ndigits, but the standards do not define what is to be done outside\nthat range.  For years 0 to 999 most OSes pad with zeros or spaces to\n4 characters, and Linux outputs just the number.\n\nOS facilities will probably not print years before 1 CE (aka 1 AD)\n‘correctly’ (they tend to assume the existence of a year 0: see\nhttps://en.wikipedia.org/wiki/0_(year), and some OSes get them\ncompletely wrong).  Common formats are -45 and -045.\n\nYears after 9999 and before -999 are normally printed with five or\nmore characters.\n\nSome platforms support modifiers from POSIX 2008 (and others).  On\nLinux the format \"%04Y\" assures a minimum of four characters\nand zero-padding.  The internal code (as used on Windows and by\ndefault on macOS) uses zero-padding by default, and formats\n%_4Y and %_Y can be used for space padding and no\npadding.\n\n\n\nTime zone offsets\n\nOffsets from GMT (also known as UTC) are part of the conversion\nbetween timezones and to/from class \"POSIXct\", but cause\ndifficulties as they are often computed incorrectly.\n\nThey conventionally have the opposite sign from time-zone\nspecifications (see Sys.timezone): positive values are\nEast of the meridian.  Although there have been time zones with\noffsets like 00:09:21 (Paris in 1900), and 00:44:30 (Liberia until\n1972), offsets are usually treated as whole numbers of minutes, and\nare most often seen in RFC 5322 email headers in forms like\n-0800 (e.g., used on the Pacific coast of the USA in winter).\n\nFormat %z can be used for input or output: it is a character\nstring, conventionally plus or minus followed by two digits for\nhours and two for minutes: the standards say that an empty string\nshould be output if the offset is unknown, but some systems use the\noffsets for the time zone in use for the current year.\n\n\n\nSources\n\nInput uses the POSIX function strptime and output the C99\nfunction strftime.\n\nHowever, not all OSes (notably Windows) provided strptime and\nmany issues were found for those which did, so since 2000 R has used\na fork of code from ‘⁠glibc⁠’.  The forked code uses the\nsystem's strftime to find the locale-specific day and month\nnames and any AM/PM indicator.\n\nOn some platforms (including Windows and by default on macOS) the\nsystem's strftime is replaced (along with most of the rest of\nthe C-level datetime code) by code modified from IANA's ‘⁠tzcode⁠’\ndistribution (https://www.iana.org/time-zones).\n\n\n\nNote\n\nThe default formats follow the rules of the ISO 8601 international\nstandard which expresses a day as \"2001-02-28\" and a time as\n\"14:01:02\" using leading zeroes as here.  (The ISO form uses no\nspace to separate dates and times: R does by default.)\n\nFor strptime the input string need not specify the date\ncompletely: it is assumed that unspecified seconds, minutes or hours\nare zero, and an unspecified year, month or day is the current one.\n(However, if a month is specified, the day of that month has to be\nspecified by %d or %e since the current day of the\nmonth need not be valid for the specified month.)  Some components may\nbe returned as NA (but an unknown tzone component is\nrepresented by an empty string).\n\nIf the time zone specified is invalid on your system, what happens is\nsystem-specific but it will probably be ignored.\n\nRemember that in most time zones some times do not occur and some\noccur twice because of transitions to/from ‘daylight saving’\n(also known as ‘summer’) time.  strptime does not\nvalidate such times (it does not assume a specific time zone), but\nconversion by as.POSIXct will do so.  Conversion by\nstrftime and formatting/printing uses OS facilities and may\nreturn nonsensical results for non-existent times at DST transitions.\n\nIn a C locale %c is required to be\n\"%a %b %e %H:%M:%S %Y\".  As Windows does not comply (and\nuses a date format not understood outside N. America), that format is\nused by R on Windows in all locales.\n\n\n\nReferences\n\nInternational Organization for Standardization (2004, 2000, ...)\n‘ISO 8601.  Data elements and interchange formats –\nInformation interchange – Representation of dates and times.’,\nslightly updated to International Organization for Standardization (2019)\n‘ISO 8601-1:2019.  Date and time – Representations for\ninformation interchange – Part 1: Basic rules’.\nFor links to versions available on-line see (at the time of writing)\nhttps://dotat.at/tmp/ISO_8601-2004_E.pdf and\nhttps://www.qsl.net/g1smd/isopdf.htm; for information on the\ncurrent official version, see https://www.iso.org/iso/iso8601 and\nhttps://en.wikipedia.org/wiki/ISO_8601.\n\nThe POSIX 1003.1 standard, which is in some respects stricter than ISO 8601.\n\n\n\nSee Also\n\nDateTimeClasses for details of the date-time classes;\nlocales to query or set a locale.\n\nYour system's help page on strftime to see how to specify their\nformats.  (On some systems, including Windows, strftime is\nreplaced by more comprehensive internal code.)\n\n\n\nExamples\n\n\n## locale-specific version of date()\nformat(Sys.time(), \"%a %b %d %X %Y %Z\")\n\n## time to sub-second accuracy (if supported by the OS)\nformat(Sys.time(), \"%H:%M:%OS3\")\n\n## read in date info in format 'ddmmmyyyy'\n## This will give NA(s) in some non-English locales; setting the C locale\n## as in the commented lines will overcome this on most systems.\n## lct <- Sys.getlocale(\"LC_TIME\"); Sys.setlocale(\"LC_TIME\", \"C\")\nx <- c(\"1jan1960\", \"2jan1960\", \"31mar1960\", \"30jul1960\")\nz <- strptime(x, \"%d%b%Y\")\n## Sys.setlocale(\"LC_TIME\", lct)\nz\n\n## read in date/time info in format 'm/d/y h:m:s'\ndates <- c(\"02/27/92\", \"02/27/92\", \"01/14/92\", \"02/28/92\", \"02/01/92\")\ntimes <- c(\"23:03:20\", \"22:29:56\", \"01:03:30\", \"18:21:03\", \"16:56:26\")\nx <- paste(dates, times)\nstrptime(x, \"%m/%d/%y %H:%M:%S\")\n\n## time with fractional seconds\nz <- strptime(\"20/2/06 11:16:16.683\", \"%d/%m/%y %H:%M:%OS\")\nz # prints without fractional seconds\nop <- options(digits.secs = 3)\nz\noptions(op)\n\n## time zone names are not portable, but 'EST5EDT' comes pretty close.\n(x <- strptime(c(\"2006-01-08 10:07:52\", \"2006-08-07 19:33:02\"),\n               \"%Y-%m-%d %H:%M:%S\", tz = \"EST5EDT\"))\nattr(x, \"tzone\")\n\n## An RFC 5322 header (Eastern Canada, during DST)\n## In a non-English locale the commented lines may be needed.\n## prev <- Sys.getlocale(\"LC_TIME\"); Sys.setlocale(\"LC_TIME\", \"C\")\nstrptime(\"Tue, 23 Mar 2010 14:36:38 -0400\", \"%a, %d %b %Y %H:%M:%S %z\")\n## Sys.setlocale(\"LC_TIME\", prev)\n\n## Make sure you know what the abbreviated names are for you if you wish\n## to use them for input (they are matched case-insensitively):\nformat(seq.Date(as.Date('1978-01-01'), by = 'day', len = 7), \"%a\")\nformat(seq.Date(as.Date('2000-01-01'), by = 'month', len = 12), \"%b\")\n\nformat(.POSIXct(Inf)) # \"Inf\"  (was  NA  in R <= 4.1.x)\nnotF <- c(-Inf,Inf,NaN,NA)\n(fF <- format(.POSIXct(notF))) # was all  NA, now the last is still NA (not \"NA\")\nstopifnot(identical(as.character(notF), fF))"
  },
  {
    "objectID": "posts/2017-10-05-capturing-contents-within-curly-brackets/capturing-contents-within-curly-brackets.html",
    "href": "posts/2017-10-05-capturing-contents-within-curly-brackets/capturing-contents-within-curly-brackets.html",
    "title": "Capturing contents within Curly Brackets",
    "section": "",
    "text": "OK, just a quickie here. I’m working with a colleague on a manuscript using LaTeX. The citation formatting for the journal we are looking at uses the numerical citations but bibtex will number the citations by the order in which the  values they occur in the bibliography section. So, it would be great to get them to be in the order in which they occur in the text.\nSo, our old friend (and sometimes enemy) grep comes to the rescue. Here is a quick one-liner that allows you to search the text for all the  entries and return only the contents within the curly brackets.\ncat test.tex | grep -o -e \"cite{[^}]*}\"\nOnce all the editing is done and we’ve finished on the main body of the text, we can reorder the bibliography section and the numbers will be incremental.\nSometimes I forget how awesome and powerful the unix underpinnings are."
  },
  {
    "objectID": "posts/2022-03-22-update-to-popgraph-library/update-to-popgraph-library.html",
    "href": "posts/2022-03-22-update-to-popgraph-library/update-to-popgraph-library.html",
    "title": "Update to the R POPGRAPH library",
    "section": "",
    "text": "A population graph is a graph-theoretic representation of population genetic covariance, which can arrise from a host of micro and macro evolutionary processes (see Dyer & Nason 2004 for a more complete description) using the Lophocereus schottii topology depicted below.\n\n\n\nThe first population graph based upon the spatial genetic structure of the sonoran desert cactus, Lophocereus schottii\n\n\nFor these analyses, I have written an R package named popgraph that does all the under-the-scenes kinds of stuff. One of the things I’m currently working on is extending this to use in genomic contexts. For this, I’ve been developing the tools for additional analyses, one of which is concerned with comparing large numbers of topologies. Well, today I found an annoying ‘feature’ in the library that would not give an answer with specific kinds of topological structure. I didn’t give the wrong answer, it just gave you a “I cannot give you an answer” kind of answer, which is annoying.\nSo I fixed it and updated the package (github). If you are following along at home and need to do congruent tests, version 1.5.3 and later will be less annoying (and more information rich). Enjoy!"
  },
  {
    "objectID": "posts/2023-01-31-5pct-dDocent-Run/index.html",
    "href": "posts/2023-01-31-5pct-dDocent-Run/index.html",
    "title": "A 5% Representation Run",
    "section": "",
    "text": "Let’s celebrate the small victories for what they are.\n\n\nSo given the output from [[dDocent All Individuals 2.5%]] and [[dDocent All Individuals 10%]], I thought I’d run a 5% representation.\nscreen -r 3222\nand sample them as:\nrm(list=ls())\nfiles <- list.files(\"all\",pattern=\"F.fq.gz\")\n\nfor( i in 1:length(files) ) { \n    file <- files[i]\n    tmp <- strsplit(file, split=\"\\\\.\")[[1]]\n    ofile <- paste(   paste(tmp[1],tmp[2],sep=\"\"), tmp[3],tmp[4], sep=\".\")\n    cmd <- paste( \"seqtk sample ./all/\",file,\" 0.025 > ./all0025/\", ofile, sep=\"\")\n    system(cmd)\n    cmd <- paste(\"gzip \", \"./all0025/\",ofile,sep=\"\")\n    system(cmd)\n    cat( format(i/length(files), digits=3), \" \", ofile, \"\\n\")\n}\n\nStarted at 1040.\n\n60 minute timer\n\nstart 0.012\nend 0.264\n\nEstimated finish: 1500\n\n\nTrimming reduced 5% representation: - Start: Jan 31 18:51 - End: Feb 1 00:21\n\nI set it to only record sequences if they are in 10% of the individuals in the full dataset.\n\nAt this point, all configuration information has been entered and dDocent may take several hours to run.\n\nIt is recommended that you move this script to a background operation and disable terminal input and output.\n\nAll data and logfiles will still be recorded.\n\nTo do this:\nPress **control** and **Z** simultaneously\nType **bg** and press enter\nType **disown -h** and press enter\nNow sit back, relax, and wait for your analysis to finish\ndDocent assembled 88487 sequences (after cutoffs) into 57829 contigs\n\ndDocent has finished with an analysis in /lustre/home/rjdyer/clemgu/samples/all005  \n\ndDocent started Tue Jan 31 18:21:35 EST 2023\n\ndDocent finished Wed Feb 1 07:20:00 EST 2023"
  },
  {
    "objectID": "posts/2016-11-13-talk-at-temple/talk-at-temple.html",
    "href": "posts/2016-11-13-talk-at-temple/talk-at-temple.html",
    "title": "Talk at Temple",
    "section": "",
    "text": "Giving a talk up at Temple University, last seminar of the year but one I’ve been looking forward to giving for a while.\n\n\nClick through the image to download a PDF version of the talk."
  },
  {
    "objectID": "posts/2021-12-21-craft-app-rstudio-distill-blogging/index.html",
    "href": "posts/2021-12-21-craft-app-rstudio-distill-blogging/index.html",
    "title": "Craft.app + rstudio::distill = blogging",
    "section": "",
    "text": "However, not everything I do is strictly R related so I thought it would be cool to see if I can hook up Craft.do to serve as a secondary route for creating and integrating posts into my laboratory website.\nThe overall roadmap is as follows:\n\nWrite 1-paged (with cover image and internal images) posts in Craft.do.\nExport as some type (currently supported types include Markdown & TextBundle as options.\nCopy the folder over to the root directory of the DLabWebsite.\nWrite some custom R script to make a new distill blog post\nTrigger a build + git add + git commit + push action.\n\nLet’s see how this can be done.\n\nExported File Types\n\nTextBundle\nA TextBundle is a different thing entirely. It is apparently ya single document bundle that contains two files:\n\nA info.json bundle\nA text.markdown text file.\n\nThere does not appear to be any tangible reason why a textBundle would be preferred over a single markdown file, so I’ll not consider it from here on.\n\n\nMarkdown\nYou can specify the flavor of markdown and the built-in types include Github. There is a nice interface here to select certain options on it and the ability to put it into a single markdown file.\n\n\n\nScreen Shot 2021-12-21 at 08.06.28.png\n\n\nOne of the other things that I didn’t quite appreciate was that for images, like the one inserted above,\n\n\n\nImage.png\n\n\nCraft will include an online reference to it on their craft servers. This does allow me to not have to upload everything to my flickr account, which is both nice (less steps) but troubling (what would happen if the craft servers go down or craft goes away (i no longer have all my stuff in one place). I suppose I could easily suck down all the images and relink them in the markdown if necessary. For now, I’ll call that a win.\n\n\n\nMarkdown 2 Distill\nFor this one, I think I’ll make a cheap and quick R solution to this. For that I’ll pick up in the next installment, and do it from the R side.\nFor this, I will enforce the following general rules.\n\nI’ll have to configure a featured image separate from this file (there is no opportunity for finding the location of the Cover Image at the top.).\nThe title will be moved form H1 to markdown metadata title.\nThe first paragraph will be taken and used as the description for the markdown metadata description.\nSave the raw markdown to a _toImport folder in the git repository for the site. The next time the site is built, it will convert the raw markdown into a distill::article object and inserted in the appropriate place.\n\nOnce I get it all up and running, then I can wrap it all up in a shortcut."
  },
  {
    "objectID": "posts/2019-04-21-simulating-random-populations/simulating-random-populations.html",
    "href": "posts/2019-04-21-simulating-random-populations/simulating-random-populations.html",
    "title": "Simulating Random Populations",
    "section": "",
    "text": "The gstudio package has routines that can be used to simulate random populations. I’ve added these to facilitate more exploratory data analysis. Here is how you can use them.\nIf you have not updated the gstudio and popgraph packages in a while, you probably should. Here is how (if it asks if you would like to update the other packages, it is probably a good idea to say yes).\n\ndevtools::install_github(\"dyerlab/popgraph\")\ndevtools::install_github(\"dyerlab/gstudio\")\n\nThen load it in as:\n\nlibrary(gstudio)\n\nI’m going to start with the enigmatic bark beetle data set.\n\ndata(arapat)\nsummary(arapat)\n\n      Species      Cluster      Population        ID         Latitude    \n Cape     : 75   CBP-C :150   32     : 19   101_10A:  1   Min.   :23.08  \n Mainland : 36   NBP-C : 84   75     : 11   101_1A :  1   1st Qu.:24.59  \n Peninsula:252   SBP-C : 18   Const  : 11   101_2A :  1   Median :26.25  \n                 SCBP-A: 75   12     : 10   101_3A :  1   Mean   :26.25  \n                 SON-B : 36   153    : 10   101_4A :  1   3rd Qu.:27.53  \n                              157    : 10   101_5A :  1   Max.   :29.33  \n                              (Other):292   (Other):357                  \n   Longitude          LTRS          WNT            EN           EF     \n Min.   :-114.3   01:01 :147   03:03  :108   01:01  :225   01:01 :219  \n 1st Qu.:-113.0   01:02 : 86   01:01  : 82   01:02  : 52   01:02 : 52  \n Median :-111.5   02:02 :130   01:03  : 77   02:02  : 38   02:02 : 90  \n Mean   :-111.7                02:02  : 62   03:03  : 22   NA's  :  2  \n 3rd Qu.:-110.5                03:04  :  8   01:03  :  7               \n Max.   :-109.1                (Other): 15   (Other): 16               \n                               NA's   : 11   NA's   :  3               \n     ZMP           AML           ATPS          MP20    \n 01:01 : 46   08:08  : 51   05:05  :155   05:07  : 64  \n 01:02 : 51   07:07  : 42   03:03  : 69   07:07  : 53  \n 02:02 :233   07:08  : 42   09:09  : 66   18:18  : 52  \n NA's  : 33   04:04  : 41   02:02  : 30   05:05  : 48  \n              07:09  : 22   07:09  : 14   05:06  : 22  \n              (Other):142   08:08  :  9   (Other):119  \n              NA's   : 23   (Other): 20   NA's   :  5  \n\n\nTo simulate random data sets we need to start off by determining what allele frequencies you may want. I’m going to use the stratum-level frequencies from the example data set. Here is what these look like.\n\nsuppressPackageStartupMessages( library(tidyverse) )\nlibrary(DT)\nfreqs <- frequencies(arapat, stratum=\"Population\")\nhead(freqs)\n\n  Stratum Locus Allele Frequency\n1     101  LTRS     01 0.2777778\n2     101  LTRS     02 0.7222222\n3     101   WNT     01 1.0000000\n4     101    EN     01 0.6111111\n5     101    EN     03 0.3888889\n6     101    EF     01 0.7142857\n\n\nthough the whole data set has 700 rows!\nWhat I’m going to do is to create a random dataset from these frequencides. This dataset will have 20 populations (I’ll just grab the first 20 Stratum from this frequency matrix).\n\nfreqs %>%\n  filter( Stratum %in% unique(freqs$Stratum)[1:20] ) -> sim_freqs\nsummary(sim_freqs)\n\n   Stratum             Locus              Allele            Frequency     \n Length:370         Length:370         Length:370         Min.   :0.0500  \n Class :character   Class :character   Class :character   1st Qu.:0.1500  \n Mode  :character   Mode  :character   Mode  :character   Median :0.3500  \n                                                          Mean   :0.4297  \n                                                          3rd Qu.:0.7000  \n                                                          Max.   :1.0000  \n\n\nAnd we can take a quick look at the frequencies across populations for, say MP20 as:\n\nsim_freqs %>%\n  filter( Locus == \"MP20\", Stratum %in% unique(Stratum)[1:5] ) %>% \n  ggplot( aes(Allele,Frequency)) + \n  geom_bar( stat=\"identity\", position=\"dodge\" )  + \n  facet_grid( Stratum ~ .) + \n  theme_bw()\n\n\n\n\nOK. Now, lets take a look at how we can make a random population. The make_population() function takes a frequency matrix and creates random individuals. Here is an example.\n\nfake101 <- make_population( sim_freqs %>% filter(Stratum==\"101\"), N=100 )\n\nWarning in make_loci(f, N, F): Your allele frequencies do not add to 1.0. The\ndifference of 3.70074341541719e-17 will be partioned across all noted alleles\n\nhead(fake101)\n\n  Population ID   AML  ATPS    EF    EN  LTRS  MP20   WNT   ZMP\n1        101  1 08:08 02:02 01:01 01:03 01:02 02:13 01:01 01:01\n2        101  2 08:11 02:02 01:01 01:01 02:02 13:13 01:01 01:01\n3        101  3 08:11 02:09 01:02 01:03 01:02 12:12 01:01 01:01\n4        101  4 08:11 02:04 01:01 01:01 02:02 12:14 01:01 01:01\n5        101  5 08:11 02:02 01:01 01:03 02:02 12:12 01:01 01:01\n6        101  6 11:11 02:04 01:02 01:01 01:02 12:12 01:01 01:01\n\n\nThe frequencies should be pretty close to the real ones. Compare the LTRS locus allele frequencies from the simualted data\n\nfrequencies( fake101,loci = \"LTRS\") \n\n  Locus Allele Frequency\n1  LTRS     01      0.28\n2  LTRS     02      0.72\n\n\nand the real data\n\nsim_freqs %>% filter(Locus==\"LTRS\", Stratum==\"101\")\n\n  Stratum Locus Allele Frequency\n1     101  LTRS     01 0.2777778\n2     101  LTRS     02 0.7222222\n\n\nPretty close. So using this approach, we can make all kinds of allele random populations. You just need to figure out the allele frequency matrix and then pass that to the appropriate functions."
  },
  {
    "objectID": "posts/2023-01-12-Right-Sizing-Sequences/index.html",
    "href": "posts/2023-01-12-Right-Sizing-Sequences/index.html",
    "title": "Right Sizing the Sequences",
    "section": "",
    "text": "There is a necessity to figure out how much of your data you should be using for each step. It is a balancing act where we need to simultaneously:\nHowever, it is not always a priori knowable how much of the data to use."
  },
  {
    "objectID": "posts/2023-01-12-Right-Sizing-Sequences/index.html#smaller-subsets",
    "href": "posts/2023-01-12-Right-Sizing-Sequences/index.html#smaller-subsets",
    "title": "Right Sizing the Sequences",
    "section": "Smaller Subsets",
    "text": "Smaller Subsets\nSo it appears that taking all the data to make an assembly may be problematic for a few different reasons:\n\nIt will take a shit ton of time (that is technical measure of quantity reserved for only the most important and magnificently large collections of items).\nIt may produce a much too many contigs to be generally informative.\n\nSo I set up some subsets of the data to see how long it will take to do smaller amounts.\nHere some R code that I wrote to just take a fractional subset of the sequences from each individual and, using the program seqtk make a new set of data in a different folder.\n\nrm(list=ls())\npct <- \"0.025\"\nfolder <- \"./all0025/\"\n\nfiles <- list.files(\"all\",pattern=\"F.fq.gz\")\n\nfor( i in 1:length(files) ) {\n    file <- files[i]\n    tmp <- strsplit(file, split=\"\\\\.\")[[1]]\n    ofile <- paste( paste(tmp[1],tmp[2],sep=\"\"), tmp[3],tmp[4], sep=\".\")\n    cmd <- paste( \"seqtk sample ./all/\",file,\" \", \n                  pct, \" > \", folder, \" \", ofile, sep=\"\")\n    system(cmd)\n    cat( format(i/length(files), digits=3), \" \", ofile, \"\\n\")\n}\n\nUsing this, I set up random subsets of the data for:\n\n10% of each individuals genome.\n5% of each individuals genome.\n2.5% of each individuals genome."
  },
  {
    "objectID": "posts/2021-12-21-craft-rstudio-distill-post/craft-rstudio-distill-post.html",
    "href": "posts/2021-12-21-craft-rstudio-distill-post/craft-rstudio-distill-post.html",
    "title": "Craft + RStudio + Distill = Post",
    "section": "",
    "text": "So the first thing to do was to set up a staging place to save raw markdown files. Once I had that, I moved the rendering of this website from the “push the button on the build pane in RStudio to”run this script.”\nThis script is in the rood directory of the site and does the following steps:\n\nfinds all markdown files in the _toImport folder. For each file it:\n\n\nLoads in the file\nUses the first line as the metadata title:\nUse the first paragraph as the metadata description:\nCreates a new distill::create_post() with title and modification date for the markdown file.\nRemoves boilerplate stuff form new post and puts in content from the markdown file.\nAdds content to the metadata (extended author info and featured image components).\nRenames post to index.Rmd to make it easier to link in (I wish this was an option in distill).\nRenders the markdown.\nDeletes original markdown file.\n\n\nAfter finishing up, it then renders the entire site.\n\nHere is the script.\n\n#' This file is how I'll build the site.\n#' \nrm( list=ls() )\n\n\n# load in and convert any of the markdown stuff in _toImport into \n#  distill articles.\nfor( file in list.files(\"_toImport\", pattern = \"*.md\", full.names = TRUE) ) { \n  \n  # find previous stuff\n  raw <- readLines( file )\n  date <- stringr::str_split( file.info(file)$mtime , \n                              \" \", \n                              simplify = TRUE)[,1] \n  title <- stringr::str_remove( raw[1], \"# \") \n  description <- raw[3]\n  contents <- paste( raw[ -1 ], collapse=\"\\n\")\n  \n  # make new post  will create \n  filetitle <- gsub(\"[[:punct:][:blank:]]+\", \"-\", title ) \n  filetitle <- tolower(filetitle)\n  orig_title <- paste( \"_posts/\", \n                       date, \"-\", \n                       filetitle, \"/\", \n                       filetitle,\".Rmd\", \n                       sep=\"\" )\n  \n  distill::create_post( filetitle, \n                        date = date,\n                        edit = FALSE )\n  \n  raw_post <- readLines( orig_title )\n  raw_post[2] <- paste( \"title: \\\"\", title, \"\\\"\" )\n  raw_post[4] <- paste( \"  \", description, sep=\" \")\n  raw_post[7] <- \"    url: https://dyerlab.org\\n    affiliation: Center for Environmental Studies\\n    affiliation_url: https://ces.vcu.edu\\n    orcid_id: 0000-0003-4707-3453\"\n  raw_post[8] <- paste( raw_post[8], \"preview: featured.png\", sep=\"\\n\")\n  raw_post <- c( raw_post[1:13], contents ) \n  raw_post_output <- paste( raw_post, collapse=\"\\n\")\n  \n  new_file <- paste( \"_posts/\", \n                     date, \"-\", \n                     filetitle, \"/\", \n                     \"index.Rmd\", sep=\"\" )\n  writeLines( raw_post_output, \n              con = new_file )\n  \n  # clean up the posts\n  unlink( orig_title )\n  unlink( file ) \n  \n  rmarkdown::render( new_file )\n}\n\n# clean up any of the crap on the site and render the whole thing.\nsystem( \"find . -type f -iname '.DS_Store' -delete\")\nrmarkdown::render_site(\".\")\n\nWhat I do not do is push through all the git actions to upload it. I think I’ll just do that manually.\nHere is an example of the first Craft \\(\\to\\) Distill posting."
  },
  {
    "objectID": "posts/2022-08-16-xcode-select/index.html",
    "href": "posts/2022-08-16-xcode-select/index.html",
    "title": "xcrun issues on Ventura Beta",
    "section": "",
    "text": "I’m running some of the beta versions of the next MacOS & iPadOS for development purposes. I ran across the following issue on a laptop when trying to work on a git repository for teaching.\nWhen checking on the status of the repo,\ngit status\nit gave me the following error.\nxcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\nI noticed that the laptop did not have a version of Xcode on it, so I downloaded it and installed it. Same problem.\n[➜  ~/ xcode-select --install\nxcode-select: note: install requested for command line developer tools\nIt turns out that you need to also tell the OS to install the command line tools. I had thought they were previously installed when you installed Xcode but apparently, the OS needs to be pointed at the proper binaries.\nTo do this, first reset the system and then switch it over to the new beta version of Xcode.\n➜  ~ sudo xcode-select --reset\nPassword:\n➜  ~ sudo xcode-select --switch /Applications/Xcode-beta.app \nPerfect, now it works exactly as it should."
  },
  {
    "objectID": "posts/2015-09-04-installing-gitbook-on-osx/installing-gitbook-on-osx.html",
    "href": "posts/2015-09-04-installing-gitbook-on-osx/installing-gitbook-on-osx.html",
    "title": "Installing Gitbook on OSX",
    "section": "",
    "text": "I am in various stages of writing technical texts using R/RStudio/knitr and have been looking for some methods that help in this process. My goals are to be able to:\n\nMaintain a single source tree that can produce the text (including graphics, statistical analyses, etc). easily\nBe able to produce high quality typesetting\nBe able to easily make epub\nInclude both Code and output in the text.\n\nI’ve just run across Gitbook and it looks like a good option, particularly with the help of the R package Rgitbook. Here is a bit of work that I had to do to get things going on my machine.\n\nYou will need to make sure you have XCode installed (get it from Apple) for all the building tools. If you’ve had previous versions of XCode on your machine, you may need to reset xcode-select as:\nsudo xcode-select -s /Applications/Xcode.app/Contents/Developer/\n\n\nDownload Node.js from their site.\nIn R, install devtools and then require(“devtools”) and install_github(“jbryer/Rgitbook”)\nTry to install it as per the instruction here. If this doesn’t help, what I had to do was:\n\nTry sudo npm install gitbook -g\nIf this fails, you need to clean the npm cache and figure out what the problems were. Depending upon your error message you may need to:\n\nClean up any locks: sudo chown -R $(whoami) ~/.npm/_locks\nClean the cache\nsudo npm cache clean\n\nThen install sudo npm install gitbook-plugins -g and sudo npm install gitbook-cli -g and you should be good.\n\nYou should be able to go to R and require(Rgitbook) and then checkForGitbook() and get normal feedback.\n\nNow you have it installed, you should go see http://jason.bryer.org/Rgitbook/ for how to use it. Good luck! It seems like this R package hasn’t been updated in a while. I hope it isn’t stale, it looks pretty interesting."
  },
  {
    "objectID": "posts/2023-01-25-A-10Percent-Full-Data-Run/index.html",
    "href": "posts/2023-01-25-A-10Percent-Full-Data-Run/index.html",
    "title": "Crashing dDocent with Reduced Representations",
    "section": "",
    "text": "Start a new screen session\nSo this time I made a small representation of the overall sequences, using 10% of each individuals reads.\nRun this, it takes about 14 hours.\nThen I’ll fire up the srun\nAfter which I’m assigned to processor 13 and I’ll move the file to its own directory\nAnd zip it for [[dDocent]]\nTook it down from 192G -> 32G"
  },
  {
    "objectID": "posts/2023-01-25-A-10Percent-Full-Data-Run/index.html#failed---died-again",
    "href": "posts/2023-01-25-A-10Percent-Full-Data-Run/index.html#failed---died-again",
    "title": "Crashing dDocent with Reduced Representations",
    "section": "Failed - Died again",
    "text": "Failed - Died again\n\nLook ma! No Contigs.\n\nNow sit back, relax, and wait for your analysis to finish\nsed: can\\'t read reference.fasta.original: No such file or directory\n\ndDocent assembled 116460741 sequences (after cutoffs) into 0 contigs\ndDocent has finished with an analysis in /lustre/home/rjdyer/clemgu/samples/small\n\ndDocent started Thu Jan 26 09:30:49 EST 2023\ndDocent finished Thu Jan 26 18:34:36 EST 2023\n\ndDocent 2.9.4\nThe 'd' is silent, hillbilly.\nSo, the problem here is that I’ve been putting all the random sequences into a single individual and the assembly is dying because it is looking for stuff that is present in more than X number of individuals."
  },
  {
    "objectID": "posts/2016-06-07-pcr-gods/pcr-gods.html",
    "href": "posts/2016-06-07-pcr-gods/pcr-gods.html",
    "title": "PCR Gods",
    "section": "",
    "text": "So true. Thanks Sketching Science."
  },
  {
    "objectID": "posts/2018-01-29-ces-faculty-meeting/ces-faculty-meeting.html",
    "href": "posts/2018-01-29-ces-faculty-meeting/ces-faculty-meeting.html",
    "title": "CES Faculty Meeting",
    "section": "",
    "text": "Welcome Back!"
  },
  {
    "objectID": "posts/2015-08-27-merging-data-frames/merging-data-frames.html",
    "href": "posts/2015-08-27-merging-data-frames/merging-data-frames.html",
    "title": "Merging data frames",
    "section": "",
    "text": "In R, there is often the need to merge two data.frame objects (say one with individual samples and the other with population coordinates. The merge() function is a pretty awesome though it may take a little getting used to.\nHere are some things to remember:\n\nYou need to have two data.frame objects to merge\nThe first one in the function call will be the one merged _on-to _the second one is added to the first.\nEach will need a column to use as an index—it is a column that will be used to match rows of data. If they are the same column names then the function will do it automagically, if no common names are found in the names() of either data.frame objects, you can specify the columns using the optional by.x= and by.y= function arguments.\n\n\nHere is an example. I’m going to load in some data from the\npopgraph library. First, I’ll load up the library and hten grab the population meta data for the lophocereus data set we analyzed in Dyer & Nason (2004).\nrequire(popgraph)\ndata(baja)\nsummary(baja)\n    Region     Population    Latitude       Longitude     \n Baja  :16   BaC    : 1   Min.   :22.93   Min.   :-114.7  \n Sonora:13   Cabo   : 1   1st Qu.:24.45   1st Qu.:-112.6  \n             CP     : 1   Median :27.95   Median :-111.8  \n             Ctv    : 1   Mean   :27.33   Mean   :-111.8  \n             ELR    : 1   3rd Qu.:29.59   3rd Qu.:-110.7  \n             IC     : 1   Max.   :31.95   Max.   :-109.5  \n             (Other):23                                   \n\nThe graph itself has nodes indicated as populations and perhaps we are interested in plotting node size as a function of spatial location. We can grab the names and sizes from the popgraph object (it is a kind of igraph ) by:\ndata(lopho)\ndf.nodes <- data.frame( Population=V(lopho)$name, Size=V(lopho)$size )\nsummary(df.nodes)\n   Population      Size       \n BaC    : 1   Min.   : 2.500  \n CP     : 1   1st Qu.: 5.291  \n Ctv    : 1   Median : 6.860  \n LaV    : 1   Mean   : 7.770  \n LF     : 1   3rd Qu.:10.925  \n Lig    : 1   Max.   :16.001  \n (Other):15\nNow we have baja and df.nodes as two data.frames and can merge them by their common column `Population`. If we merge df.nodesonto baja then we get the new data.frame:\nmerge( baja, df.nodes )\n   Population Region Latitude Longitude      Size\n1         BaC   Baja    26.59   -111.79 12.158810\n2          CP Sonora    27.95   -110.66  7.870725\n3         Ctv   Baja    29.73   -114.72  3.880886\n4         LaV   Baja    24.04   -109.99  3.533757\n5          LF Sonora    30.68   -112.27  8.472215\n6         Lig   Baja    25.73   -111.27  4.731355\n7          PL Sonora    30.39   -112.58  6.692795\n8         PtC   Baja    24.19   -111.15  4.684652\n9         PtP   Baja    29.03   -113.90 10.925375\n10     SenBas Sonora    31.95   -112.87  9.116705\n11       Seri Sonora    28.88   -111.96  2.500000\n12         SG Sonora    29.40   -112.05 11.027530\n13         SI Sonora    29.75   -112.50 11.521450\n14        SLG   Baja    29.59   -114.40  5.955645\n15         SN Sonora    28.82   -111.80  8.325785\n16        SnE   Baja    24.45   -110.70 11.828220\n17        SnF   Baja    30.76   -114.73  6.325655\n18        SnI   Baja    27.29   -113.02  5.466695\n19        StR   Baja    24.91   -111.62  6.859545\n20         TS Sonora    28.41   -111.37 16.001165\n21        TsS   Baja    23.58   -110.34  5.290570\nbut if we do it the other way, we get:\nmerge(df.nodes,baja)\n   Population      Size Region Latitude Longitude\n1         BaC 12.158810   Baja    26.59   -111.79\n2          CP  7.870725 Sonora    27.95   -110.66\n3         Ctv  3.880886   Baja    29.73   -114.72\n4         LaV  3.533757   Baja    24.04   -109.99\n5          LF  8.472215 Sonora    30.68   -112.27\n6         Lig  4.731355   Baja    25.73   -111.27\n7          PL  6.692795 Sonora    30.39   -112.58\n8         PtC  4.684652   Baja    24.19   -111.15\n9         PtP 10.925375   Baja    29.03   -113.90\n10     SenBas  9.116705 Sonora    31.95   -112.87\n11       Seri  2.500000 Sonora    28.88   -111.96\n12         SG 11.027530 Sonora    29.40   -112.05\n13         SI 11.521450 Sonora    29.75   -112.50\n14        SLG  5.955645   Baja    29.59   -114.40\n15         SN  8.325785 Sonora    28.82   -111.80\n16        SnE 11.828220   Baja    24.45   -110.70\n17        SnF  6.325655   Baja    30.76   -114.73\n18        SnI  5.466695   Baja    27.29   -113.02\n19        StR  6.859545   Baja    24.91   -111.62\n20         TS 16.001165 Sonora    28.41   -111.37\n21        TsS  5.290570   Baja    23.58   -110.34\nHope this helps."
  },
  {
    "objectID": "posts/2016-05-14-life-sciences-graduation/life-sciences-graduation.html",
    "href": "posts/2016-05-14-life-sciences-graduation/life-sciences-graduation.html",
    "title": "Life Sciences Graduation",
    "section": "",
    "text": "You’re about to be told one more time that you’re America’s most valuable natural resource. Have you seen what they do to valuable, natural resources? Have you seen a strip mine? Have you seen a clear-cut in a forest? Have you seen a polluted river? Don’t ever let them call you a valuable natural resource! They’re gonna strip mine your soul! They’re gonna clear-cut your best thoughts for the sake of profit, unless you learn to resist, ’cause the profit system follows the path of least resistance, and following the path of least resistance is what makes the river crooked!\n\nUtah Phillips"
  },
  {
    "objectID": "posts/2017-05-22-per-hour-population-growth/per-hour-population-growth.html",
    "href": "posts/2017-05-22-per-hour-population-growth/per-hour-population-growth.html",
    "title": "Per Hour Population Growth",
    "section": "",
    "text": "A great infographic of per-hour growth in major cities."
  },
  {
    "objectID": "posts/2023-02-16-github-reset-user/index.html",
    "href": "posts/2023-02-16-github-reset-user/index.html",
    "title": "Reset Github User for Push",
    "section": "",
    "text": "So I was working on a repository at home that I set up on another github acount, for another entity. In doing so, I clobbered my global github user and user.email values and as such when I tried to git push none of the changes would go because it could not authenticate. Instead I got this:\n\nrodney$ git push\nremote: Permission to dyerlab/DLabWebsite.git denied to windbunny.\nfatal: unable to access 'https://github.com/dyerlab/DLabWebsite.git/': The requested URL returned error: 403\n\nSo, what you have to do is reconfigure the username, user.email, and remote.origin.url to reset your user name for ssh/https pushing.\n\nrodney$ git config user.name dyerlab\nrodney$ git config user.email rjdyer@vcu.edu\nrodney$ git config remote.origin.url https://dyerlab@github.com/dyerlab/DLabWebsite.git\n\nThen the next time you push it (go Salt-n-Pepper), it will ask for your authentication token again. Enter it and you are good."
  },
  {
    "objectID": "posts/2016-07-10-evolution-2016-youtube-channel/evolution-2016-youtube-channel.html",
    "href": "posts/2016-07-10-evolution-2016-youtube-channel/evolution-2016-youtube-channel.html",
    "title": "Evolution 2016 Youtube Channel",
    "section": "",
    "text": "A large subset of the talks given at this year’s Evolution meeting are now available on Youtube.\n\nThe playlist is here as a Google Docs spreadsheet.\nThe channel is here on Youtube."
  },
  {
    "objectID": "posts/2016-01-08-congratulations-anna-tucker/congratulations-anna-tucker.html",
    "href": "posts/2016-01-08-congratulations-anna-tucker/congratulations-anna-tucker.html",
    "title": "Congratulations Anna Tucker",
    "section": "",
    "text": "Previous Dyerlab member, Anna Tucker, just got her thesis work accepted for publication in Auk. Be on the lookout for the following:"
  },
  {
    "objectID": "posts/2016-01-08-congratulations-anna-tucker/congratulations-anna-tucker.html#opportunistic-conspecific-brood-parasitism-in-a-box-nesting-population-of-prothonotary-warblers-protonotaria-citrea",
    "href": "posts/2016-01-08-congratulations-anna-tucker/congratulations-anna-tucker.html#opportunistic-conspecific-brood-parasitism-in-a-box-nesting-population-of-prothonotary-warblers-protonotaria-citrea",
    "title": "Congratulations Anna Tucker",
    "section": "Opportunistic conspecific brood parasitism in a box-nesting population of Prothonotary Warblers (Protonotaria citrea)",
    "text": "Opportunistic conspecific brood parasitism in a box-nesting population of Prothonotary Warblers (Protonotaria citrea)\n\nConspecific brood parasitism, while prevalent in some avian taxa, is easily overlooked in when it occurs low frequencies and therefore the ecology of this behavior has been only occasionally described in passerines. Here we describe the occurrence of conspecific brood parasitism (CBP) in a population of Prothonotary Warblers (Protonotaria citrea) breeding in nest boxes, demonstrate associated fitness costs, and investigate parasite strategy. We genotyped individuals at six microsatellite loci and used CERVUS to determine log-likelihood of maternity (LOD scores) for offspring and social mothers. We set critical cut-off LOD scores at 95% confidence for exclusion of the social mother and assignment of a parasite mother from the breeding population. Of 805 nestlings (233 family groups from 2009 to 2013), we found that 12.7% had incompatible genotypes with their social mother. Females with unrelated nestlings (hosts) fledged fewer biological offspring within the host year than non-host females despite fledging more total offspring, but being a host was not significantly associated with total reproductive success over five years of breeding. We were able to identify only ~30% of parasite females, suggesting that the majority of parasites may be floaters (i.e. non-nesters) in the population or nesting in nearby natural cavities. We found no evidence of host selection based on host age, arrival at the breeding site, or nest box productivity in the previous year. This opportunistic behavior is likely facilitated by the nesting ecology of this population, in that nest sites are limited, conspicuous, and relatively dense. Future studies investigating CBP in populations using natural cavities can help elucidate the drivers of this behavior."
  },
  {
    "objectID": "posts/2016-01-15-chapter-1-learning-r/chapter-1-learning-r.html",
    "href": "posts/2016-01-15-chapter-1-learning-r/chapter-1-learning-r.html",
    "title": "Chapter 1 Learning R",
    "section": "",
    "text": "Here are the presentations for Chapter 1: Learning R from the upcoming text Applied Population Genetics. More information on this text can be found here."
  },
  {
    "objectID": "posts/2019-03-08-rstudio-server-on-ubuntu/rstudio-server-on-ubuntu.html",
    "href": "posts/2019-03-08-rstudio-server-on-ubuntu/rstudio-server-on-ubuntu.html",
    "title": "RStudio Server on Ubuntu",
    "section": "",
    "text": "Ubuntu server is a nice platform for server-related activities. Here is a short tutorial of how I updated my most current version to the latest available by rstudio.org. Here is how I got it going.\nIf this is your first install, you need to grab the gdebi stuff\nsudo apt-get install gdebi-core \nNext download the latest deb from rstudio. I typically like to try out the preview release, often stable enough to get what you want done while at the same time highlighting the latest features. When writing, it was the 1.2.1321 version.\nwget https://s3.amazonaws.com/rstudio-ide-build/server/trusty/amd64/rstudio-server-1.2.1321-amd64.deb\nMake sure to check the md5sum!\nIf you already have it running, stop it with\nsudo rstudio-server stop\nthen install the new version\nsudo gdebi rstudio-server-1.2.1321-amd64.deb \nThis went out and grabbed some other libraries and installed everything for me then turned it back on. Since I had it already installed, that was the end of it. If this is the first time you are installing it, you can configure it following the installation guide here.\n\nRichmond, Virginia"
  },
  {
    "objectID": "posts/2016-10-03-dyer-envs-research-talk/dyer-envs-research-talk.html",
    "href": "posts/2016-10-03-dyer-envs-research-talk/dyer-envs-research-talk.html",
    "title": "Dyer ENVS Research Talk",
    "section": "",
    "text": "Here are my slides from the talk I gave in Dr. Fox’s Survey of Environmental Studies course."
  },
  {
    "objectID": "posts/2015-12-02-laboratory-move/laboratory-move.html",
    "href": "posts/2015-12-02-laboratory-move/laboratory-move.html",
    "title": "Laboratory Move",
    "section": "",
    "text": "The Dyer laboratory is moving! I don not know the final destination, but it has been verified that the current space is unusable. After 31 months of not having a functional laboratory…"
  },
  {
    "objectID": "posts/2015-01-23-turning-in-assignments-via-google-sharing/turning-in-assignments-via-google-sharing.html",
    "href": "posts/2015-01-23-turning-in-assignments-via-google-sharing/turning-in-assignments-via-google-sharing.html",
    "title": "Turning In Assignments via Google Sharing",
    "section": "",
    "text": "If you use Google Docs for your writing, there are several cool tricks you can use to increase your efficiency. Here is one thing that has made it much easier when it comes to turning in assignments. Previously, one would create a document in some word processor, work on it, put it on a thumb drive, take it home and work on it, take it back to school, perhaps a lab computer, maybe it is also worked on in the library, etc. Eventually, you finish the document and then to turn it in you can either print it off (got to go find a printer or where I put that extra paper) or email it in. This last option is terrible if you have a large class!\nIf you are using Google Docs, you can just share it with the instructor. In the sharing options, you can designate that you share with someone but only allow them to make “suggestions”. This keeps the integrity of your document in place while allowing another person to mark it up. Once you share it, they can open it and write in it but any and all changes to the document are indicated via a highlight color. Since both of you are working on the document, there is no need to email it back and forth, there is only one document.\nHere is a short video how that is done if you need more visual input."
  },
  {
    "objectID": "posts/2016-04-20-layered-maps-in-r-using-ggplot-of-course-8230/layered-maps-in-r-using-ggplot-of-course-8230.html",
    "href": "posts/2016-04-20-layered-maps-in-r-using-ggplot-of-course-8230/layered-maps-in-r-using-ggplot-of-course-8230.html",
    "title": "Layered Maps in R Using GGPlot of course 8230",
    "section": "",
    "text": "A very cool writeup on making blow out maps.\n\nhttp://urbandemographics.blogspot.co.uk/2016/04/creating-tilted-and-stacked-maps-in-r.html"
  },
  {
    "objectID": "posts/2013-02-01-restriction-enzymes-for-aflps/restriction-enzymes-for-aflps.html",
    "href": "posts/2013-02-01-restriction-enzymes-for-aflps/restriction-enzymes-for-aflps.html",
    "title": "Restriction Enzymes for AFLPs",
    "section": "",
    "text": "The key to the AFLP protocol is to be able to digest two restriction enzymes (RE’s) simultaneously and be able to ligate onto these sticky ends primers of known concentration. When you purchase new primers, you need to aliquot out usable volumes because repeated freeze/thaw cycles reduce RE efficiency. Here are some guidelines:\n\nOrder from NEB (http://neb.com), they are the shiznit (n.b., that is a technical term).\nDo not order the MOST CONCENTRATED but be reasonable. We typically do not work in the volume of needing 100,000 U/ml, be reasonable.\nWhen you receive the shipment from NEB, aliquot and dilute such that we get 5 U in 20µl putting in 2µl stock (e.g., shoot for 2.5 U/µl).\nTemplate DNA should be no more than 300 ng. We DO NOT need a lot of template to start with."
  },
  {
    "objectID": "posts/2017-02-20-r-post-of-the-day/r-post-of-the-day.html",
    "href": "posts/2017-02-20-r-post-of-the-day/r-post-of-the-day.html",
    "title": "R Post of the Day",
    "section": "",
    "text": "Fancy pie chart (thanks, yihui, you are a genius):\npar(mar = c(0, 1, 0, 1))\npie(\n  c(280, 60, 20),\n  c('Sky', 'Sunny side of pyramid', 'Shady side of pyramid'),\n  col = c('#0292D8', '#F7EA39', '#C4B632'),\n  init.angle = -50, border = NA\n)"
  },
  {
    "objectID": "posts/2021-05-23-spring-2021-landscape-genetics-workshop/spring-2021-landscape-genetics-workshop.html",
    "href": "posts/2021-05-23-spring-2021-landscape-genetics-workshop/spring-2021-landscape-genetics-workshop.html",
    "title": "Spring 2021 Landscape Genetics Workshop",
    "section": "",
    "text": "This spring, my Landscape Genetics Workshop will need to be held virtually via zoom. While that provides a set of unique challenges, it looks like this is facilitating a more diverse group of attendees, which is always beneficial. All course content is hosted on this site under Courses link.\nCan’t wait to start!"
  },
  {
    "objectID": "posts/2015-03-26-new-lab-member/new-lab-member.html",
    "href": "posts/2015-03-26-new-lab-member/new-lab-member.html",
    "title": "New Lab Member",
    "section": "",
    "text": "I just received verification that Jane Remfert has decided to join the Dyer lab in the fall as a new PhD student! AND she is interested in working on dogwood! Welcome!"
  },
  {
    "objectID": "posts/2021-02-09-dplyr-summarize-warnings/dplyr-summarize-warnings.html",
    "href": "posts/2021-02-09-dplyr-summarize-warnings/dplyr-summarize-warnings.html",
    "title": "dplyr summarize Warnings",
    "section": "",
    "text": "One of the few annoying things I find with dplyr lately is the addition of an experimental option where if you use something like,\ngroup_by(X) %>% \n  summarize( Val = mean(Y))\nit gives you an error message with something like.\n\nsummarise() has grouped output by ‘X’. You can override using the .groups argument.\n\nBut why would I want to ‘override’ that grouping dplyr::authors? Didn’t I just set the grouping? I would suspect that the majority of use cases are exactly like above (group_by() immediately by summarize()).\nWhile much of tidyverse is too verbose for most of my liking. I can do without messages like:\n\n\n\nmessages on tidyverse startup\n\n\nWell I finally figured out how to shut the first part up (still working on the second part). Just put the following code into your .Rprofile file for a global fix, or any code you are using on a per-file basis.\noptions( dplyr.summarise.inform = FALSE )\nNow if we could just find some way to not have to use include=FALSE in the chunk preamble or suppressPackageStartupMessages(library(dplyr)) just to load in a library without adding a bunch of crap to our markdown files."
  },
  {
    "objectID": "posts/2015-09-04-paris-2015/paris-2015.html",
    "href": "posts/2015-09-04-paris-2015/paris-2015.html",
    "title": "Paris 2015",
    "section": "",
    "text": "I just received the program for an upcoming conference I’m presenting at in Paris on 23-24 September. I’m really excited to see the other presenters and hear about their work on eco-design tools. It is being held at la Gaîté Lyrique and sponsored by ParisTech and the Vinci Corporation."
  },
  {
    "objectID": "posts/2021-12-14-moving-old-markdown-posts/moving-old-markdown-posts.html",
    "href": "posts/2021-12-14-moving-old-markdown-posts/moving-old-markdown-posts.html",
    "title": "Moving Old Markdown Posts",
    "section": "",
    "text": "OK, now that I have moved over most of the manuscripts from the previous site, it comes time to move over some of the older posts. Many of these posts are important as there is code and data associated with them that I’d like to have access to going forward.\nLike before, however, there is some futzing around that needs to be done. However, this time, I took a different appraoch. I was less concerned about keeping the category information and all of them were authored by myself, so what I did was:\n\nPick out a set of 100 or so entries to keep.\n\nMove them into a top-level folder called old_posts.\n\nRead them in, one at a time, and extracted the title and date.\nCreated a new post using distill::create_post() using that date and title.\n\nPasted the contents of the markdown (skipping all the YAML crazyness) on the end of the new post (n.b., did you know that you could use cat() to concatenate onto the end of a file on the filesystem? I didn’t!).\n\nSo here is the basic code I used for it.\n\nrm(list = ls())\nlibrary( distill )\nlibrary( stringr )\n\nfiles <- list.files(\n  path = \"old_posts\",\n  pattern = \"index.Rmd\",\n  recursive = TRUE,\n  full.names = TRUE\n)\n\nfor (file in files) {\n  print(file)\n  lines <- readLines(file)\n  \n  # find the date \n  idx <- grep( \"date: \", lines, fixed = TRUE)\n  date <- \"\"\n  \n  if (length(idx) == 1) {\n    date <- str_sub( lines[idx], 7, 16)\n  }\n  \n  # Find the second --- and put in the output type\n  idx <- grep(\"---\", lines, fixed = TRUE)\n  content <- \"\"\n  lines <- c(lines, \" \", \" \", \" \")\n  if (length(idx) == 2) {\n    content <- paste( lines[ (idx[2]+1):length(lines) ] , \n                      collapse = \"\\n\")\n  }\n  \n  # find the title\n  idx <- grep(\"title: \", lines, fixed=TRUE )\n  title <- \"No Title\"\n  if( length(idx)>0 ) { \n    title <- str_trim( gsub('[[:punct:] ]+', \n                            \" \", \n                            str_remove(lines[idx], \"title: \")))\n  }\n  \n  ofile <- str_replace_all( tolower(title),  \n                            pattern=\" \", \n                            replacement = \"-\" ) \n  nfile <- paste(date, ofile, sep=\"-\") \n  path <- paste(\"_posts/\",\n                nfile,\n                \"/\", \n                ofile, \n                \".Rmd\", sep=\"\")\n\n  if( !file.exists(path) ) { \n\n    distill::create_post( title[1], \n                          collection=\"posts\", \n                          date = date, \n                          date_prefix=date, \n                          edit = FALSE)\n    cat( content, \n         file = path, \n         append=TRUE, \n         sep=\"\\n\")  \n  }\n}\n\nBut the problem is that when we use distill::createpost(), it puts in the following default content into the markdown. And then I just appended the original content onto the end of it.\n\n\n\nDefault distill post content\n\n\nSo I did a quick global search and replace using my favorite TextMate and then ran the following code to render it all out and looking good.\n\nfor( file in list.files(path=\"_posts/\", \n                        pattern = \"*.Rmd\",\n                        recursive = TRUE,\n                        full.names = TRUE) ) { \n  \n  rmarkdown::render( file )  \n}\n\n\nQuestions?\n\n\n\nPeter Sellers"
  },
  {
    "objectID": "posts/2016-01-11-new-semester/new-semester.html",
    "href": "posts/2016-01-11-new-semester/new-semester.html",
    "title": "New Semester",
    "section": "",
    "text": "This semester has a ton of new content and opportunities in the Dyerlab. Here is a quick synopsis.\n\nTeaching Population Genetics, should be a ton of fun.\nTeaching the Distributed graduate seminar Landscape Genetics again.\nStarting a new eDNA project with VDOT and getting a new student associated with it.\nStarting a new RadSEQ project on Protonotary Warblers and getting a new student to start in the fall.\nStarting a new Landscape Genetics NSF-funded project on gypsy moths with the Johnson Lab. Need a technician for this one as well.\nThe text Applied Population Genetics should be released as an ebook.\nShould be finishing up both Jameson’s and Chitra’s theses and submitting them for publication.\nMoving into a new laboratory location and perhaps collapsing both our lab and the Verrelli lab into a single unit."
  },
  {
    "objectID": "posts/2018-07-23-setting-up-atom-for-pweave-or-what-the-what/setting-up-atom-for-pweave-or-what-the-what.html",
    "href": "posts/2018-07-23-setting-up-atom-for-pweave-or-what-the-what/setting-up-atom-for-pweave-or-what-the-what.html",
    "title": "Setting up Atom for Pweave Or What the what",
    "section": "",
    "text": "So as a way to expand some of the analytical tools we offer the students at my work, I’m developing a version of my Data Literacy course that will use Python as well as R. There is a lot of overlap in these two languages and both are of interest to our students as they develop their toolkits. This document walks through how to set up Pweave on your machine so you can engage in a little Literate Programming (trust me, it will make your life suck a lot less. To see how to set up Atom, see my previous post."
  },
  {
    "objectID": "posts/2018-07-23-setting-up-atom-for-pweave-or-what-the-what/setting-up-atom-for-pweave-or-what-the-what.html#literate-programming",
    "href": "posts/2018-07-23-setting-up-atom-for-pweave-or-what-the-what/setting-up-atom-for-pweave-or-what-the-what.html#literate-programming",
    "title": "Setting up Atom for Pweave Or What the what",
    "section": "Literate Programming",
    "text": "Literate Programming\n\n\nI believe that the time is ripe for significantly better documentation of programs, and that we can best achieve this by considering programs to be works of literature. Hence, my title Literate Programming.\n\n\nKnuth – 1992\n\n\nIf you think of it a bit, as data scientists, the documents and manuscripts we work on every day are just extensions of programs and scripts we use to do our work. However, in academia we are taught the process in entirely the wrong sequence. Traditionally, we are taught the following sequence.\n\nWe’ve are funneled by the primary interface for writing scientific documents–the word processor–into that monstrous chunk of software we use to crafted our tales about the data we were presenting. How many times have we started working on a new project and the first thing we do is fire up a editor and start an outline of a manuscript? We never really liked it but this was the main tool we were taught to use (and the crappy reference managers tacked onto them).\nIn a separate interface, we would perform our analyses. In my career, I’ve used:\n\nThat VAX machine over in the Math Department at UMSL. It ran SAS and I did most of my work in IML.\nOne-off software packages that worked on our ‘special’ kind of data we are working with. These were typically FORTRAN code written by some wizard at a far-off university. Anyone remember BioSYS from Swofford & Selander?\nWorkarounds in C (my own popgraph software is written in C).\nExtensions that could be shoved into Excel (GenAlEx is a good example of how far you can push VB).\nScripting languages such as R, Perl (no one uses this one any longer, which is probably a good thing), Python, Julia, etc.\n\nThen we would export the raw output to some kind of plotting software to make your graphics. I always hated this step, because inevitably, we’d have to come back and redo the graphics (higher DPI says the publisher) and we’d have to remember how we made it that last time as most of these interfaces are stupid point-and-click software packages.\n\nThe main problem is that any iteration of the manuscript would require manually going through the process or changing the text document, rerunning the analysis, then replotting the figures. Move this section up her and then go back through and make sure all your figure and table references are recovered.\nBut this is entirely upside-down! Instead of Communicate -> Analysis -> Visualize, our workflow should be more like:\n\n\n\nData science workflow\n\n\nWe should be data-focused, not manuscript focused!\n\n\nThe research manuscript is simply an advertisement of our research and the data, it IS NOT the research or data.\n\n\nDyer – Just now!"
  },
  {
    "objectID": "posts/2018-07-23-setting-up-atom-for-pweave-or-what-the-what/setting-up-atom-for-pweave-or-what-the-what.html#pweave",
    "href": "posts/2018-07-23-setting-up-atom-for-pweave-or-what-the-what/setting-up-atom-for-pweave-or-what-the-what.html#pweave",
    "title": "Setting up Atom for Pweave Or What the what",
    "section": "PWeave",
    "text": "PWeave\nPWeave is like SWeave (and its better version Knitr) on R. It is a tool that we can use to interdigitate our analysis and how we go about presenting it all in one place. This allows us to have a single document where we can have the data, the analyses, the output, and the verbiage that we use to describe what we are doing. This tight coupling of the data to the rest of the components helps in Reproducible Research.\nTo install Pweave, you need to have atom and python already configured. Then in Atom, install the following packages\n\nlanguage-weave\nHydrogen\nlanguage-markdown\nplatformio-ide-terminal\n\nNext, you can prepare a short script. Here is a fragment of one.\n\n\n\nRaw pweave document.\n\n\n\nWhat this does is mix in markdown text and code. If you have not used Markdown before, it is pretty straight forward. Here are some simple rules.\n\n\nA line with one or more # marks are headings.\nA word or bit of text between asterisks (e.g., *this*) are italicized.\nA word or bit of text between pairs of asterisks (e.g., **this**) are bold.\nLinks are placed in parentheses with the option to have specific word to be the link. [link](http://foo.bar)\nLists are done physically, new line with dash for unordered or new line with number as numeric.\n\nAll the python code must be within the bounds marked by the three backslashes. The code will be evaluated, from the top of the document to the bottom. You do not have to show the code for it to run.\nTo weave the document into HTML (we can do other formats as well but this gets us going, open the terminal and type:\npweave.exe test1.pmd\nAnd it should produce a document in the same folder but as an *.html file.\n\n\n\nWhich is pretty cool. Now, there are a lot more things you can do with markdown."
  },
  {
    "objectID": "posts/2015-07-28-congratulations-to-jameson-hinkle/congratulations-to-jameson-hinkle.html",
    "href": "posts/2015-07-28-congratulations-to-jameson-hinkle/congratulations-to-jameson-hinkle.html",
    "title": "Congratulations to Jameson Hinkle",
    "section": "",
    "text": "Jameson successfully defended his MS Thesis on eDNA techniques for identification of Atlantic Sturgeon. Jameson is now the twelfth graduate student to pass through the lab. It was great having him here and we look forward to seeing where he goes from here. Way to go!"
  },
  {
    "objectID": "posts/2015-07-29-compiling-the-gsl-library-for-osx/compiling-the-gsl-library-for-osx.html",
    "href": "posts/2015-07-29-compiling-the-gsl-library-for-osx/compiling-the-gsl-library-for-osx.html",
    "title": "Compiling the GSL Library for OSX",
    "section": "",
    "text": "I’ve been working on integrating the Swift language into my analysis workflow but much of what I do involves the GNU Scientific Libraries for matrix analysis and other tools. Here is a quick tutorial on how to install the GSL library on a clean OSX platform.\n\nIt is easiest if you have XCode installed. You can get this from the App Store for free. Go download it and install it.\nDownload the latest version of the GSL libraries. You can grab them by:\n\nLooking for your nearest mirror site listed at http://www.gnu.org/prep/ftp.html and connecting to it.\nOpen the directory gsl/ where all the versions will be listed. Scroll down and grab gsl-latest.tar.gz.\n\nOpen the terminal (Utilities -> Terminal.app) and type: cd ~/Downloads\nUnpack the archive by: tar zxvf gsl-latest.tar.gz then cd gsl-1.16/ (or whatever the version actually was, it will probably be some number larger than 1.16).\nInside that folder will be a README file (which you probably won’t read) and an INSTALL file (which you should read). In that folder it will tell you to: ./configure then make then sudo make install. This last command will require you to type in your password as it is going to install something into the base system.\nAll the libraries and header files will be installed into the /usr/local/ directory."
  },
  {
    "objectID": "posts/2015-03-31-install-rgeos-on-osx/install-rgeos-on-osx.html",
    "href": "posts/2015-03-31-install-rgeos-on-osx/install-rgeos-on-osx.html",
    "title": "Install rgeos on OSX",
    "section": "",
    "text": "There seems to be some nefarious conspiracy against packaging spatial R packages on the mac platform. Don’t quite understand it but it sucks. Here is how to install the rgeos package.\nIf you try the normal way, you get the following error:\ninstall.packages(\"rgeos\")\npackage ‘rgeos’ is available as a source package but not as a binary\nWarning in install.packages : package ‘rgeos’ is not available (as a binary package for R version 3.1.3)\nwhich is not very helpful. So here is a quick way to do that I use when I need to upgrade it or put it on a new machine.\n\nIf you do not have the developers tools from Apple, download them and install through the normal AppStore mechanisms. You will need to compile stuff from raw code for this to work.\nDownload and install the GDAL Complete package from KyngChaos. At the time of writing, it was version 1.11 (39.0 MB). If you are using Mavericks or later, you’ll have to probably change your security settings (System Preferences -> Security -> General) to “Allow apps downloaded from ‘anywhere’ to be installed. If everything works nicely (which I’ve never seen actually work), you should be able to do the following to install. Unfortunately, it always barfs on me.\ninstall.packages(“rgeos”, repos=“http://R-Forge.R-project.org”, type=“source”) trying URL ‘http://R-Forge.R-project.org/src/contrib/rgeos_0.3-9.tar.gz’ Content type ‘application/x-gzip’ length 238246 bytes (232 KB) opened URL ================================================== downloaded 232 KB\n\n\ninstalling source package ‘rgeos’ … configure: CC: clang configure: CXX: clang++ configure: rgeos: 0.3-8 checking for /usr/bin/svnversion… yes cat: inst/SVN_VERSION: No such file or directory configure: svn revision: checking for geos-config… no configure: error: geos-config not found or not executable. ERROR: configuration failed for package ‘rgeos’\nremoving ‘/Library/Frameworks/R.framework/Versions/3.1/Resources/library/rgeos’\n\nThe downloaded source packages are in ‘/private/var/folders/06/jmbn_ny94rs1nw19xclvdzqc0000gn/T/Rtmp9VCkBI/downloaded_packages’ Warning message: In install.packages(“rgeos”, repos = “http://R-Forge.R-project.org”, : installation of package ‘rgeos’ had non-zero exit status\n\n\nThis means that you need to actually compile the results. Download the latest sources from r-forge (use the *.tar.gz version). Open the terminal and:\ncd ~/Downloads\nR CMD INSTALL\n\n\nand you should see the following:\n\n<pre class=\"lang:default decode:true \">R CMD INSTALL rgeos_0.3-9.tar.gz --configure-args=\"--with-geos-config=/Library/Frameworks/GEOS.framework/unix/bin/geos-config\"\n\ninstalling to library ‘/Library/Frameworks/R.framework/Versions/3.1/Resources/library’\ninstalling source package ‘rgeos’ … configure: CC: clang configure: CXX: clang++ configure: rgeos: 0.3-8 checking for /usr/bin/svnversion… yes cat: inst/SVN_VERSION: No such file or directory configure: svn revision: configure: geos-config set to /Library/Frameworks/GEOS.framework/unix/bin/geos-config checking geos-config exists… yes checking geos-config executable… yes checking geos-config usability… yes configure: GEOS version: 3.4.2 checking geos version at least 3.2.0… yes checking geos-config clibs… yes checking for gcc… clang checking whether the C compiler works… yes checking for C compiler default output file name… a.out checking for suffix of executables… checking whether we are cross compiling… no checking for suffix of object files… o checking whether we are using the GNU C compiler… yes checking whether clang accepts -g… yes checking for clang option to accept ISO C89… none needed checking how to run the C preprocessor… clang -E checking for grep that handles long lines and -e… /usr/bin/grep checking for egrep… /usr/bin/grep -E checking for ANSI C header files… rm: conftest.dSYM: is a directory rm: conftest.dSYM: is a directory yes checking for sys/types.h… yes checking for sys/stat.h… yes checking for stdlib.h… yes checking for string.h… yes checking for memory.h… yes checking for strings.h… yes checking for inttypes.h… yes checking for stdint.h… yes checking for unistd.h… yes checking geos_c.h usability… yes checking geos_c.h presence… yes checking for geos_c.h… yes checking geos: linking with libgeos_c… yes configure: PKG_CPPFLAGS: -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include configure: PKG_LIBS: -L/Library/Frameworks/GEOS.framework/Versions/3/unix/lib -lgeos -L/Library/Frameworks/GEOS.framework/Versions/3/unix/lib -lgeos_c configure: creating ./config.status config.status: creating src/Makevars ** libs clang++ -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c dummy.cc -o dummy.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c init.c -o init.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c local_stubs.c -o local_stubs.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos.c -o rgeos.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_R2geos.c -o rgeos_R2geos.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_R2geosMP.c -o rgeos_R2geosMP.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_bbox.c -o rgeos_bbox.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_buffer.c -o rgeos_buffer.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_coord.c -o rgeos_coord.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_geos2R.c -o rgeos_geos2R.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_misc.c -o rgeos_misc.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_poly2nb.c -o rgeos_poly2nb.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_predicate_binary.c -o rgeos_predicate_binary.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_predicate_unary.c -o rgeos_predicate_unary.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_topology.c -o rgeos_topology.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_topology_binary.c -o rgeos_topology_binary.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_validate.c -o rgeos_validate.o clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/Library/Frameworks/GEOS.framework/Versions/3/unix/include -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I”/Library/Frameworks/R.framework/Versions/3.1/Resources/library/sp/include” -fPIC -Wall -mtune=core2 -g -O2 -c rgeos_wkt.c -o rgeos_wkt.o clang++ -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/Library/Frameworks/R.framework/Resources/lib -L/usr/local/lib -o rgeos.so dummy.o init.o local_stubs.o rgeos.o rgeos_R2geos.o rgeos_R2geosMP.o rgeos_bbox.o rgeos_buffer.o rgeos_coord.o rgeos_geos2R.o rgeos_misc.o rgeos_poly2nb.o rgeos_predicate_binary.o rgeos_predicate_unary.o rgeos_topology.o rgeos_topology_binary.o rgeos_validate.o rgeos_wkt.o -L/Library/Frameworks/GEOS.framework/Versions/3/unix/lib -lgeos -L/Library/Frameworks/GEOS.framework/Versions/3/unix/lib -lgeos_c -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation installing to /Library/Frameworks/R.framework/Versions/3.1/Resources/library/rgeos/libs ** R ** inst ** preparing package for lazy loading ** help *** installing help indices ** building package indices ** testing if installed package can be loaded\nDONE (rgeos)\n\n\nAnd your done."
  },
  {
    "objectID": "posts/2023-02-13-Mapping-SNPS/index.html",
    "href": "posts/2023-02-13-Mapping-SNPS/index.html",
    "title": "Mapping & SNP Calling",
    "section": "",
    "text": "Full Data\nSo the first pass for this process, I took the original raw data that was demultiplexed.\n\n\nReduced Representation"
  },
  {
    "objectID": "posts/2015-04-16-new-position/new-position.html",
    "href": "posts/2015-04-16-new-position/new-position.html",
    "title": "New Position",
    "section": "",
    "text": "It looks like I will be moving into the position of Assistant Director for the Center for Environmental Studies this year! Should be fun!"
  },
  {
    "objectID": "posts/2023-01-21-First-dDocent-Run/index.html",
    "href": "posts/2023-01-21-First-dDocent-Run/index.html",
    "title": "First dDocent Run",
    "section": "",
    "text": "You crash all the time, and sometimes it’s a really bad one, but sometimes it’s not so bad. - Lindsay Vonn\n\nSo I set this one up with all the data to make an assembly, map, and then call SNPs for all the individuals.\nIt crashed so bad that I didn’t even make a log of it."
  },
  {
    "objectID": "posts/2021-12-12-moving-manuscripts-from-hugo/moving-manuscripts-from-hugo.html",
    "href": "posts/2021-12-12-moving-manuscripts-from-hugo/moving-manuscripts-from-hugo.html",
    "title": "Moving Manuscripts from Hugo",
    "section": "",
    "text": "As part of moving over from Hugo to Distill, I need to move over all my manuscripts. While putting everything into Markdown is a good idea for portability, there does not seem to be a very quick way to translate YAML. IN this case, the old YAML looked like this (n.b., they are all .md files, not .Rmd files like distill likes so the syntax hightlighting will not look right):\n\n\n\nOldYAML\n\n\nWhich will need to be translated into the new YAML to resemble:\n\n\n\nNewYAML\n\n\nThis may not be that big of an deal but at the end of the day, I’ve got a ton of folders that each represent each manuscript I’ve published. I was able to get a lot of it done using some quick perl like this:\nperl -pi -e s/name =/name:/g file.md\nHowever, there is going to be a lot of pain associated with some of it (authors & categories sections). For that, I’ll have to run some R code. Here is how I did it.\n\nfiles <- list.files(path=\"../../_manuscripts\", \n                    recursive = TRUE,\n                    full.names = TRUE,\n                    pattern = \"index.md\")\n\nSo, for each of these files, I need to:\n\nLoad markdown file\nSave as Rmd\nUse some terminal magic to convert over yaml formatting.\n\nSo here it goes:\n\nfor( file in files ) { \n  newfile <- gsub(\".md\", \".Rmd\", file,perl = TRUE)\n  cmd <- paste(\"mv\",file, newfile )\n  system( cmd )\n}\n\nOK, so that was sufficient for me to get things good enough to compile. And it looks… meh.\n\n\n\nNailed it!\n\n\nI put all the manuscripts in its own category and subfolder but it has all the abstract shoved into the description. However, that causes some issues because some of the abstracts are long and it makes for an unreasonable view of the manuscripts.\n\nand none of the images are showing. Now we’ll have to go through it all and futz around to make it look good. Here is the whole salchicha.\n\nlibrary( yaml )\nfiles <- list.files(path=\"../../_manuscripts\", \n                    recursive = TRUE,\n                    full.names = TRUE,\n                    pattern = \"index.Rmd\")\n\nfor( file in files ) { \n  print(file)\n  # load in the YAML\n  old <- read_yaml( file )\n  \n  # Make the new file contents\n  new <- c(\"---\",\n           paste(\"title:\", as.yaml(old$title)),\n           paste(\"date:\", as.yaml(old$date ) ) )\n  \n  # make authors for post\n  pub_authors <- unlist( lapply( old$authors, \n                             FUN = function(x) { return(paste(\"- name:\", x))}))\n  new <- c(new, \n           \"authors:\",\n           pub_authors)\n  \n  # put authors, year and publication here.\n  year <- strsplit(old$date, \"-\",fixed = TRUE)[[1]][1]\n  pub <- old$publication\n  \n  description <- paste(\"description: |\")\n  description <- paste( \"   \", pub, year, \" \", sep=\". \")\n\n  new <- c(new,\n           \"description: |\",\n           description)\n  \n  # clean up the categories\n  if( \"categories\" %in% names(old) ) { \n    categories <- tolower( gsub( \"\\\"\", \"\", old$categories ) )\n    new <- c(new, \n             \"categories: \",\n             unlist( lapply( categories, \n                             FUN = function(x) { return(paste(\"-\", x))})))\n  }\n  \n  \n  \n  \n  # put in the Journal \n  if( length( old$publication) > 0 ) { \n    new <- c(new,\n             paste(\"journal: \", old$publication))\n  }\n  \n  if( \"doi\" %in% names( old ) ) { \n    new <- c(new,\n             paste(\"doi: \", old$doi ))\n  }\n  \n  \n  # if there is a bib\n  bibs <- list.files( dirname(file), \n                      pattern = \"*.bib\",\n                      full.names = TRUE)\n  if( length(bibs) == 1 ) { \n    cmd <- paste( \"mv\", \n                  bibs, \n                  paste( dirname(bibs),\n                         \"bibliography.bib\",\n                         sep=\"/\"))\n    system(cmd)\n    new <- c(new,\n             \"bibliography: bibliography.bib\" )\n  }\n  \n  \n  \n  #add end stuff\n  if( \"respository_url\" %in% names( old ) ) { \n    new <- c(new, \n             paste(\"repository_url:\",as.yaml(old$respository_url ) ) )\n  }\n  new <- c( new, \n            paste(\"output:\\n\",as.yaml(old$output)),\n            \"---\",\n            \"\")\n  new <- gsub(\"\\n\\n\", \"\\n\", paste( new, collapse=\"\\n\") ) \n  \n  \n    # put in links to PDF and doi if presnt\n  links <- \"\"\n  if( \"url_pdf\" %in% names( old ) ) { \n    url <- old$url_pdf \n    val <- paste( \"[![PDF Download](https://img.shields.io/badge/PDF-21B02C.svg)](\", url, \")\", sep=\"\")\n    links <- paste( links, val)\n  }\n  \n  if( \"doi\" %in% names( old ) ) { \n    url <- paste(\"https://doi.org\",old$doi, sep=\"/\")\n    val <- paste( \"[![ DOI \", \n                  old$doi, \n                  \"](https://img.shields.io/badge/DOI-474747.svg)](\",\n                  url,\n                  \")\", sep=\"\") \n    links <- paste( links, val )\n  }\n  \n  new <- c( new, links )\n  \n  \n  \n  # Add image if present\n  if( \"featured\" %in% names( old ) ) { \n    img <- paste(\"![](\",old$featured,\")\")\n    new <- c( new, \n              \"\",\n              img )\n  }\n  \n  if( \"description\" %in% names( old ) ) { \n    new <- c(new,\n             \"\",\n             \"## Abstract\",\n             \"\",\n             old$description )\n  }\n\n  #  Previously, I saved to a different file so as to not overwrite the important stuff.\n  #   Once it worked, then write over the old one.\n  # newfile <- paste( dirname(file), \"/manuscript.Rmd\", sep=\"\")\n  write(new, file=file)\n  rmarkdown::render(file)\n  \n}\n\nNow, I’ve just got to go clean up the old temporary files using something like:\n\nfind _manuscripts -iname manuscrip* -delete\n\n\nfor( file in list.files(path=\"../../_manuscripts\", \n                    recursive = TRUE,\n                    full.names = TRUE,\n                    pattern = \"index.Rmd\") ) { \n  rmarkdown::render( file )\n  }\n\n\n\n\nThe End"
  },
  {
    "objectID": "posts/2015-07-23-hello-r-markdown/hello-r-markdown.html",
    "href": "posts/2015-07-23-hello-r-markdown/hello-r-markdown.html",
    "title": "Hello R Markdown",
    "section": "",
    "text": "R Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\n\nsummary(cars)\n##      speed           dist       \n##  Min.   : 4.0   Min.   :  2.00  \n##  1st Qu.:12.0   1st Qu.: 26.00  \n##  Median :15.0   Median : 36.00  \n##  Mean   :15.4   Mean   : 42.98  \n##  3rd Qu.:19.0   3rd Qu.: 56.00  \n##  Max.   :25.0   Max.   :120.00\nfit <- lm(dist ~ speed, data = cars)\nfit\n## \n## Call:\n## lm(formula = dist ~ speed, data = cars)\n## \n## Coefficients:\n## (Intercept)        speed  \n##     -17.579        3.932\n\n\n\nIncluding Plots\nYou can also embed plots. See Figure @ref(fig:pie) for example:\n\npar(mar = c(0, 1, 0, 1))\npie(\n  c(280, 60, 20),\n  c('Sky', 'Sunny side of pyramid', 'Shady side of pyramid'),\n  col = c('#0292D8', '#F7EA39', '#C4B632'),\n  init.angle = -50, border = NA\n)\n\n\n\n\nA fancy pie chart."
  },
  {
    "objectID": "posts/2021-03-16-problems-with-rmarkdown-htmlwidgets/problems-with-rmarkdown-htmlwidgets.html",
    "href": "posts/2021-03-16-problems-with-rmarkdown-htmlwidgets/problems-with-rmarkdown-htmlwidgets.html",
    "title": "Problems with RMarkdown HTMLWidgets",
    "section": "",
    "text": "OK, so in working on various RMarkdown stuff, I‘ve just run across a problem with it no longer rendering HTMLWidget stuff in the recent upgrade. So if you use something like mermaid or leaflet in your xaringan presentation, it will show you the raw\n<div></div>\noutput instead of the actual widget. This is not an easy one to track down online because the RMarkdown & Xaringan Github sites do not address it. So I thought I would insert a thing here so I can find it next time I need it.\nAs it turns out, we need to set an option in the setup chunck as follows:\noptions(htmltools.preserve.raw = FALSE)\nThis will fix things until RStudio fixes the markdown problems and the world can get back to normal."
  },
  {
    "objectID": "posts/2013-06-03-updating-r-and-with-current-libraries/updating-r-and-with-current-libraries.html",
    "href": "posts/2013-06-03-updating-r-and-with-current-libraries/updating-r-and-with-current-libraries.html",
    "title": "Updating R and With Current Libraries",
    "section": "",
    "text": "If you work in R for very long on mac, there comes a time when you upgrade and the framework process looses all your libraries! In some sense this is pretty lame because you now have to install all these libraries again. However, it can be a blessing if you install packages in a willy-nilly fashion as you will only reinstall the ones you use most often. At any rate, it is kind of a pain. Here is what I’ve been doing about this to automate the process. The key here is that you need to do the first part before you upgrade.\n\nCurrent Library\nIn the old version of R, prior to updating you’ll want to save the libraries that you have installed. In R, this can be done as follows:\npkgs <- installed.packages()\npkgs <- names( is.na(pkgs[,4]))\nsave(pkgs,file=’~/Desktop/pkgs.rda’)\n \n\n\nInstall Updated R Version\nEither download the latest package or update your svn repository and rebuild R and install it. There are a lot of options for learning more about these options elsewhere on the web.\n\n\nInstall Missing Packages\nNow, in the new version of R, you can figure out which are installed by default and then take the differences from what you have and what the previous version had installed and then install them.\nnew_pkgs <- installed.packages()\nnew_pkgs <- names( is.na(new_pkgs[,4]))\nload(“~/Desktop/pkgs.rda”)\nto_install <- setdiff( pkgs, new_pkgs )\ninstall.packages( to_install )\nupdate.packages()\n\n \nAnd you should be done."
  },
  {
    "objectID": "posts/2017-01-10-new-job/new-job.html",
    "href": "posts/2017-01-10-new-job/new-job.html",
    "title": "New Job",
    "section": "",
    "text": "I have accepted and begun working as the Director of the Center for Environmental Studies at Virginia Commonwealth University. The Center is a chartered research center whose mission is to… Well, do whatever I think it will do to produce the best research and educational opportunities for our undergraduate and graduate students. We train applied scientists.\nThe Center has about 10 FTE faculty, a lot of which are shared among groups (e.g., half biology/half CES, half business/half CES, etc.) and several quality adjunct instructors. We have about 250 undergraduates, 40 Masters-level graduate students in the program, and several individuals with Ph.D. students in the Integrative Life Sciences program."
  },
  {
    "objectID": "posts/2016-02-21-denver-talk/denver-talk.html",
    "href": "posts/2016-02-21-denver-talk/denver-talk.html",
    "title": "Denver Talk",
    "section": "",
    "text": "I’m giving a seminar at the University of Denver on 22 February about my research program. Here is a link to a PDF version of the talk.\nPDF"
  },
  {
    "objectID": "posts/2022-08-25-GitHub-PAT/index.html",
    "href": "posts/2022-08-25-GitHub-PAT/index.html",
    "title": "GitHub Personal Access Tokens",
    "section": "",
    "text": "To create a new token in RStudio, you will be using some packages that you may not have on your machine already. No problem. Just follow the instructions below.\n\nOpen RStudio and select the R Console.\nType in the following command\n\ninstall.packages(\"usethis\")\ninstall.packages(\"credentials\")\nlibrary(usethis)\n\nNow create a token from Github by typing in the following command\n\ncreate_github_token()\n\nThis will open a verification window in a browser that will ask you to verify your GitHub credentials. Then it will dump you into the Personal Access Token settings page for your GitHub account.\n\nGenerate a new token and give it a name for its intended use.\n\nIt will produce this long access token (the ghp_B0… part. Copy that long access token, this is your key (n.b., this one is not valid after I made this page).\n\nNo go back into RStudio and type\n\ncredentials::set_github_pat(\"YOUR ACCESS TOKEN HERE\")\n\n\nYou should be able to check to see if your access token is set and all good by looking at the output from this command. You should s\n\ngit_sitrep()\n\nSomewhere in the output you should see something like:\n\n• Personal access token for 'https://github.com': '<discovered>'\n\nIf so, you are good!"
  },
  {
    "objectID": "posts/2017-05-22-vdot-progress-update/vdot-progress-update.html",
    "href": "posts/2017-05-22-vdot-progress-update/vdot-progress-update.html",
    "title": "VDOT Progress Update",
    "section": "",
    "text": "This is a short presentation on the progress for the VDOT eDNA project."
  },
  {
    "objectID": "posts/2021-03-03-population-graphs-swift-edition/population-graphs-swift-edition.html",
    "href": "posts/2021-03-03-population-graphs-swift-edition/population-graphs-swift-edition.html",
    "title": "Population Graphs Swift Edition",
    "section": "",
    "text": "So this spring, I’m going to make a large push at porting over the population graphs analyses (Dyer & Nason 2004) that I have in R to a version that runs as a native app on iOS/MacOS. The long-term goals here are to leverage the upcoming advances in Augmented Reality and LiDAR at the phone/glasses level that I suspect will be more mainstream by 2023 or so.\n\nBig Picture\nSo, in the long run, I’m looking to have a set of software that can do the following:\n\nEstimate a population graph from genotype data.\n\nWrite custom SVD routines linked with Accelerate.\nWrap in GeneticStudio interface for Genotype & Project CRUD.\n\nVisualize the graph in either 2D (SpriteKit), 3D (SceneKit), or in AR (ARKit).\n\nForce directed estimation of location in 2-space\nExpand to 3-space\nDevelop individual physics models for dynamical system in SpriteKit & SceneKit\n\nComprehensive set of network-based analytical output for local (node- and edge- centric) as well as global parameters.\nOverlay spatial network on GeoTiff for prevalence/avoidance of features.\nChromosome walking - Use engine to analyze how population covariance changes along stretches of chromosomes from SNP-like data.\nPopulation Simulation - Develop stochastic simulation background that is visualized using dynamical population graphs for hypothesis testing, where we specify a model and"
  },
  {
    "objectID": "posts/2018-01-31-csbc-faculty-meeting/csbc-faculty-meeting.html",
    "href": "posts/2018-01-31-csbc-faculty-meeting/csbc-faculty-meeting.html",
    "title": "CSBC Faculty Meeting",
    "section": "",
    "text": "Welcome back!"
  },
  {
    "objectID": "posts/2015-08-04-dyerlab-temporary-headquarters/dyerlab-temporary-headquarters.html",
    "href": "posts/2015-08-04-dyerlab-temporary-headquarters/dyerlab-temporary-headquarters.html",
    "title": "Dyerlab Temporary Headquarters",
    "section": "",
    "text": "Two NSF grants submitted! Taking a bit of time out for some programming and to set up Dyerlab South (in the vicinity of 24.9515812,-80.5807652)…"
  },
  {
    "objectID": "posts/2022-09-30-Irreversibility/index.html",
    "href": "posts/2022-09-30-Irreversibility/index.html",
    "title": "Irreversibility of Structure & Diversity Statistics",
    "section": "",
    "text": "Non-uniqueness of frequency spectra resulting in identical among population (\\(F_{st}\\)) and within population (\\(H_t\\)) estimates of genetic diversity as demonstrated from allele frequencies for twelve populations for the first two alleles from a three allele locus.\n\n\nThe mapping of genotypes -> estimates of both within locale diversity and among local structure are a fundamental component of population and landscape genetic analyses, and indeed the formulation for our understanding of how evolution proceeds.\nA common method for measuring structure is from Sewell Wright ’s \\(F_{st}\\) statistic and its offspring. At heart, the parameters is defined as the fraction of the total genetic variance that can be contributed to individuals being in different populations. This parameter has many offspring but in its most general form, it can be defined as the ratio of the among locale variance in allele frequencies standardized by the variance in the global allele frequencies. For a single locus, this becomes.\n\\[\nF_{ST} = \\frac{\\sum_{i=1}^\\ell \\sigma_{q_{S(i)}}^2}{\\sum_{i=1}^\\ell \\left[  q_{T(i)} (1 - q_{T(i)}) \\right]}\n\\]\nOriginally, Wright suggested that this should probably not be thought of in the way that most of us see ‘differentiation’. Namely,\n\nThe fixation index [Fst] is thus not a measure of the degree of differentiation in the sense implied in the extreme case by the absence of any common allele. It measures differentiation within the total array in the sense of the extent to which the process of fixation has gone toward completion.1\n\nTo demonstrate this, he showed the following examples. Of note, compare cases 1, 6, 7, & 8 in the following table, all of which have the same value for Fst but have different allele spectra (in particular, see 7 & 8, which have subsets of populations that have Fst = 0!\n\n\n\nTable 3.1 from Wright’s 4th volume on the variability within and among natural populations.\n\n\nTo view this in a more broad context, we can easily show that for any particular value of Fst, we can define a similarly large number of population configurations that results in both the same amount of overall genetic structure (\\(F_{st}\\)) and the same amount of within strata diversity (\\(H_t\\)).\nThere are two examples that highlight some of the challenges for this.\n\nIt is possible to fix the allele frequencies and shuffle the labels. For example, the identity of the specific locale relative to the inherent allele frequencies is not unique. Consider the case where Population A has p=0.3 at a locus and Population B has p=0.7 After some perturbation in the system or iterating across generations, we may have the situation where Population A has p = 0.7 and Population B has p = 0.3. Measuring structure or diversity within and among these pairs of pops will yield identical values even though the relative positions of each population has been swapped in allele space.\nMore generally, for any given value of diversity and structure, we can find an infinite set of populations that can yield the same estimates. The featured image on this page is an example with K=12 populations for a single 3-allele locus. The plots are of the first two allele frequencies and the estimates of both diversity and differentiation are the same to the first 3 decimal points (n.b., we can be more stringent but I think this makes the point close enough).\n\nIn both of these situations, the relative position and arrangements of the individual populations are not unique. Now, this may not be an issue, if the kinds of questions you are working with do not rely upon interpreting the relative positions of populations in allele space. However, for many population, conservation, and landscape type studies, it is exactly the relative positions of populations that are the focus of the study. As such, to ignore the irreversibility of structure and diversity statistics is to pass up on potentially valuable insights on the species and systems you are working with.\n\n\n\n\nFootnotes\n\n\nWright, S. 1978. Evolution & the Genetics of Populations 4: Variability within and among natural populations. University of Chicago Press. .↩︎"
  },
  {
    "objectID": "posts/2019-02-13-uva-center-for-public-health-genomics/uva-center-for-public-health-genomics.html",
    "href": "posts/2019-02-13-uva-center-for-public-health-genomics/uva-center-for-public-health-genomics.html",
    "title": "UVa Center for Public Health Genomics",
    "section": "",
    "text": "Today, I’ve been invited to give a talk at the University of Virginia Center for Public Health Genomics. I’ll be introducing the Population Graph framework we’ve been developing over the last decade with highlights on how we are applying it to SNP-level genomic data analysis in non-model systems."
  },
  {
    "objectID": "posts/2015-09-28-eyes-on-climate/eyes-on-climate.html",
    "href": "posts/2015-09-28-eyes-on-climate/eyes-on-climate.html",
    "title": "Eyes on Climate",
    "section": "",
    "text": "A previous visitor to the laboratory, Philip Bertrand, is taking a trip between his graduate programs to travel the world and report on climate change. Here is ongoing blog, cataloging their travel from across the globe. Definitely worth following."
  },
  {
    "objectID": "posts/2021-12-15-smoothing-rasters/smoothing-rasters.html",
    "href": "posts/2021-12-15-smoothing-rasters/smoothing-rasters.html",
    "title": "Smoothing rasters",
    "section": "",
    "text": "So let’s load in a raster and crop it down to look at it. Here is the area surrounding Loreto, BCS Mexico as represented by a 1-km resolution raster of elevation.\n\nlibrary( raster )\nurl <- \"https://github.com/dyerlab/ENVS-Lectures/raw/master/data/alt_22.tif\"\nraster( url ) %>%\n  crop(extent( -111.6, -111, 25.6, 26.2) ) -> baja_california\nplot( baja_california ) \n\n\n\n\nFor simple viewing, we can tell the plot to interpolate it, which will shape it a bit. This does not change the data, it only shows the data a bit differently.\n\nplot( baja_california, interpolate = TRUE )\n\n\n\n\nWe can also resample the data, which changes it. We can disaggregate it, which makes a new raster with a more fine grain resolution and interpolates the new values to fit.\n\nloreto_disaggregated <- disaggregate( baja_california, \n                                      fact = 5,\n                                      method = \"bilinear\")\n\nwhich takes the previous raster whose size was:\n\ndim( baja_california )\n\n[1] 72 72  1\n\n\nand makes the new one of size\n\ndim( loreto_disaggregated )\n\n[1] 360 360   1\n\n\nas the fact=5 means that each cell in baja_california is turned into a 5x5 set of cells whose values are interpolated. Notice in the plot below, how the pixelation is reduced around the coast (this raster has all water = NA).\n\nplot( loreto_disaggregated )\n\n\n\n\nWe can also smooth it using a custom focal operation based upon a matrix of values and a function we define for it. Here the weight (w) matrix is a 5x5 matrix of 1 (defining the values around each spot that will be used) and the fun=mean will take the average of the 5x5 matrix of values.\n\nloreto_focal <- focal( baja_california, \n                       w = matrix(1, 5, 5), \n                       fun = mean, \n                       na.rm=TRUE)\n\nThis approach does not change the resoution of each cell, it only smooths it out. I also ignored NA for those edge cases.\n\ndim( loreto_focal )\n\n[1] 72 72  1\n\n\nAnd if you look at it, it still has some pixelation (minecraft-i-ness if you will)\n\nplot( loreto_focal )\n\n\n\n\nThe method you choose is up to you and the consequences of changing the raw data. Be careful."
  },
  {
    "objectID": "posts/2016-06-19-landscape-epigenetics/landscape-epigenetics.html",
    "href": "posts/2016-06-19-landscape-epigenetics/landscape-epigenetics.html",
    "title": "Landscape Epigenetics",
    "section": "",
    "text": "Here is my talk for the Evolution 2016 meeting\nHere is a link to the PDF."
  },
  {
    "objectID": "posts/2015-09-24-a-talk-at-the-university-of-paris-sud/a-talk-at-the-university-of-paris-sud.html",
    "href": "posts/2015-09-24-a-talk-at-the-university-of-paris-sud/a-talk-at-the-university-of-paris-sud.html",
    "title": "A talk at the University of Paris Sud",
    "section": "",
    "text": "I was fortunate to get asked to provide a talk at the University of Paris-Sud, a great campus that I’ve visited back in 2011. Here are the slides I used, presenting for the first time the methylation genomic data from Araptus attenuatus."
  },
  {
    "objectID": "posts/2023-01-25-Second-dDocent-Run/index.html",
    "href": "posts/2023-01-25-Second-dDocent-Run/index.html",
    "title": "Second dDocent Run",
    "section": "",
    "text": "This time, I made discussed things with Mike Davis and then tried this.\nI was able to get onto the compute node and then start up a run of dDocent with the following data: - All the samples. - 256 processors per node - Trim - Assemble as Single End (SE) reads - Map the individual to the assembly - SNP call on individuals."
  },
  {
    "objectID": "posts/2023-01-25-Second-dDocent-Run/index.html#the-printout.",
    "href": "posts/2023-01-25-Second-dDocent-Run/index.html#the-printout.",
    "title": "Second dDocent Run",
    "section": "The Printout.",
    "text": "The Printout.\n[rjdyer@huff12 all]$ dDocent\ndDocent 2.9.4\n\nContact jpuritz@uri.edu with any problems\n\n\nChecking for required software\n\nAll required software is installed!\n\ndDocent version 2.9.4 started Tue Jan 24 10:11:43 EST 2023\n\n1419 individuals are detected. Is this correct? Enter yes or no and press [ENTER]\nyes\nProceeding with 1419 individuals\ndDocent detects 256 processors available on this system.\nPlease enter the maximum number of processors to use for this analysis.\n256\n\nDo you want to quality trim your reads?\nType yes or no and press [ENTER]?\nyes\n\nDo you want to perform an assembly?\nType yes or no and press [ENTER].\nyes\nWhat type of assembly would you like to perform?  Enter SE for single end, PE for paired-end, RPE for paired-end sequencing for RAD protocols with random shearing, or OL for paired-end sequencing that has substantial overlap.\nThen press [ENTER]\nSE\nReads will be assembled with Rainbow\nCD-HIT will cluster reference sequences by similarity. The -c parameter (% similarity to cluster) may need to be changed for your taxa.\nWould you like to enter a new c parameter now? Type yes or no and press [ENTER]\nyes\nPlease enter new value for c. Enter in decimal form (For 90%, enter 0.9)\n.85\nDo you want to map reads?  Type yes or no and press [ENTER]\nyes\nBWA will be used to map reads.  You may need to adjust -A -B and -O parameters for your taxa.\nWould you like to enter a new parameters now? Type yes or no and press [ENTER]\nyes\nPlease enter new value for A (match score).  It should be an integer.  Default is 1.\n1\nPlease enter new value for B (mismatch score).  It should be an integer.  Default is 4.\n4\nPlease enter new value for O (gap penalty).  It should be an integer.  Default is 6.\n6\nDo you want to use FreeBayes to call SNPs?  Please type yes or no and press [ENTER]\nyes\n\nPlease enter your email address.  dDocent will email you when it is finished running.\nDont worry; dDocent has no financial need to sell your email address to spammers.\nrjdyer@vcu.edu\n\n\ndDocent will require input during the assembly stage.  Please wait until prompt says it is safe to move program to the background.\n\nTrimming reads and simultaneously assembling reference sequences\nparallel: Warning: Starting 30 processes took > 2 sec.\nparallel: Warning: Consider adjusting -j. Press CTRL-C to stop.\nSo, again, I am experiencing some problems on the servers. Our server admin person, Mike Davis, did follow up with some comments that one of the servers we were running on was experiencing some odd behaviors…\nTry again."
  },
  {
    "objectID": "posts/2019-03-24-landscape-genetics-workshop-2019/landscape-genetics-workshop-2019.html",
    "href": "posts/2019-03-24-landscape-genetics-workshop-2019/landscape-genetics-workshop-2019.html",
    "title": "Landscape Genetics Workshop 2019",
    "section": "",
    "text": "This week I’m in the wonderful town of Glasgow giving a workshop on Applied Landscape Genetics to a wide and interesting population of researchers.\nHere is the link to the content. If you are not taking it, you can follow along at your own pace, it is all available under the following CC-SA 4.0 license."
  },
  {
    "objectID": "posts/2017-03-17-march-faculty-meeting-notes/march-faculty-meeting-notes.html",
    "href": "posts/2017-03-17-march-faculty-meeting-notes/march-faculty-meeting-notes.html",
    "title": "March Faculty Meeting Notes",
    "section": "",
    "text": "Here are the notes for the March CES Faculty Meeting."
  },
  {
    "objectID": "posts/2016-08-29-applied-environmental-statistics/applied-environmental-statistics.html",
    "href": "posts/2016-08-29-applied-environmental-statistics/applied-environmental-statistics.html",
    "title": "Applied Environmental Statistics",
    "section": "",
    "text": "This semester, I’ll be leading a graduate course in applied ecological statistics. Should be a lot of fun getting a group of people up to speed on the benefits of being an R guru!\nhttps://sites.google.com/a/vcu.edu/applied-environmental-statistics"
  },
  {
    "objectID": "posts/1969-10-14-Dyers-Philosophy-Of-Life/index.html",
    "href": "posts/1969-10-14-Dyers-Philosophy-Of-Life/index.html",
    "title": "Dyer’s Philosophy of Life",
    "section": "",
    "text": "It is given that things in your life can be categorized into two mutually exclusive groups.\n\nThings that suck\nThe rest\n\nThe things that suck occur at a frequency of \\(p\\) whereas everything else in your life can be represented as \\(q = 1-p\\) . Clearly \\(p + q = 1\\) and this is nice because I’m a population geneticist and we like to deal in simple probabilities.\nVisually, we can represent the relationship between the things that do suck and the things that do not as a simple pie chart."
  },
  {
    "objectID": "posts/1969-10-14-Dyers-Philosophy-Of-Life/index.html#the-contents",
    "href": "posts/1969-10-14-Dyers-Philosophy-Of-Life/index.html#the-contents",
    "title": "Dyer’s Philosophy of Life",
    "section": "The Contents",
    "text": "The Contents\nSo what are these things that ‘suck’, how do we know about them, how can we identify them, etc.? As in Buddhism, things that suck are ultimately the things in your life that cause suffering. Suffering is inevitable and part of the human experience. Some people even seem to be needing suffering as a condition of existence (my grandparents for example-loved to be miserable).\nIn the modern age, the kinds of things that suck include (but are not limited to):\n\nRunning out of ink on your printer the morning your paper is due,\nBeing a Cleveland Browns fan,\nStevia,\nWaking up 45 minutes before your alarm goes off,\nPop Music,\nThe Windows Operating System,\nStepping in cat hairballs in the middle of the night,\nFinding that door dash delivered you the veggie burger instead of the dozen wings.\n\nI’m sure there are many additional things you can add to this list.\nSo it is also true that the “rest of that stuff in your life” is a pretty big grab-bag of items. That is OK. As long as each of them do not suck in any way, they can stay in this category. However, it is important that you look at these items often and Marie Condo them to see if they actually do suck but you’ve ignored them mostly because the amount of sucking they contribute to is only marginally larger than zero.\nBe vigilant! Do not let these things persist in this state. You MUST eradicate and exile them to the “Suck” category. Failing to do so results in condition called Suck Creep, which through time, will slowly eat all of your non-sucking life parts and eventually your life will consist of 100% suck."
  },
  {
    "objectID": "posts/1969-10-14-Dyers-Philosophy-Of-Life/index.html#mitigating-suckiness",
    "href": "posts/1969-10-14-Dyers-Philosophy-Of-Life/index.html#mitigating-suckiness",
    "title": "Dyer’s Philosophy of Life",
    "section": "Mitigating Suckiness",
    "text": "Mitigating Suckiness\nSo, one of the best ways to gain pleasure and enjoyment in your life is to figure out how to reduce that suckiness in your life and simply remove it.\nIn the examples above, we have a situation where roughly 22.2% of the life is classified as *The Part that Sucks”. Now, suppose that through some deep introspection and honest reflection on your part, you can identify 25% of the things in that category.\nThat situation looks like this:\n\n\n\n\n\nNow, here is the solemn truth of this entire philosophy. If you can look at these things and:\n\nRemove then from your life (e.g., stop using Windows),\nGive them to someone else (e.g., rehome the cat), or\nReconfigure your life so they no longer live rent free in your head (e.g., become a Seattle Seahawks fan)\n\nThen you can achieve what is technically called a period of suckiness reduction. These things are not guaranteed to stay static without constant vigilance. However, your life after this reduction will be more like this:\n\n\n\n\n\nThen you will, by definition, have reduce the amount of suckiness in your life (compare this graph and the one above). A concomitant feature of this is that\n\nYour life will now suck less.\n\nWhich is the “sunny side of the pyramid” we are all trying get to in life, isn’t it?"
  },
  {
    "objectID": "posts/2022-03-04-deq-r-workshop-day-1/deq-r-workshop.html",
    "href": "posts/2022-03-04-deq-r-workshop-day-1/deq-r-workshop.html",
    "title": "Workshop on R Data Literacy",
    "section": "",
    "text": "Venti Views Image from Unspalsh"
  },
  {
    "objectID": "posts/2022-03-04-deq-r-workshop-day-1/deq-r-workshop.html#workshop-logistics",
    "href": "posts/2022-03-04-deq-r-workshop-day-1/deq-r-workshop.html#workshop-logistics",
    "title": "Workshop on R Data Literacy",
    "section": "Workshop Logistics",
    "text": "Workshop Logistics\n\n\n\n \n \n\n\n\n\nWhen:\nMarch 7-8, 2022\n\n\nWhere:\n1111 East Main Street, Richmond Virginia 37.5367, -77.4350\n\n\nImpetus:\nBuild internal capacity at for using R as an analysis platform to increase efficiency of data management.\n\n\nInstructor:\n\n\n\nData Sets:\n\n\n\n\n\nIntroduction to R and RStudio\n\n\n\n\n\nLearning Objectives:\n- Learning about the R environment,\n- Understand differences between coding to the Console versus making scripts,\n- Use a Project to organize code, data, analyses, & narratives,\n- Personalize the RStudio GUI for success.\n\n\n\nCharacter Data and Basic Function Usage\n\n\n\n\n\nLearning Objectives:\n- Learn about basic function structure,\n- Explore the built-in help system,\n- Practice operations using the fundamental data type character,\n- Manipulate data in vector formats,\n- Perform textual analyses using the stringr library.\nstringr Cheatsheet\n\n\n\nNumeric Data and Data Frames\n\n\n\n\n\nLearning Objectives:\n- Explore numeric data and mathematical operations.\n- Create and manipulate data within data.frame objects.\n\n\n\nBasic Data Manipulation - Tidyverse\n\n\n\n\n\nLearning Objectives:\n- Understand data manipulation verbs,\n- Pipe data through several modifier functions to derive inferences,\n- Filter and select subsets of a larger data set,\n- Group and summarize measurements to derive summary parameters\nData Wrangling Cheatsheet\n\n\n\nNon-Character Character Data\n\n\n\n\n\nLearning Objectives:\n- Apply the mutate operator to create derived data columns.\n- Demonstrate the use of unordered and ordered factor data.\n- Convert textual representations of dates and times into date objects.\n- Derive temporal inferences from date objects\nforcats Cheatsheet\nlubridate Cheatsheet\n \n\n\n\nVisualizing Data - Basic & GGPlot\n\n\n\n\n\nLearning Objectives:\n- Learn about joins to merge data from two or more data.frames. - Develop your first function for consistent data formatting prior to visualization.\n- Understand and implement basic plotting routines provided in R::graphics\n- Convert raw data into high-quality graphical output using a variety of ggplot2 routines.\nvisualization Cheatsheet\n\n\n\nInteractive Mapping\n\n\n\n\n\nLearning Objectives:\n- Understand how to create a viable map display.\n- Apply differential tile providers to an interactive map.\n- Create markers on a map representing data found within the data frame.\nleaflet Cheatsheet\n\n\n\nMarkdown\n\n\n\n\n\nLearning Objectives:\n- Understand basic markup to represent common textual components.\n- Insert graphical output (figures, maps, etc) into a markdown document.\n- Inject components of statistical inferences into the text of a markdown document.\nmarkdown Cheatsheet"
  },
  {
    "objectID": "posts/2015-08-26-loading-in-rasters/loading-in-rasters.html",
    "href": "posts/2015-08-26-loading-in-rasters/loading-in-rasters.html",
    "title": "Loading in Rasters",
    "section": "",
    "text": "Much of the work in my laboratory uses spatial data in some context. As such it is important to try to be able to grab and use spatial data to in an easy fashion. At present, R is probably the best way to grab, visualize, and analyze spatial data. For this example, I went to http://worldclim.org and downloaded the elevation (altitude) for tile 13 (eastern North America) as a GeoTiff. A GeoTiff is a specific type of image format that has spatial data contained within it. The tile data has a pixel resolution of 30 arc seconds which puts us in the general area of ~ 1km. First, we need to get things set up to work.\n# Set the working directory to where you want it.\nsetwd(\"~/Downloads\")\n\n# load in the raster library\nrequire(raster)\nLoading required package: raster\nLoading required package: sp\n\nThen we can load in and visualize the data.\nr <- raster(\"alt_13.tif\")\nplot(r)\n\n\nWe can see what the raster relates to by looking at the extent.\nextent(r)\nclass       : Extent \nxmin        : -90 \nxmax        : -60 \nymin        : 30 \nymax        : 60\nor its contents.\nprint(r)\nclass       : RasterLayer \ndimensions  : 3600, 3600, 12960000  (nrow, ncol, ncell)\nresolution  : 0.008333333, 0.008333333  (x, y)\nextent      : -90, -60, 30, 60  (xmin, xmax, ymin, ymax)\ncoord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 \ndata source : /Users/rodney/Downloads/alt_13.tif \nnames       : alt_13 \nvalues      : -98, 1961  (min, max)\nAnd you are off to the races. This should get you going with the data. Other posts you may be interested in looking at are found by here."
  },
  {
    "objectID": "posts/2016-06-17-evolution-2016-8211-austin-texas/evolution-2016-8211-austin-texas.html",
    "href": "posts/2016-06-17-evolution-2016-8211-austin-texas/evolution-2016-8211-austin-texas.html",
    "title": "Evolution 2016 8211 Austin Texas",
    "section": "",
    "text": "And it starts! Going to be a great meeting with a huge VCU contingent!"
  },
  {
    "objectID": "posts/2022-02-01-unneceessary-output-by-ttdplyrtt/unneceessary-output-by-ttdplyrtt.html",
    "href": "posts/2022-02-01-unneceessary-output-by-ttdplyrtt/unneceessary-output-by-ttdplyrtt.html",
    "title": "Unnecessary Output by dplyr",
    "section": "",
    "text": "I love to use tidyverse when working on data but there is a bad habit that the authors have by spamming your output with messages they thing are informative. We need to have some basic ways to turn off this output if we are to use things link distil to publish actual manuscripts directly instead of just simple markdown documents.\nFor example, consider the case when you load in the library tidyverse. You get all this cruft which 99% of the time is just annoying.\n\nlibrary( tidyverse )\n\nRegistered S3 methods overwritten by 'dbplyr':\n   method         from\n   print.tbl_lazy     \n   print.tbl_sql      \n ── Attaching packages ───────────────────────────────────────────────────────────── tidyverse 1.3.1 ──\n ✓ ggplot2 3.3.5     ✓ purrr   0.3.4\n ✓ tibble  3.1.6     ✓ dplyr   1.0.7\n ✓ tidyr   1.2.0     ✓ stringr 1.4.0\n ✓ readr   2.1.2     ✓ forcats 0.5.1\n ── Conflicts ──────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n x dplyr::filter() masks stats::filter()\n x dplyr::lag()    masks stats::lag()\n\nThat is now what we want! There are several other options (like asking about conflicts, warning that group_by is not carried over after a summarize, etc), and we get it already. To turn these off put the following into your .Rprofile file at the root of your home directory and it will make a beginning stab at it!\ntidyverse.quiet = TRUE\ndplyr.summarise.inform = FALSE"
  },
  {
    "objectID": "posts/2019-04-22-population-graph-stability/population-graph-stability.html",
    "href": "posts/2019-04-22-population-graph-stability/population-graph-stability.html",
    "title": "Population Graph Stability",
    "section": "",
    "text": "A population graph is a network structure based upon inter-stratum conditional genetic covariance (see Dyer & Nason 2004 for a more complete discussion). In this context, it is often of interest to know the statistical stability of your loci in determining the topology you see in the popgraph. Here is a way to subsample the loci you have and identify the extent to which you are asymptotically estimating a stable topology. Basically we are going to:\n\nSample a subset of your loci randomly (without replacement) of a particular size (e.g., 10 loci).\n\nEstimate a topology.\n\nMeasure some characteristic (or characteristics) on that topology.\n\nGoTo #1 a large number of times (say 100).\n\nIncrement the number of loci being used."
  },
  {
    "objectID": "posts/2015-11-18-nsf-grant-recommended-for-funding/nsf-grant-recommended-for-funding.html",
    "href": "posts/2015-11-18-nsf-grant-recommended-for-funding/nsf-grant-recommended-for-funding.html",
    "title": "NSF Grant Recommended for Funding",
    "section": "",
    "text": "The Johnson and Dyer laboratories have been funded by DEB-Evolutionary Ecology for the project, A landscape resistance mapping approach to understanding species invasion patterns. Congratulations to the gypsy moth crew."
  },
  {
    "objectID": "posts/2017-02-28-bayesian-models/bayesian-models.html",
    "href": "posts/2017-02-28-bayesian-models/bayesian-models.html",
    "title": "Bayesian Models",
    "section": "",
    "text": "A three-part introduction to Bayesian Data Analysis by Rasmus Bååth."
  },
  {
    "objectID": "posts/2021-06-09-macos-monterey-beta/macos-monterey-beta.html",
    "href": "posts/2021-06-09-macos-monterey-beta/macos-monterey-beta.html",
    "title": "MacOS Monterey beta",
    "section": "",
    "text": "So yesterday, Apple introduced the next set of operating systems for iOS, MacOS, tvOS, iPadOS, and tvOS as well as a bunch of interesting upgrades for all the new hardware. I took the plunge with installing it on my M1 Macbook and here are some thoughts on items as I see them evolve."
  },
  {
    "objectID": "posts/2021-06-09-macos-monterey-beta/macos-monterey-beta.html#overall",
    "href": "posts/2021-06-09-macos-monterey-beta/macos-monterey-beta.html#overall",
    "title": "MacOS Monterey beta",
    "section": "Overall",
    "text": "Overall\nOverall, most things work out of the box with no problems.\n\nR, RStudio (minus git as described below)\nMail - I wish they would add “send later” but works great and has more privacy functions."
  },
  {
    "objectID": "posts/2021-06-09-macos-monterey-beta/macos-monterey-beta.html#safari",
    "href": "posts/2021-06-09-macos-monterey-beta/macos-monterey-beta.html#safari",
    "title": "MacOS Monterey beta",
    "section": "Safari",
    "text": "Safari\nIt is still REALLY FAST and new layout for the tabs.\n\n\n\nSafari with tabs and address bar integrated"
  },
  {
    "objectID": "posts/2023-01-27-10pct-dDocent-Run/index.html",
    "href": "posts/2023-01-27-10pct-dDocent-Run/index.html",
    "title": "A 10% dDocent Run",
    "section": "",
    "text": "So this time I made a small representation of the overall sequences, using: - 10% of each individual - Renamed to not have period in population name for each state (thinking that may be why I’ve had failures in the past). - Saved to different folder.\nrm(list=ls())\n\nfiles <- list.files(\"all\",pattern=\"F.fq.gz\")\nfor( i in 1:length(files) ) {\n    file <- files[i]\n    tmp <- strsplit(file, split=\"\\\\.\")[[1]]\n    ofile <- paste( paste( tmp[1],\n                                 tmp[2],\n                                 sep=\"\"), \n                        tmp[3], tmp[4], tmp[5], sep=\".\")\n    cmd <- paste(\"seqtk sample ./all/\",\n                     file,\n                     \" 0.10 | gzip > ./all010/\", \n                     ofile, \n                     sep=\"\")\n    system(cmd)\n    cat( format(i/length(files), digits=3), \" \", ofile, \"\\n\")\n}\nIt ran for a while, then died. So I tried it again and there were some issues with dDocent not recognizing the the files as being gz files… So I had to unzip all the 10% individuals and redo them.\nFinally it went through but I got a few errors along the way.\nTrimming reads and simultaneously assembling reference sequences\n\nRemoving the _1 character and replacing with /1 in the name of every sequence\nparallel: Warning: Starting 16 processes took > 2 sec.\nparallel: Warning: Consider adjusting -j. Press CTRL-C to stop.\nThen it gave me the prompt for number of unique sequences per individual.\n\nPlease choose data cutoff. In essence, you are picking a minimum (within individual) coverage level for a read (allele) to be used in the reference assembly.\n3\n\nI had hit the return button a few times and it ran using some ‘default’ value.\nThis time it did finish and made contigs.\nAt this point, all configuration information has been entered and dDocent may take several hours to run.\n\nIt is recommended that you move this script to a background operation and disable terminal input and output.\n\nAll data and logfiles will still be recorded.\nTo do this:\nPress **control** and **Z** simultaneously\nType **bg** and press enter\nType **disown -h** and press enter\nNow sit back, relax, and wait for your analysis to finish\n\ndDocent assembled 969927 sequences (after cutoffs) into 394146 contigs\n  \nUsing BWA to map reads\nSo at this point, I let it run for a while longer and then realized I was not going to use the 10% representation and would be using another assembly. So I killed the mapping."
  },
  {
    "objectID": "posts/2016-04-11-congratulations-chitra/congratulations-chitra.html",
    "href": "posts/2016-04-11-congratulations-chitra/congratulations-chitra.html",
    "title": "Congratulations Chitra",
    "section": "",
    "text": "Congratulations to Chitra Seshadri for defending her Masters Thesis entitled, “Genome wide analysis of epigenetic adaptive variance in _Araptus __attenuatus_, the Sonoran Desert bark beetle.” You are #13 graduate student from the Dyer Laboratory (lucky right?)."
  },
  {
    "objectID": "posts/2016-04-22-congratulations-to-dr-viverette/congratulations-to-dr-viverette.html",
    "href": "posts/2016-04-22-congratulations-to-dr-viverette/congratulations-to-dr-viverette.html",
    "title": "Congratulations to Dr Viverette",
    "section": "",
    "text": "Congratulations to the latest member of the PhD club, Dr. Cathy Viverette! Today, she became the 14th graduate student to graduate from the lab and the very first doctoral student. Take a break, relax, and then let’s get to those revisions! ;-)."
  },
  {
    "objectID": "posts/2015-08-27-compiling-rgdal-on-osx-8211-why-do-you-hate-me/compiling-rgdal-on-osx-8211-why-do-you-hate-me.html",
    "href": "posts/2015-08-27-compiling-rgdal-on-osx-8211-why-do-you-hate-me/compiling-rgdal-on-osx-8211-why-do-you-hate-me.html",
    "title": "Compiling RGDAL on OSX 8211 Why do you hate me",
    "section": "",
    "text": "Every time I upgrade in any significant way, two R libraries seem to raise their ugly heads and scream like a spoiled child—rgdal and rgeos . Why do these two have to be SOOOO much of a pain? Why can’t we have a auto build of a binary with all the options in it for OSX? Who knows? I always feel like I get the fuzzy end of the lollipop with these two. Here is my latest approach for getting them going.\n\nFirst you have to make sure you have the latest GDAL libraries. I used to get mine from\nKyngchaos, just download the framework, install it, and then do some kind of long R CMD INSTALL dance, which seems to no longer work for me. I also tried installing from Ripley’s repository and found that (a) It was a version older than the one I already had on my machine, and (b) you can’t install from that repository , there is a malformed header and the install.packages() function just barfs.\nTime to try something new. I typically stay away from the various installer frameworks out there on OSX to keep everything in Frameworks. But this time, I used MacPorts. You can find the latest version here. Here is how I got it to help me out.\n\nDownloaded the version for my OS, I’m currently on 10.10 and installed it.\nIn the terminal, I updated it sudo port -v selfupdate\nI then used it to install gdal as a unix library (rather than as a framework so it won’t be located in /Library/Frameworks) by sudo port install gdal. There were a lot of dependencies for this one so it took a while.\nI then had R install rgdal as install.packages( rgdal, type=”source”)\nWorked like a charm."
  },
  {
    "objectID": "posts/2016-06-25-google-earth-pro-8211-now-free/google-earth-pro-8211-now-free.html",
    "href": "posts/2016-06-25-google-earth-pro-8211-now-free/google-earth-pro-8211-now-free.html",
    "title": "Google Earth Pro 8211 Now Free",
    "section": "",
    "text": "This may be old news but I just ran across it today and thought it may be helpful for others. GoogleEarth Pro is now free.\nYou can download it and follow the instructions here."
  },
  {
    "objectID": "posts/2017-10-07-envs-welcome-slides/envs-welcome-slides.html",
    "href": "posts/2017-10-07-envs-welcome-slides/envs-welcome-slides.html",
    "title": "ENVS Welcome Slides",
    "section": "",
    "text": "We have just begun the new academic year and we are already getting orientation meetings together for the next set of incoming students."
  },
  {
    "objectID": "posts/2017-03-09-new-sequencer/new-sequencer.html",
    "href": "posts/2017-03-09-new-sequencer/new-sequencer.html",
    "title": "New sequencer",
    "section": "",
    "text": "USB-3.0 powered!"
  },
  {
    "objectID": "posts/2015-01-21-setting-up-your-site-for-syndication/setting-up-your-site-for-syndication.html",
    "href": "posts/2015-01-21-setting-up-your-site-for-syndication/setting-up-your-site-for-syndication.html",
    "title": "Setting Up Your Site for Syndication",
    "section": "",
    "text": "This quick tutorial is for how you set up your site to make it able to syndicate to a class site. I am using the BIOL310 Genetics Online course as an example. You are going to need the following:\n\nA category given to you by the professor to use on your site to indicate which posts should be sent over to the class site.\nA blog. Here I am running WordPress as it is the supported one from VCU. Others are available if you already have a blog going, if not got to rampages.us and sign up as a VCU student and make one. Consider it a digital portfolio for all your work.\nSend your professor the address of your blog.\n\nBelow is a video of the process. It is pretty easy to do.\nThat should be it. Once your professor has the link and sets up syndication, your posts (when the category is applied to them) will show up on the site."
  },
  {
    "objectID": "posts/2023-01-ddRADSeq-Progress/index.html#summary",
    "href": "posts/2023-01-ddRADSeq-Progress/index.html#summary",
    "title": "Turtle ddRADSeq Project",
    "section": "Summary",
    "text": "Summary\n\n\n\nWe retrieved usable sequence data from at total of 1419 individuals. The number of sequence reads is depicted by file size (log base 10) below.\n\n\n\n\n\nThe distrubiton of sequence reads (denoted as log10 of file size) for all individuals sequenced.\n\n\n\n\nThe largest number of sequences was retrieved from a sample from Camp Edwards, MA, with 50,205,568 sequences. The median read size was 17,332,284."
  },
  {
    "objectID": "posts/2023-01-ddRADSeq-Progress/index.html#processing",
    "href": "posts/2023-01-ddRADSeq-Progress/index.html#processing",
    "title": "Turtle ddRADSeq Project",
    "section": "Processing",
    "text": "Processing\n\n\n\n\n\n\n\n\nProgress of the main steps in processing raw sequence data."
  },
  {
    "objectID": "posts/2023-01-ddRADSeq-Progress/index.html#progress",
    "href": "posts/2023-01-ddRADSeq-Progress/index.html#progress",
    "title": "Turtle ddRADSeq Project",
    "section": "Progress",
    "text": "Progress\nThe following logs document the initial attempts at implementing the dDocent workflow for processing NovoSEQ data on the spotted turtle.\n\nDemultiplexing is the process of taking all the data that is mixed together and turning it inot a a bunch of files, one for each individual, based upon the individual barcodes.\nThe first run of dDocent crashed almost immediately.\nThe second run of dDocent also crashed, but this time it was for a different reason. Apparently, the node it was running on was failing. However, it still crashed.\nAs a result of these attempts, it appears that the data are just too big and I need to take subsets of the data to work with so the computers can actually get something done. So, after talking with a colleague about it, I right-sized the data first in random samples and then ran a third run used a random subset of 10% of each individuals reads to make a synthetic “individual”. It ultimately failed at the end as well.\nSo, lessons learned. I needed to create a random subset of my data and use that for just the assembly portion of this process. So I set out to do that and found results.\n\nA 2.5% subset finished with 7k contigs.\nA 5% subset finished with 58k contigs.\nA 10% subset finished with 400k contigs.\n\nSo, I can now start mapping. At first, I took the reference genome from the 2.5% subset and took the raw data again (all the reads for each indiviudal) and used bwa to assemble and FreeBayes to call SNPs. Unfortunately, since the number of reads for each individual is somewhere in the range of 3 - 33 million reads, it takes a bit of time. Right now, it is averaging 11 hours per individual * 1419 individuals which is 650.375 days (meaning it will be done on 2024-11-13). This run is still going and unless it dies at some point, I am going to allow it to keep running…\nAgain, to take a random subset seems to be the way to go. In what follows is my current approach to this, which started on 2 February 2022.\n\n\nWorkflow Progress\nSo I started up a individuals processes to map and call SNPs. It is done using slurm on our clusters so I fire up an instance on one of the compute nodes as:\n\n\n\nAs a first mapping run, I had a single process (that one used 64G of memory and was way too much for what bwa and FreeBayes seem to need). The data being used in this run include:\n\nA new random selection of 5% of each individuals genome.\n\nThe assembly created from the 2.5% random selection of each individual.\n\nThis was started on 2 February 2023 and appears to be taking roughly 30 minutes per indivudal to allow bwa to map. Below is the progress to date.\n\n\n\n\n\n\n\nPopulation\n\n\nN\n\n\nDemultiplexed\n\n\nFiltered\n\n\nMapped\n\n\nSites\n\n\nSNPs\n\n\n\n\n\n\nL\n\n\n95\n\n\n100\n\n\n100\n\n\n102\n\n\n\n\n\n\n\n\nA\n\n\n92\n\n\n100\n\n\n100\n\n\n100\n\n\n\n\n\n\n\n\nB\n\n\n102\n\n\n100\n\n\n100\n\n\n100\n\n\n\n\n\n\n\n\nC\n\n\n139\n\n\n100\n\n\n100\n\n\n100\n\n\n\n\n\n\n\n\nD\n\n\n84\n\n\n100\n\n\n100\n\n\n100\n\n\n\n\n\n\n\n\nE\n\n\n36\n\n\n100\n\n\n100\n\n\n100\n\n\n\n\n\n\n\n\nF\n\n\n31\n\n\n100\n\n\n100\n\n\n100\n\n\n\n\n\n\n\n\nG\n\n\n78\n\n\n100\n\n\n100\n\n\n100\n\n\n\n\n\n\n\n\nH\n\n\n66\n\n\n100\n\n\n100\n\n\n100\n\n\n\n\n\n\n\n\nI\n\n\n33\n\n\n100\n\n\n100\n\n\n100\n\n\n\n\n\n\n\n\nJ\n\n\n13\n\n\n100\n\n\n100\n\n\n100\n\n\n9367\n\n\n1508\n\n\n\n\nK\n\n\n13\n\n\n100\n\n\n100\n\n\n100\n\n\n9367\n\n\n1508\n\n\n\n\nM\n\n\n129\n\n\n100\n\n\n100\n\n\n100\n\n\n\n\n\n\n\n\nN\n\n\n53\n\n\n100\n\n\n100\n\n\n100\n\n\n\n\n\n\n\n\nO\n\n\n44\n\n\n100\n\n\n100\n\n\n100\n\n\n11338\n\n\n282\n\n\n\n\nP\n\n\n59\n\n\n100\n\n\n100\n\n\n100\n\n\n10730\n\n\n1660\n\n\n\n\nQ\n\n\n18\n\n\n100\n\n\n100\n\n\n100\n\n\n7100\n\n\n188\n\n\n\n\nR\n\n\n42\n\n\n100\n\n\n100\n\n\n100\n\n\n10294\n\n\n1348\n\n\n\n\nS\n\n\n187\n\n\n100\n\n\n100\n\n\n100\n\n\n15089\n\n\n1994\n\n\n\n\nT\n\n\n81\n\n\n100\n\n\n100\n\n\n100\n\n\n11986\n\n\n176\n\n\n\n\nV\n\n\n21\n\n\n100\n\n\n100\n\n\n100\n\n\n8586\n\n\n58\n\n\n\n\nW\n\n\n53\n\n\n100\n\n\n100\n\n\n100\n\n\n10891\n\n\n1113\n\n\n\n\n\nTable 1 Current progress on bioinformatic workflows.\n\n\nAt present, there are -2 samples remaining to be mapped."
  },
  {
    "objectID": "posts/2015-02-05-a-terrible-loss-for-vcu/a-terrible-loss-for-vcu.html",
    "href": "posts/2015-02-05-a-terrible-loss-for-vcu/a-terrible-loss-for-vcu.html",
    "title": "A terrible loss for VCU",
    "section": "",
    "text": "This past week, VCU lost a champion of multidisciplinary research, Dr. Thomas Huff, Vice Provost of Life Sciences. Tom was an unwavering advocate of interdisciplinary interactions and a continuous supporter of Biology. He leaves lasting impressions on VCU, Life Sciences, and the Department of Biology."
  },
  {
    "objectID": "posts/2016-10-06-spatial-data-sources/spatial-data-sources.html",
    "href": "posts/2016-10-06-spatial-data-sources/spatial-data-sources.html",
    "title": "Spatial Data Sources",
    "section": "",
    "text": "As part of a class in Landscape Genetics, faculty (mostly done by Melanie Murphy and Jeffrey Evans) compiled an extensive list of spatial data sources. These were made available on the course website we hosted but I wanted to make a more persistent copy of them here so they will not be lost. They are listed below the break.\n\n\n\n\n\nAfrica Infrastructure Knowledge Program\n\n\nhttp://www.infrastructureafrica.org/\n\n\n\n\nASTER (Advanced Spaceborne Thermal Emission and Reflection Radiometer)\n\n\nhttp://asterweb.jpl.nasa.gov/\n\n\n\n\nASTER Global 30m DEM\n\n\nhttp://www.gdem.aster.ersdac.or.jp/\n\n\n\n\nAtlas of the Biosphere\n\n\nhttp://www.sage.wisc.edu/atlas/\n\n\n\n\nAtrium biodiversity information system\n\n\nhttp://atrium.andesamazon.org/metadata_search.php\n\n\n\n\nAtrium biodiversity information system\n\n\nhttp://atrium.andesamazon.org/\n\n\n\n\nAVIRIS (Airborne Visible/Infrared Imaging Spectrometer)\n\n\nhttp://aviris.jpl.nasa.gov/\n\n\n\n\nBLM Land Survey Information System\n\n\nhttp://www.geocommunicator.gov/GeoComm/\n\n\n\n\nBLM Sage Grouse Breeding Densities\n\n\nhttp://conserveonline.org/workspaces/sagegrouse/documents/all.html\n\n\n\n\nCAL-Atlas California GIS data\n\n\nhttp://www.atlas.ca.gov/\n\n\n\n\nColorado 2009 NAIP County Mosaics\n\n\nhttps://my.usgs.gov/Public/NSDIPartnershipOffice/CO/2009%20NAIP%20County%20Mosaics/\n\n\n\n\nColorado Dept of Transportation\n\n\nhttp://apps.coloradodot.info/dataaccess/GeoData/index.cfm?fuseaction=GeoDataMain\n\n\n\n\nColorado Ownership database (COMaP)\n\n\nhttp://www.nrel.colostate.edu/projects/comap/index.html\n\n\n\n\nCSIRO Lidar mapping of vegetation canopies\n\n\nhttp://www.cossa.csiro.au/vsis/lidhome.htm\n\n\n\n\nDownscaled Climate GCM’s\n\n\nhttp://futureclim.info/\n\n\n\n\nEPA Webmap Services\n\n\nhttp://www.epa.gov/geospatial/help.htm\n\n\n\n\nFEMA Flood maps\n\n\nhttps://msc.fema.gov/webapp/wcs/stores/servlet/FemaWelcomeView?storeId=10001&catalogId=10001&langId=-1&userType=G\n\n\n\n\nFEMA Imagery download\n\n\nhttp://stratus.cr.usgs.gov/viewer/\n\n\n\n\nGeoEye foundation\n\n\nhttp://www.geoeye.com/CorpSite/corporate/foundation/\n\n\n\n\nGlobal Gridded Popuation data\n\n\nhttp://sedac.ciesin.columbia.edu/gpw/aboutus.jsp\n\n\n\n\nGlobal Land Cover Characterization\n\n\nhttp://edc2.usgs.gov/glcc/glcc.php\n\n\n\n\nGlobal Landcover Facility\n\n\nhttp://landcover.org/index.shtml\n\n\n\n\nGlobal Landcover Facility Amazon and Central Africa Forest Change\n\n\nhttp://landcover.org/data/pathfinder/data.shtml\n\n\n\n\nGlobal Multi-resolution Terrain Elevation Data 2010\n\n\nhttp://pubs.usgs.gov/of/2011/1073/\n\n\n\n\nGlobal Protected Areas\n\n\nhttp://www.protectedplanet.net/\n\n\n\n\nICESat/GLAS\n\n\nhttp://icesat.gsfc.nasa.gov/icesat/\n\n\n\n\nIdaho Dept Water Resources\n\n\nhttp://www.idwr.idaho.gov/\n\n\n\n\nIdaho GIS data (Inside Idaho)\n\n\nhttp://inside.uidaho.edu/\n\n\n\n\nLandsat Path/Row Index Shapefile\n\n\nhttps://landsat.usgs.gov/tools_wrs-2_shapefile.php\n\n\n\n\nMODIS Global NPP\n\n\nhttp://secure.ntsg.umt.edu/projects/index.php/ID/ca2901a0/fuseaction/projects.detail.htm\n\n\n\n\nMODIS Sinusoidal Grid shapefile\n\n\nhttp://gis.cri.fmach.it/modis-sinusoidal-gis-files/\n\n\n\n\nMODIS Subset tool\n\n\nhttp://daac.ornl.gov/cgi-bin/MODIS/GLBVIZ_1_Glb/modis_subset_order_global_col5.pl\n\n\n\n\nMontana Geographic Information Clearinghouse\n\n\nhttp://nris.mt.gov/gis/default.asp\n\n\n\n\nMRLC National Land Cover\n\n\nhttp://www.mrlc.gov/nlcd2006.php\n\n\n\n\nNASA GLOVIS\n\n\nhttp://glovis.usgs.gov/\n\n\n\n\nNASA Land Processes Distributed Active Archive Center\n\n\nhttps://lpdaac.usgs.gov/\n\n\n\n\nNASA Multiangle Imaging SpectroRadiometer\n\n\nhttp://eosweb.larc.nasa.gov/PRODOCS/misr/table_misr.html\n\n\n\n\nNASA-JPL Global Carbon mapping\n\n\nhttp://lidarradar.jpl.nasa.gov/\n\n\n\n\nNational Agricultural Statistics Service Crop Data\n\n\nhttp://www.nass.usda.gov/research/Cropland/SARS1a.htm\n\n\n\n\nNational Agriculture Imagery Program (NAIP)\n\n\nhttp://www.fsa.usda.gov/FSA/apfoapp?area=home&subject=prog&topic=nai\n\n\n\n\nNatural Earth Global data\n\n\nhttp://www.naturalearthdata.com/\n\n\n\n\nNCALM (National Center of Airborne Laser Mapping)\n\n\nhttp://www.ncalm.org/home.html\n\n\n\n\nNDEP (National Digital Elevation Program)\n\n\nhttp://www.ndep.gov/\n\n\n\n\nNevada GIS data\n\n\nhttp://keck.library.unr.edu/\n\n\n\n\nNOAA Costal topographic change\n\n\nhttp://www.csc.noaa.gov/crs/tcm/index.html\n\n\n\n\nNorth American Regional Climate Change Assessment Program\n\n\nhttp://www.narccap.ucar.edu/users/observed-datasets.html\n\n\n\n\nNorth Dakota Webmap Services\n\n\nhttp://www.nd.gov/gis/mapsdata/web/\n\n\n\n\nNRCS Geospatial Data Gateway\n\n\nhttp://datagateway.nrcs.usda.gov/\n\n\n\n\nOpen Street Map\n\n\nhttp://www.openstreetmap.org/\n\n\n\n\nOpenTopography\n\n\nhttp://www.opentopography.org/\n\n\n\n\nOregon Geospatial Enterprise Office\n\n\nhttp://www.oregon.gov/DAS/EISPD/GEO/sdlibrary.shtml\n\n\n\n\nPlanet Action SPOT program\n\n\nhttp://www.planet-action.org/\n\n\n\n\nPritected Areas Database of the United States\n\n\nhttp://www.protectedlands.net/\n\n\n\n\nPuget Sound Lidar Consortium\n\n\nhttp://pugetsoundlidar.ess.washington.edu/\n\n\n\n\nUS State data clearinghouse (links to state data)\n\n\nhttp://web.mit.edu/dtfg/www/data/data_gis_us_state.htm\n\n\n\n\nSRTM (Shuttle Radar Topography Mission) 90m global data\n\n\nhttp://srtm.csi.cgiar.org/\n\n\n\n\nSTRM Topography and Canopy data\n\n\nhttp://srtm.csi.cgiar.org/\n\n\n\n\nSWreGAP processed Landsat, ASTER and MSS\n\n\nhttp://earth.gis.usu.edu/search.phtml\n\n\n\n\nTexas Natural Resources Information System\n\n\nhttp://www.tnris.org/get-data#ccm\n\n\n\n\nTNC AWWI Landscape Assessment Tool\n\n\nhttp://wind.tnc.org/awwi/#\n\n\n\n\nTNC Climate Wizard\n\n\nhttp://www.climatewizard.org/\n\n\n\n\nTNC Climate Wizard Custom Queries\n\n\nhttp://climatewizardcustom.org/\n\n\n\n\nTNC Development by Design Webmap Server\n\n\nhttp://50.18.62.210/DevByDesign/\n\n\n\n\nUMAC Remote Sensing Imagery\n\n\nhttp://www.umac.org/imagery/sources/index.html\n\n\n\n\nUniversity of Washington, Various Global Data\n\n\nhttp://wagda.lib.washington.edu/data/geography/world/\n\n\n\n\nUS Census Bureau\n\n\nhttp://www.census.gov/geo/www/pvs/PVS_main.html\n\n\n\n\nUS Census Bureau – TIGER data\n\n\nhttp://www.census.gov/geo/www/tiger/tgrshp2009/tgrshp2009.html\n\n\n\n\nUS Federal Geographic Data Committee\n\n\nhttp://www.fgdc.gov/\n\n\n\n\nUS National Atlas raw data download\n\n\nhttp://www.nationalatlas.gov/atlasftp.html\n\n\n\n\nUSDA-AFPO NAIP Webmap Service\n\n\nwms.ftw.nrcs.usda.gov\n\n\n\n\nUSFS-Rocky Mt Region GIS data\n\n\nhttp://www.fs.fed.us/r2/gis/datasets_regionwide.shtml\n\n\n\n\nUSFWS Critical Habitat data\n\n\nhttp://criticalhabitat.fws.gov/crithab/\n\n\n\n\nUSFWS National Wetlands Inventory\n\n\nhttp://www.fws.gov/wetlands/Data/DataDownload.html\n\n\n\n\nUSGS CLICK\n\n\nhttp://lidar.cr.usgs.gov/\n\n\n\n\nUSGS Geologic formations\n\n\nhttp://pubs.usgs.gov/of/2005/1325/index_map.htm\n\n\n\n\nUSGS Geosciences Database\n\n\nhttp://ngmdb.usgs.gov/Other_Resources/rdb_es.html\n\n\n\n\nUSGS Global Ecosystems\n\n\nhttp://rmgsc.cr.usgs.gov/ecosystems/\n\n\n\n\nUSGS National geophysical data\n\n\nhttp://tin.er.usgs.gov/catalog/cite-view.php?cite=97\n\n\n\n\nUSGS National Hydrography Dataset\n\n\nhttp://nhd.usgs.gov/\n\n\n\n\nUSGS North West ReGap Landcover\n\n\nhttp://gap.uidaho.edu/index.php/gap-home/Northwest-GAP/landcover/download-data-by-state\n\n\n\n\nUSGS Seamless data server\n\n\nhttp://seamless.usgs.gov/\n\n\n\n\nUSGS South West ReGap Landcover\n\n\nhttp://earth.gis.usu.edu/swgap/\n\n\n\n\nUSGS Water Resource Data\n\n\nhttp://water.usgs.gov/maps.html\n\n\n\n\nVITO Image processing and archiving center\n\n\nhttp://www.vgt.vito.be/\n\n\n\n\nWashington 2009 NAIP County Mosaics\n\n\nhttp://gis.ess.washington.edu/data/raster/naip2009ccm_wa/index.html\n\n\n\n\nWorldClim\n\n\nhttp://www.worldclim.org/\n\n\n\n\nWyGISc (Wyoming GIS data server)\n\n\nhttp://www.uwyo.edu/wygisc/geodata/\n\n\n\n\nWWF Ecoregions\n\n\nhttp://www.worldwildlife.org/science/data/item1875.html\n\n\n\n\nWWF GIS data\n\n\nhttp://www.worldwildlife.org/science/data/item1872.html\n\n\n\n\nWWF Global Hydrosheds\n\n\nhttp://hydrosheds.cr.usgs.gov/#"
  },
  {
    "objectID": "posts/2022-02-15-guest-lecture-in-envs102/guest-lecture-in-envs102.html",
    "href": "posts/2022-02-15-guest-lecture-in-envs102/guest-lecture-in-envs102.html",
    "title": "Guest Lecture in ENVS102",
    "section": "",
    "text": "First Slide\n\n\nA link to the slides can be found here."
  },
  {
    "objectID": "manuscripts.html",
    "href": "manuscripts.html",
    "title": "Manuscripts",
    "section": "",
    "text": "Population Genetic Structure, Connectivity, and Potential Broodstock Sources for the Endangered James Spinymussel (Parvaspina collina).\n\n\n\n\n\nVirginia Department of Wildlife Resources, General Technical Report.\n\n\n\n\n\n\nJun 11, 2021\n\n\nRodney Dyer, Bonnie Roderique\n\n\n\n\n\n\n  \n\n\n\n\nEvolutionary stability, landscape heterogeneity, and human land-usage shape population genetic connectivity in the Cape Floristic Region biodiversity hotspot.\n\n\n\n\n\n\n\ngene flow\n\n\nurbanization\n\n\n\n\nEvolutionary Applications. 2021, 14: 1109-1123.\n\n\n\n\n\n\nApr 1, 2021\n\n\nErica Tassone, Lindsay Miles, Rodney Dyer, Michael Rosenberg, Richard Cowling, Brian Verrelli\n\n\n\n\n\n\n  \n\n\n\n\nGenetic Diversity and Connectivity in Plant Species Differing in Clonality and Dispersal Mechanisms in Wetland Island Habitats\n\n\n\n\n\n\n\ndispersal\n\n\nclonal growth\n\n\nmetapopulation\n\n\ngenetic divergence\n\n\ngenetic diversity\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2021\n\n\nSissi Lozada-Gobilard, Christian Schwarzer, Rodney Dyer, Ralph Tiedemann, Jasmin Joshi\n\n\n\n\n\n\n  \n\n\n\n\nPopulation assignment reveals low migratory connectivity in a weakly structured songbird\n\n\n\n\n\n\n\npopulation genetics\n\n\nddradseq\n\n\n\n\nMolecular Ecology. 2020.\n\n\n\n\n\n\nFeb 14, 2020\n\n\n\n\n\n\n  \n\n\n\n\nWide outcrossing provides functional connectivity for new and old Banksia populations within a fragmented landscape\n\n\n\n\n\n\n\npopulation genetics\n\n\ngene flow\n\n\ngenetic structure\n\n\n\n\nOecologia. 2019.\n\n\n\n\n\n\nMar 27, 2019\n\n\n\n\n\n\n  \n\n\n\n\nEvolutionary genomics of gypsy moth populations sampled along a latitudinal gradient\n\n\n\n\n\n\n\npopulation genetics\n\n\nddradseq\n\n\ngypsy moth\n\n\n\n\nMolecular Ecology. 2019.\n\n\n\n\n\n\nMar 4, 2019\n\n\n\n\n\n\n\n\n\n\n\nFunctional connectivity and home range inferred at a microgeographic landscape genetics scale in a desert-dwelling rodent\n\n\n\ndesert ecosystems\ndipodomys merriami\nfunctional connectivity\nlandscape genetics\nmerriam's kangaroo rat\nresistance surfaces\n\n\n\nECOLOGY AND EVOLUTION. 2019.\n\n\n\nJan 1, 2019\n\n\n\n\n  \n\n\n\n\nComparison of Pollination Graphs\n\n\n\n\n\n\n\npollination network\n\n\ncorrelated random walk\n\n\nagent-based model\n\n\npollen carryover\n\n\ntree density\n\n\n\n\nMOLECULAR ECOLOGY. 2018.\n\n\n\n\n\n\nAug 1, 2018\n\n\n\n\n\n\n  \n\n\n\n\nUrban hubs of connectivity: contrasting patterns of gene flow within and among cities in the western black widow spider\n\n\n\n\n\n\n\nurbanization\n\n\ngenetic connectivity\n\n\npopulation genetics\n\n\nurban pest\n\n\n\n\nPROCEEDINGS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES. 2018.\n\n\n\n\n\n\nAug 1, 2018\n\n\n\n\n\n\n  \n\n\n\n\nUrbanization as a facilitator of gene flow in a human health pest\n\n\n\n\n\n\n\npest\n\n\npopgraph\n\n\nsocial network\n\n\nspider\n\n\nurban facilitation\n\n\n\n\nMOLECULAR ECOLOGY. 2018.\n\n\n\n\n\n\nAug 1, 2018\n\n\n\n\n\n\n  \n\n\n\n\nStructure and Resilience of Bald Eagle Roost Networks\n\n\n\n\n\n\n\nbald eagle\n\n\nchesapeake bay\n\n\ncommunal roost\n\n\nhaliaeetus leucocephalus\n\n\nnetworks\n\n\nresiliency\n\n\n\n\nWILDLIFE SOCIETY BULLETIN. 2018.\n\n\n\n\n\n\nJun 1, 2018\n\n\n\n\n\n\n  \n\n\n\n\nEditorial: The Least Cost Path From Landscape Genetics to Landscape Genomics: Challenges and Opportunities to Explore NGS Data in a Spatially Explicit Context\n\n\n\n\n\n\n\nlandscape genetics\n\n\nlandscape genomics\n\n\nnext generation sequencing\n\n\nspatial genetics\n\n\necological genetics\n\n\n\n\nFRONTIERS IN GENETICS. 2018.\n\n\n\n\n\n\nJun 1, 2018\n\n\n\n\n\n\n  \n\n\n\n\nSex-specific graphs: Relating group-specific topology to demographic and landscape data\n\n\n\n\n\n\n\ngenetic network\n\n\npekania pennanti\n\n\npopulation graph\n\n\nsex-biased dispersal\n\n\nsex-specific graphs\n\n\n\n\nMOLECULAR ECOLOGY. 2017.\n\n\n\n\n\n\nAug 1, 2017\n\n\n\n\n\n\n  \n\n\n\n\nModel Comparison for Abiotic versus Biotic Pollen Dispersal\n\n\n\n\n\n\n\ngene flow\n\n\nagent based modelling\n\n\ncorrelated random walk\n\n\npollen\n\n\n\n\nNONLINEAR DYNAMICS PSYCHOLOGY AND LIFE SCIENCES. 2016.\n\n\n\n\n\n\nOct 1, 2016\n\n\n\n\n\n\n  \n\n\n\n\nOpportunistic conspecific brood parasitism in a box-nesting population of Prothonotary Warblers (Protonotaria citrea)\n\n\n\n\n\n\n\nbreeding ecology\n\n\ncavity nesters\n\n\nconspecific brood parasitism\n\n\nprotonotaria citrea\n\n\n\n\nAUK. 2016.\n\n\n\n\n\n\nApr 1, 2016\n\n\n\n\n\n\n  \n\n\n\n\nPopulation Graphs and Landscape Genetics\n\n\n\n\n\n\n\nlandscape genetics\n\n\npopulation graphs\n\n\nspatial structure\n\n\nconnectivity\n\n\n\n\nANNUAL REVIEW OF ECOLOGY, EVOLUTION, AND SYSTEMATICS. 2015.\n\n\n\n\n\n\nOct 6, 2015\n\n\n\n\n\n\n  \n\n\n\n\nGenetic structure of Pinus henryi and Pinus tabuliformis: Natural landscapes as significant barriers to gene flow among populations\n\n\n\n\n\n\n\ncpssr\n\n\ngenetic structure\n\n\ngeographical boundary\n\n\npinus henryi\n\n\npinus tabuliformis\n\n\n\n\nBIOCHEMICAL SYSTEMATICS AND ECOLOGY. 2015.\n\n\n\n\n\n\nAug 1, 2015\n\n\n\n\n\n\n  \n\n\n\n\nIs there such a thing as landscape genetics?\n\n\n\n\n\n\n\nlandscape genetics\n\n\nlandscape ecology\n\n\npopulation genetics\n\n\n\n\nMOLECULAR ECOLOGY. 2015.\n\n\n\n\n\n\nJul 1, 2015\n\n\n\n\n\n\n  \n\n\n\n\nIdentification of Eastern United States Reticulitermes Termite Species via PCR-RFLP, Assessed Using Training and Test Data\n\n\n\n\n\nINSECTS. 2015.\n\n\n\n\n\n\nJun 1, 2015\n\n\n\n\n\n\n  \n\n\n\n\nThe gravity of pollination: integrating at-site features into spatial analysis of contemporary pollen movement\n\n\n\n\n\n\n\ncornus florida\n\n\ngene flow\n\n\ngravity models\n\n\nlandscape genetics\n\n\npopulation graphs\n\n\n\n\nMOLECULAR ECOLOGY. 2014.\n\n\n\n\n\n\nAug 1, 2014\n\n\n\n\n\n\n  \n\n\n\n\nPutting the landscape into the genomics of trees: approaches for understanding local adaptation and population responses to changing climate\n\n\n\n\n\n\n\nadaptive genetic variation\n\n\nclimate change\n\n\nenvironmental association\n\n\nforest genetics\n\n\ngenomics\n\n\nlandscape genetics\n\n\n\n\nTREE GENETICS & GENOMES. 2013.\n\n\n\n\n\n\nAug 1, 2013\n\n\n\n\n\n\n  \n\n\n\n\nEcological coassociations influence species’ responses to past climatic change: an example from a Sonoran Desert bark beetle\n\n\n\n\n\n\n\nbaja california\n\n\ncoleoptera\n\n\nlandscape history\n\n\npopulation genetics\n\n\nrange expansion\n\n\nvicariance\n\n\n\n\nMOLECULAR ECOLOGY. 2013.\n\n\n\n\n\n\nJun 1, 2013\n\n\n\n\n\n\n  \n\n\n\n\nDefining the landscape of adaptive genetic diversity\n\n\n\n\n\n\n\nadaptive traits\n\n\nconifers\n\n\nfitness landscape\n\n\ngenome-wide association\n\n\nserotiny\n\n\n\n\nMOLECULAR ECOLOGY. 2012.\n\n\n\n\n\n\nJun 1, 2012\n\n\n\n\n\n\n  \n\n\n\n\nCombining multiple analytical approaches for the identification of population structure and genetic delineation of two subspecies of the endemic Arabian burnet moth Reissita simonyi (Zygaenidae; Lepidoptera)\n\n\n\n\n\n\n\nreissita simonyi\n\n\nmicrosatellites\n\n\nisolatuion by distance\n\n\nisolatuion by altitude\n\n\nlandscape connectivity\n\n\nnull alleles\n\n\n\n\nCONSERVATION GENETICS. 2012.\n\n\n\n\n\n\nFeb 1, 2012\n\n\n\n\n\n\n  \n\n\n\n\nPollination graphs: quantifying pollen pool covariance networks and the influence of intervening landscape on genetic connectivity in the North American understory tree, Cornus florida L.\n\n\n\n\n\n\n\npollination graph\n\n\nconnectivity\n\n\nconditional genetic distance\n\n\ngene flow\n\n\ncornus florida\n\n\n\n\nLANDSCAPE ECOLOGY. 2012.\n\n\n\n\n\n\nFeb 1, 2012\n\n\n\n\n\n\n  \n\n\n\n\nInvasion genetics of Microstegium vimineum (Poaceae) within the James River Basin of Virginia, USA\n\n\n\n\n\n\n\nmicrostegium vimineum\n\n\ninvasive species\n\n\ngenetic structure\n\n\nfounder effects\n\n\nsecondary contact\n\n\n\n\nCONSERVATION GENETICS. 2011.\n\n\n\n\n\n\nJun 1, 2011\n\n\n\n\n\n\n  \n\n\n\n\nLandscape modelling of gene flow: improved power using conditional genetic distance derived from the topology of population networks\n\n\n\n\n\n\n\ngene flow\n\n\ngenetic ovariance\n\n\nlandscape genetics\n\n\n\n\nMOLECULAR ECOLOGY. 2010.\n\n\n\n\n\n\nSep 1, 2010\n\n\n\n\n\n\n  \n\n\n\n\nNuclear gene phylogeography using PHASE: dealing with unresolved genotypes, lost alleles, and systematic bias in parameter estimation\n\n\n\n\n\nBMC EVOLUTIONARY BIOLOGY. 2010.\n\n\n\n\n\n\nApr 1, 2010\n\n\n\n\n\n\n  \n\n\n\n\nVariable nuclear markers for a Sonoran Desert bark beetle, Araptus attenuatus Wood (Curculionidae: Scolytinae), with applications to related genera\n\n\n\n\n\n\n\nbaja california\n\n\ncodominant loci\n\n\ncoleoptera\n\n\nintrons\n\n\npopulation structure\n\n\n\n\nCONSERVATION GENETICS. 2009.\n\n\n\n\n\n\nAug 1, 2009\n\n\n\n\n\n\n  \n\n\n\n\nNot just vicariance: phylogeography of a Sonoran Desert euphorb indicates a major role of range expansion along the Baja peninsula\n\n\n\n\n\n\n\nbaja california\n\n\neuphorbia\n\n\nlandscape history\n\n\npopulation structure\n\n\nstatistical phylogeography\n\n\n\n\nMOLECULAR ECOLOGY. 2009.\n\n\n\n\n\n\nMay 1, 2009\n\n\n\n\n\n\n  \n\n\n\n\nGeneticStudio: a suite of programs for spatial analysis of genetic-marker data\n\n\n\n\n\n\n\ngenetic structure\n\n\npopulation graphs\n\n\nspatial structure\n\n\n\n\nMOLECULAR ECOLOGY RESOURCES. 2009.\n\n\n\n\n\n\nJan 1, 2009\n\n\n\n\n\n\n  \n\n\n\n\nA set of polymorphic nuclear intron markers for conservation genetics and phylogeography of Euphorbia species (Pedilanthus clade)\n\n\n\n\n\n\n\ncodominant loci\n\n\neuphorbiaceae\n\n\npopulation structure\n\n\nphylogeny\n\n\nsonoran desert\n\n\n\n\nCONSERVATION GENETICS. 2008.\n\n\n\n\n\n\nDec 1, 2008\n\n\n\n\n\n\n  \n\n\n\n\nBabies and bathwater: a comment on the premature obituary for nested clade phylogeographical analysis\n\n\n\n\n\n\n\ncross-validation\n\n\nhypothesis testing\n\n\nintegrative analyses\n\n\nmultiple loci\n\n\n\n\nMOLECULAR ECOLOGY. 2008.\n\n\n\n\n\n\nMar 1, 2008\n\n\n\n\n\n\n  \n\n\n\n\nPowers of discerning: challenges to understanding dispersal processes in natural populations\n\n\n\n\n\nMOLECULAR ECOLOGY. 2007.\n\n\n\n\n\n\nDec 1, 2007\n\n\n\n\n\n\n  \n\n\n\n\nThe evolution of genetic topologies\n\n\n\n\n\n\n\npopulation graphs\n\n\ngenetic structure\n\n\nisolation by distance\n\n\ngraph theory\n\n\ncentrality\n\n\ngraph diameter\n\n\n\n\nTHEORETICAL POPULATION BIOLOGY. 2007.\n\n\n\n\n\n\nFeb 1, 2007\n\n\n\n\n\n\n  \n\n\n\n\nPollen-mediated gene dispersal within continuous and fragmented populations of a forest understorey species, Trillium cuneatum\n\n\n\n\n\n\n\nfragmentation\n\n\npollen gene flow\n\n\ntrillium\n\n\ntwogener\n\n\n\n\nMOLECULAR ECOLOGY. 2006.\n\n\n\n\n\n\nJul 1, 2006\n\n\n\n\n\n\n  \n\n\n\n\nGENER: a server-based analysis of pollen pool structure\n\n\n\n\n\n\n\ngene flow\n\n\npollen structure\n\n\ntwo-generation analysis\n\n\n\n\nMOLECULAR ECOLOGY NOTES. 2005.\n\n\n\n\n\n\nDec 1, 2005\n\n\n\n\n\n\n  \n\n\n\n\nA two-generation analysis of pollen pool genetic structure in flowering dogwood, Cornus florida (Cornaceae), in the Missouri Ozarks\n\n\n\n\n\n\n\ncalifornia\n\n\ncornaceae\n\n\ngene flown\n\n\ngenetic structure\n\n\nlandscape change\n\n\npollen movement\n\n\nsilvicultural treatment\n\n\n2gener\n\n\n\n\n\n\n\n\n\n\n\nFeb 1, 2005\n\n\n\n\n\n\n  \n\n\n\n\nPopulation Graphs: the graph theoretic shape of genetic structure\n\n\n\n\n\n\n\ngenetic structure\n\n\ngraph theory\n\n\nnetworks\n\n\nphylogeography\n\n\n\n\nMOLECULAR ECOLOGY. 2004.\n\n\n\n\n\n\nJul 1, 2004\n\n\n\n\n\n\n  \n\n\n\n\nTwo-generation analysis of pollen flow across a landscape V: a stepwise approach for extracting factors contributing to pollen structure\n\n\n\n\n\n\n\npollen movement\n\n\n2gener\n\n\ngene flow\n\n\nstamova\n\n\n\n\nHEREDITY. 2004.\n\n\n\n\n\n\nMar 1, 2004\n\n\n\n\n\n\n  \n\n\n\n\nPollen movement in declining populations of California Valley oak, Quercus lobata: where have all the fathers gone?\n\n\n\n\n\n\n\ncalifornia valley oak\n\n\ngenetic isolation\n\n\npollen flow\n\n\nquercus lobata\n\n\n2gener\n\n\n\n\nMOLECULAR ECOLOGY. 2002.\n\n\n\n\n\n\nSep 1, 2002\n\n\n\n\n\n\n  \n\n\n\n\nDemographic consequences of inflorescence-feeding insects for Liatris cylindracea, an iteroparous perennial\n\n\n\n\n\n\n\nexperimental insect exclusion\n\n\nindividual-based population models\n\n\ninflorescence-feeding insects\n\n\niteroparous perennial\n\n\npopulation growth rate\n\n\n\n\nOECOLOGIA. 2002.\n\n\n\n\n\n\nAug 1, 2002\n\n\n\n\n\n\n  \n\n\n\n\nPatterns of mating in an insect-pollinated tree species in the Missouri Ozark Forest Ecosystem Project\n\n\n\n\n\nPROCEEDINGS OF THE SECOND MISSOURI OZARK FOREST ECOSYSTEM PROJECT SYMPOSIUM - POST-TREATMENT RESULTS OF THE LANDSCAPE EXPERIMENT. 2002.\n\n\n\n\n\n\nJan 1, 2002\n\n\n\n\n\n\n  \n\n\n\n\nPollen pool heterogeneity in shortleaf pine, Pinus echinata Mill.\n\n\n\n\n\n\n\ncpssr\n\n\ndensity\n\n\ngenetic\n\n\npinus\n\n\npollen\n\n\nstructure\n\n\n\n\nMOLECULAR ECOLOGY. 2001.\n\n\n\n\n\n\nApr 1, 2001\n\n\n\n\n\n\n  \n\n\n\n\nTwo-generation analysis of pollen flow across a landscape. I. Male gamete heterogeneity among females\n\n\n\n\n\n\n\namova\n\n\ngene flow\n\n\ngenetic structure\n\n\nparentage analysis\n\n\nphi statistics\n\n\npollen movement\n\n\nquercus alba\n\n\n2gener\n\n\n\n\nEVOLUTION. 2001.\n\n\n\n\n\n\nFeb 1, 2001\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "dyerlab",
    "section": "",
    "text": "The Dyer laboratory is a research lab at Virginia Commonwealth University that focuses on developing and testing tools to aid in understand how landscape features influence genetic connectivity. This requires a mix of theory development, software creation, and evaluation using (largely) non-model systems in the field."
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "dyerlab",
    "section": "Recent Posts",
    "text": "Recent Posts"
  },
  {
    "objectID": "people.html",
    "href": "people.html",
    "title": "People",
    "section": "",
    "text": "Research in the Dyer Laboratory focuses on understanding how landscape features influence genetic connectivity and movement in native and introduced species.\n\n\n\n\n\n\n\n   \n\n\n\nRodney J. Dyer, PhD\nPrincipal Investigator\n\n\n\n\n \n\n\n\n\n\n\n\n   \n\n\n\n\nJane Remfert\nDoctoral Candidate\n\n\n\n\n \n\n\n\n\n\n\n\n   \n\n\n\n\nMadison Whitehurst\nMasters Candidate\n\n\n\n\n\n\nPrevious Laboratory Members\n\nRebekha Archibald-Shaw Thesis: Seed dispersal and subsequent recruitment of the mid-canopy forest tree, Cornus florida. Supported in part by the Rice Center. MS, Environmental Sciences, Virginia Commonwealth University 2009.\nStephen Baker Thesis: Invasion genetic of the invasive grass, Microstegium vimineum (Poaceae). Supported in part by the Rice Center. MS, Biology, Virginia Commonwealth University 2009.\nDan Carr Thesis: Pollination biology of the understory tree, Cornus florida L. Supported in part by the Rice Center and National Science Foundation research grant DEB-0640803. MS, Biology, Virginia Commonwealth University, 2010.\nStephanie Crouch-Burgess Thesis: Spatial genetic structure of the mole salamander, Ambystoma opacum (Gravenhorst). Supported in part by the Rice Center. MS, Biology, Virginia Commonwealth University, 2008. Currently pursuing her PhD at OleMiss with Dr. Ryan Garrick.\nMatthew DeSaix Thesis: Patterns of population structure and migratory connectivity revealed in a songbird of conservation concern. Supported in part by funding by the Department of Defense, the Rice Center, and the Center for Environmental Studies. MS, Environmental STudies, Virginia Commonwealth University, 2018.\nCandace Dillion Thesis: Assessment of pre-PCR whole genome amplification of single pollen grains in flowering dogwood (Cornus florida L.). Supported in part by the Rice Center and National Science Foundation research grant DEB-0640803. MS, Biology, Virginia Commonwealth University 2009.\nVicki Gardiakos Thesis: Investigating patterns of pollen-mediated gene dispersal in the flowering dogwood, Cornus florida L. Supported in part by NSF DEB-0640803. Supported in part by National Science Foundation research grant DEB-0640803. MS, Biology, Virginia Commonwealth University 2009.\nDr. Ryan Garrick Dr. Garrick was a post-doctoral researcher in the laboratory from 2007-2009 under National Science Foundation Research Grant DEB-0543102. Currently Dr. Garrick is an Assistant Professor in Biology at the University of Mississippi.\nMorgan Gostel Thesis: Evolutionary relationships in Afro-Malagasy Schefflera based on nuclear and chloroplast markers. MS, Biology, Virginia Commonwealth University, 2010.\nCatherine Heidrich MS Thesis Project: Who’s your daddy? Extra-pair copulation of Prothonotary warblers (Protonotaria citrea). Supported in part by the Rice Center. MS, Biology, Virginia Commonwealth University 2012.\nJameson Hinkle MS Thesis Project: Proof-of-concept of environmental DNA tools for Atlantic Sturgeon management. MS Center for Environmental Studies, Virginia Commonwealth University, 2015.\nMegan Kuechle Thesis: Influence of environmental features on spermatophore placement and male fecundity in spotted salamanders (Ambystoma maculatum). MS, Center for Environmental Studies, Virginia Commonwealth University, 2020.\nOlivia Latham Thesis: Bee functional trait analysis in shale barren pollinator networks. MS, Center for Environmental Studies, Virginia Commonwealth University, 2020.\nCrystal Meadows Thesis: Determining impediments to gene flow in a natural population of Cornus florida L. Cornaceae, using integrative landscape genetic techniques. MS, Biology, Virginia Commonwealth University, 2010.\nAngela Redwine Thesis: Reproductive dynamics in flowering dogwood along an urban landscape gradient. MS, Environmental Sciences, Virginia Commonwealth University, 2012.\nBonnie Roderique Thesis: Improving the conservation of a cryptic endangered freshwater mussel (Parvaspina collina) through the use of environmental DNA and species distribution modeling. This project was supported in part by funding from the Virginia Transportation Research Council (VTRC) and the Rice Center. MS, Environmental Studies, Virginia Commonwealth University, 2018.\nChitra Seshadri Thesis: Genome wide analysis of sequence and epigenetic variance in Araptus attenuatus, the Sonoran Desert bark beetle. MS, Environmental Sciences, 2016.\nAnna Tucker Thesis: Fitness cost of conspecific brood parasitism in a cavity-nesting warbler. MS, Biology, Virginia Commonwealth University, 2014.\nDr. Cathy Viverette Thesis: Influence of historic landscapes and contemporary species management on Chesapeake Bay Bald Eagles and Osprey. PhD, Integrated Life Sciences, 2016.\nAbby Wright Undergraduate researchers. 2019-2020."
  },
  {
    "objectID": "people/dyer.html",
    "href": "people/dyer.html",
    "title": "Rodney J. Dyer",
    "section": "",
    "text": "Rodney Dyer is currently serving as the Director of the Center for Environmental Studies at Virginia Commonwealth University.\nHis research laboratory focuses on developing tools to better understand how the physical configuration of natural and modified landscapes impact genetic connectivity for native and introduced species."
  },
  {
    "objectID": "people/dyer.html#education",
    "href": "people/dyer.html#education",
    "title": "Rodney J. Dyer",
    "section": "Education",
    "text": "Education\n2002 - PhD Biology - University of Missouri Saint Louis\n1998 - MS Biology - University of Missouri Saint Louis\n1996 - BS Biology - Western Washington University\n1994 - AA General - Seattle Central Community College"
  },
  {
    "objectID": "people/dyer.html#professional-experience",
    "href": "people/dyer.html#professional-experience",
    "title": "Rodney J. Dyer",
    "section": "Professional Experience",
    "text": "Professional Experience\n2017 - Present: Full Professor, VCU\n2017 - Present: Director, CES\n2017 - 2018: Interim Director, CSBC\n2010 - 2017: Associate Professor, VCU\n2004 - 2010: Assistant Professor, VCU\n2002 - 2004: Postdoctoral Researcher, ISU\n1995 - 1995: Howard Hughes Research Fellow, UW"
  }
]